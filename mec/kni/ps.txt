USER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root          2  0.0  0.0      0     0 ?        S    May03   0:00 [kthreadd]
root          3  0.0  0.0      0     0 ?        S    May03   0:15  \_ [ksoftirqd/0]
root          5  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/0:0H]
root          8  0.0  0.0      0     0 ?        S    May03   0:01  \_ [migration/0]
root          9  0.0  0.0      0     0 ?        S    May03   0:00  \_ [rcu_bh]
root         10  0.1  0.0      0     0 ?        S    May03  38:44  \_ [rcu_sched]
root         11  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [lru-add-drain]
root         12  0.0  0.0      0     0 ?        S    May03   0:06  \_ [watchdog/0]
root         13  0.0  0.0      0     0 ?        S    May03   0:06  \_ [watchdog/1]
root         14  0.0  0.0      0     0 ?        S    May03   0:01  \_ [migration/1]
root         15  0.0  0.0      0     0 ?        S    May03   0:08  \_ [ksoftirqd/1]
root         17  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/1:0H]
root         18  0.0  0.0      0     0 ?        S    May03   0:05  \_ [watchdog/2]
root         19  0.0  0.0      0     0 ?        S    May03   0:02  \_ [migration/2]
root         20  0.0  0.0      0     0 ?        S    May03   0:09  \_ [ksoftirqd/2]
root         22  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/2:0H]
root         23  0.0  0.0      0     0 ?        S    May03   0:05  \_ [watchdog/3]
root         24  0.0  0.0      0     0 ?        S    May03   0:02  \_ [migration/3]
root         25  0.0  0.0      0     0 ?        S    May03   0:09  \_ [ksoftirqd/3]
root         27  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/3:0H]
root         28  0.0  0.0      0     0 ?        S    May03   0:05  \_ [watchdog/4]
root         29  0.0  0.0      0     0 ?        S    May03   0:03  \_ [migration/4]
root         30  0.0  0.0      0     0 ?        S    May03   0:10  \_ [ksoftirqd/4]
root         32  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/4:0H]
root         33  0.0  0.0      0     0 ?        S    May03   0:05  \_ [watchdog/5]
root         34  0.0  0.0      0     0 ?        S    May03   0:01  \_ [migration/5]
root         35  0.0  0.0      0     0 ?        S    May03   0:12  \_ [ksoftirqd/5]
root         37  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/5:0H]
root         38  0.0  0.0      0     0 ?        S    May03   0:05  \_ [watchdog/6]
root         39  0.0  0.0      0     0 ?        S    May03   0:01  \_ [migration/6]
root         40  0.0  0.0      0     0 ?        S    May03   0:07  \_ [ksoftirqd/6]
root         42  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/6:0H]
root         43  0.0  0.0      0     0 ?        S    May03   0:05  \_ [watchdog/7]
root         44  0.0  0.0      0     0 ?        S    May03   0:01  \_ [migration/7]
root         45  0.0  0.0      0     0 ?        S    May03   0:06  \_ [ksoftirqd/7]
root         47  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/7:0H]
root         48  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/8]
root         49  0.0  0.0      0     0 ?        S    May03   0:01  \_ [migration/8]
root         50  0.0  0.0      0     0 ?        S    May03   0:05  \_ [ksoftirqd/8]
root         52  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/8:0H]
root         54  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/9]
root         55  0.0  0.0      0     0 ?        S    May03   0:01  \_ [migration/9]
root         56  0.0  0.0      0     0 ?        S    May03   0:05  \_ [ksoftirqd/9]
root         58  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/9:0H]
root         59  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/10]
root         60  0.0  0.0      0     0 ?        S    May03   0:02  \_ [migration/10]
root         61  0.0  0.0      0     0 ?        S    May03   0:07  \_ [ksoftirqd/10]
root         63  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/10:0H]
root         64  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/11]
root         65  0.0  0.0      0     0 ?        S    May03   0:02  \_ [migration/11]
root         66  0.0  0.0      0     0 ?        S    May03   0:06  \_ [ksoftirqd/11]
root         68  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/11:0H]
root         69  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/12]
root         70  0.0  0.0      0     0 ?        S    May03   0:03  \_ [migration/12]
root         71  0.0  0.0      0     0 ?        S    May03   0:09  \_ [ksoftirqd/12]
root         73  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/12:0H]
root         74  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/13]
root         75  0.0  0.0      0     0 ?        S    May03   0:01  \_ [migration/13]
root         76  0.0  0.0      0     0 ?        S    May03   0:13  \_ [ksoftirqd/13]
root         78  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/13:0H]
root         79  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/14]
root         80  0.0  0.0      0     0 ?        S    May03   0:01  \_ [migration/14]
root         81  0.0  0.0      0     0 ?        S    May03   0:09  \_ [ksoftirqd/14]
root         83  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/14:0H]
root         84  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/15]
root         85  0.0  0.0      0     0 ?        S    May03   0:01  \_ [migration/15]
root         86  0.0  0.0      0     0 ?        S    May03   0:06  \_ [ksoftirqd/15]
root         88  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/15:0H]
root         89  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/16]
root         90  0.0  0.0      0     0 ?        S    May03   0:01  \_ [migration/16]
root         91  0.0  0.0      0     0 ?        S    May03   0:00  \_ [ksoftirqd/16]
root         93  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/16:0H]
root         94  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/17]
root         95  0.0  0.0      0     0 ?        S    May03   0:56  \_ [migration/17]
root         96  0.0  0.0      0     0 ?        S    May03   0:09  \_ [ksoftirqd/17]
root         98  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/17:0H]
root         99  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/18]
root        100  0.0  0.0      0     0 ?        S    May03   0:09  \_ [migration/18]
root        101  0.0  0.0      0     0 ?        S    May03   0:01  \_ [ksoftirqd/18]
root        103  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/18:0H]
root        104  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/19]
root        105  0.0  0.0      0     0 ?        S    May03   0:03  \_ [migration/19]
root        106  0.0  0.0      0     0 ?        S    May03   0:00  \_ [ksoftirqd/19]
root        108  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/19:0H]
root        109  0.0  0.0      0     0 ?        S    May03   0:03  \_ [watchdog/20]
root        110  0.0  0.0      0     0 ?        S    May03   0:02  \_ [migration/20]
root        111  0.0  0.0      0     0 ?        S    May03   0:00  \_ [ksoftirqd/20]
root        113  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/20:0H]
root        114  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/21]
root        115  0.0  0.0      0     0 ?        S    May03   0:02  \_ [migration/21]
root        116  0.0  0.0      0     0 ?        S    May03   0:00  \_ [ksoftirqd/21]
root        118  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/21:0H]
root        119  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/22]
root        120  0.0  0.0      0     0 ?        S    May03   0:01  \_ [migration/22]
root        121  0.0  0.0      0     0 ?        S    May03   0:03  \_ [ksoftirqd/22]
root        123  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/22:0H]
root        124  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/23]
root        125  0.0  0.0      0     0 ?        S    May03   0:01  \_ [migration/23]
root        126  0.0  0.0      0     0 ?        S    May03   0:00  \_ [ksoftirqd/23]
root        128  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/23:0H]
root        129  0.0  0.0      0     0 ?        S    May03   0:05  \_ [watchdog/24]
root        130  0.0  0.0      0     0 ?        S    May03   0:01  \_ [migration/24]
root        131  0.0  0.0      0     0 ?        S    May03   0:00  \_ [ksoftirqd/24]
root        133  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/24:0H]
root        134  0.0  0.0      0     0 ?        S    May03   0:05  \_ [watchdog/25]
root        135  0.0  0.0      0     0 ?        S    May03   1:09  \_ [migration/25]
root        136  0.0  0.0      0     0 ?        S    May03   0:05  \_ [ksoftirqd/25]
root        138  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/25:0H]
root        139  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/26]
root        140  0.0  0.0      0     0 ?        S    May03   0:11  \_ [migration/26]
root        141  0.0  0.0      0     0 ?        S    May03   0:00  \_ [ksoftirqd/26]
root        143  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/26:0H]
root        144  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/27]
root        145  0.0  0.0      0     0 ?        S    May03   0:04  \_ [migration/27]
root        146  0.0  0.0      0     0 ?        S    May03   0:00  \_ [ksoftirqd/27]
root        148  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/27:0H]
root        149  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/28]
root        150  0.0  0.0      0     0 ?        S    May03   0:03  \_ [migration/28]
root        151  0.0  0.0      0     0 ?        S    May03   0:00  \_ [ksoftirqd/28]
root        153  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/28:0H]
root        154  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/29]
root        155  0.0  0.0      0     0 ?        S    May03   0:02  \_ [migration/29]
root        156  0.0  0.0      0     0 ?        S    May03   0:00  \_ [ksoftirqd/29]
root        158  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/29:0H]
root        159  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/30]
root        160  0.0  0.0      0     0 ?        S    May03   0:01  \_ [migration/30]
root        161  0.0  0.0      0     0 ?        S    May03   0:00  \_ [ksoftirqd/30]
root        163  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/30:0H]
root        164  0.0  0.0      0     0 ?        S    May03   0:04  \_ [watchdog/31]
root        165  0.0  0.0      0     0 ?        S    May03   0:01  \_ [migration/31]
root        166  0.0  0.0      0     0 ?        S    May03   0:00  \_ [ksoftirqd/31]
root        168  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/31:0H]
root        171  0.0  0.0      0     0 ?        S    May03   0:00  \_ [kdevtmpfs]
root        172  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [netns]
root        173  0.0  0.0      0     0 ?        S    May03   0:02  \_ [khungtaskd]
root        174  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [writeback]
root        175  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kintegrityd]
root        176  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [bioset]
root        177  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [bioset]
root        178  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [bioset]
root        179  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kblockd]
root        180  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [md]
root        181  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [edac-poller]
root        182  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [watchdogd]
root        189  0.0  0.0      0     0 ?        S    May03   0:00  \_ [kswapd0]
root        190  0.0  0.0      0     0 ?        S    May03   0:00  \_ [kswapd1]
root        191  0.0  0.0      0     0 ?        SN   May03   0:00  \_ [ksmd]
root        192  0.0  0.0      0     0 ?        SN   May03   0:06  \_ [khugepaged]
root        193  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [crypto]
root        201  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kthrotld]
root        205  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kmpath_rdacd]
root        206  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kaluad]
root        208  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kpsmoused]
root        209  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [ipv6_addrconf]
root        222  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [deferwq]
root        258  0.0  0.0      0     0 ?        S    May03   0:06  \_ [kauditd]
root        625  0.0  0.0      0     0 ?        S    May03   0:07  \_ [kworker/21:1]
root       1070  0.0  0.0      0     0 ?        S    May03   0:00  \_ [scsi_eh_0]
root       1074  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [scsi_tmf_0]
root       1221  0.0  0.0      0     0 ?        S    May03   0:07  \_ [kworker/23:1]
root       1490  0.0  0.0      0     0 ?        S    May03   0:07  \_ [kworker/16:1]
root       1494  0.0  0.0      0     0 ?        S    May03   0:08  \_ [kworker/22:1]
root       1496  0.0  0.0      0     0 ?        S    May03   0:03  \_ [kworker/31:1]
root       1501  0.0  0.0      0     0 ?        S    May03   0:04  \_ [kworker/30:1]
root       1505  0.0  0.0      0     0 ?        S    May03   0:19  \_ [kworker/19:1]
root       1507  0.0  0.0      0     0 ?        S    May03   0:07  \_ [kworker/28:1]
root       1810  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [bnx2x]
root       1811  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [bnx2x_iov]
root       2673  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [ttm_swap]
root       7029  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [bioset]
root       7032  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfsalloc]
root       7033  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs_mru_cache]
root       7040  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-buf/sda3]
root       7042  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-data/sda3]
root       7043  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-conv/sda3]
root       7044  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-cil/sda3]
root       7045  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-reclaim/sda]
root       7048  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-log/sda3]
root       7049  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-eofblocks/s]
root       7052  0.0  0.0      0     0 ?        S    May03   8:57  \_ [xfsaild/sda3]
root       7056  0.0  0.0      0     0 ?        S<   May03   0:03  \_ [kworker/9:1H]
root       8815  0.0  0.0      0     0 ?        SN   May03   0:00  \_ [kipmi0]
root      10555  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-buf/sda2]
root      10556  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-data/sda2]
root      10558  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-conv/sda2]
root      10560  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-cil/sda2]
root      10562  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-reclaim/sda]
root      10564  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-log/sda2]
root      10566  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-eofblocks/s]
root      10573  0.0  0.0      0     0 ?        S    May03   0:00  \_ [xfsaild/sda2]
root      10694  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-buf/sda4]
root      10702  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-data/sda4]
root      10716  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-conv/sda4]
root      10732  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-cil/sda4]
root      10750  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-reclaim/sda]
root      10758  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-log/sda4]
root      10765  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [xfs-eofblocks/s]
root      10766  0.0  0.0      0     0 ?        S    May03   0:00  \_ [xfsaild/sda4]
root      12451  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kvm-irqfd-clean]
root      13664  0.0  0.0      0     0 ?        S<   May03   0:04  \_ [kworker/11:1H]
root      13665  0.0  0.0      0     0 ?        S<   May03   0:10  \_ [kworker/12:1H]
root      13815  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/21:1H]
root      13832  0.0  0.0      0     0 ?        S    May03   4:34  \_ [kworker/24:2]
root      13879  0.0  0.0      0     0 ?        S<   May03   0:09  \_ [kworker/14:1H]
root      13880  0.0  0.0      0     0 ?        S<   May03   0:04  \_ [kworker/15:1H]
root      13890  0.0  0.0      0     0 ?        S<   May03   0:05  \_ [kworker/10:1H]
root      13896  0.0  0.0      0     0 ?        S<   May03   0:15  \_ [kworker/13:1H]
root      13942  0.0  0.0      0     0 ?        S<   May03   0:07  \_ [kworker/4:1H]
root      20242  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/17:1H]
root      20243  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/1:1H]
root      21340  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/25:1H]
root      23189  0.0  0.0      0     0 ?        S<   May03   0:02  \_ [kworker/3:1H]
root      23264  0.0  0.0      0     0 ?        S<   May03   0:02  \_ [kworker/7:1H]
root      23265  0.0  0.0      0     0 ?        S<   May03   0:03  \_ [kworker/8:1H]
root      23578  0.0  0.0      0     0 ?        S<   May03   0:01  \_ [kworker/0:1H]
root      25860  0.0  0.0      0     0 ?        S<   May03   0:00  \_ [kworker/19:1H]
root      28385  0.0  0.0      0     0 ?        S<   May04   0:12  \_ [kworker/5:1H]
root      28396  0.0  0.0      0     0 ?        S<   May04   0:06  \_ [kworker/6:1H]
root      28397  0.0  0.0      0     0 ?        S<   May04   0:03  \_ [kworker/2:1H]
root       1406  0.0  0.0      0     0 ?        S<   May04   0:00  \_ [kworker/27:1H]
root       7239  0.0  0.0      0     0 ?        S<   May04   0:00  \_ [kworker/18:1H]
root       8821  0.0  0.0      0     0 ?        S<   May04   0:00  \_ [kworker/22:1H]
root       8822  0.0  0.0      0     0 ?        S<   May04   0:00  \_ [kworker/16:1H]
root       8853  0.0  0.0      0     0 ?        S<   May04   0:00  \_ [kworker/23:1H]
root       8992  0.0  0.0      0     0 ?        S<   May04   0:00  \_ [kworker/20:1H]
root      12586  0.0  0.0      0     0 ?        S<   May04   0:00  \_ [kworker/28:1H]
root      13128  0.0  0.0      0     0 ?        S<   May04   0:00  \_ [kworker/30:1H]
root      22865  0.0  0.0      0     0 ?        S<   May04   0:00  \_ [kworker/24:1H]
root      32067  0.0  0.0      0     0 ?        S<   May04   0:00  \_ [kworker/26:1H]
root       8182  0.0  0.0      0     0 ?        S<   May04   0:00  \_ [iscsi_eh]
root       8529  0.0  0.0      0     0 ?        S<   May04   0:00  \_ [kmpathd]
root       8530  0.0  0.0      0     0 ?        S<   May04   0:00  \_ [kmpath_handlerd]
root       9714  0.0  0.0      0     0 ?        S<   May04   0:00  \_ [dm_bufio_cache]
root       9731  0.0  0.0      0     0 ?        S<   May04   0:00  \_ [target_completi]
root       9732  0.0  0.0      0     0 ?        S<   May04   0:00  \_ [tmr-rd_mcp]
root       9735  0.0  0.0      0     0 ?        S<   May04   0:00  \_ [xcopy_wq]
root      11453  0.0  0.0      0     0 ?        S<   May04   0:00  \_ [kworker/31:1H]
root      11615  0.0  0.0      0     0 ?        S<   May04   0:00  \_ [kworker/29:1H]
root     112548  0.0  0.0      0     0 ?        S    May05   0:00  \_ [kworker/19:0]
root      31064  0.0  0.0      0     0 ?        S    May06   0:43  \_ [kworker/4:2]
root     103538  0.0  0.0      0     0 ?        S    May06   0:05  \_ [kworker/29:0]
root     104677  0.0  0.0      0     0 ?        S    May06   0:10  \_ [kworker/20:1]
root     120769  0.0  0.0      0     0 ?        S    May07   0:13  \_ [kworker/27:2]
root      88337  0.0  0.0      0     0 ?        S    May07   0:00  \_ [kworker/23:0]
root      35250  0.0  0.0      0     0 ?        S    May07   0:00  \_ [kworker/18:1]
root     102472  0.0  0.0      0     0 ?        S    May09   0:56  \_ [kworker/1:1]
root     106956  0.0  0.0      0     0 ?        S    May09   0:00  \_ [kworker/22:0]
root       9276  0.0  0.0      0     0 ?        S    May10   0:29  \_ [kworker/5:1]
root     120272  0.0  0.0      0     0 ?        S    May10   0:00  \_ [kworker/16:0]
root     120324  0.0  0.0      0     0 ?        S    May10   0:24  \_ [kworker/7:2]
root      33997  0.0  0.0      0     0 ?        S    May11   0:00  \_ [kworker/24:1]
root      61917  0.0  0.0      0     0 ?        S    May12   0:23  \_ [kworker/6:2]
root      70986  0.0  0.0      0     0 ?        S    May12   0:14  \_ [kworker/15:2]
root      71967  0.0  0.0      0     0 ?        S    May12   0:12  \_ [kworker/8:0]
root     115615  0.0  0.0      0     0 ?        S<   May12   0:00  \_ [dio/sda3]
root     121514  0.0  0.0      0     0 ?        S    May12   0:00  \_ [kworker/30:0]
root       5808  0.0  0.0      0     0 ?        S    May12   0:00  \_ [kworker/29:2]
root      56312  0.0  0.0      0     0 ?        S    May12   0:00  \_ [kworker/20:0]
root      46838  0.0  0.0      0     0 ?        S    May13   0:00  \_ [kworker/8:2]
root      47243  0.0  0.0      0     0 ?        S    May13   0:12  \_ [kworker/18:2]
root      56827  0.0  0.0      0     0 ?        S    May13   0:00  \_ [kworker/27:1]
root      66997  0.0  0.0      0     0 ?        S    May13   3:02  \_ [kvm-pit/191]
root      42384  0.0  0.0      0     0 ?        S    May14   0:24  \_ [kworker/12:1]
root      62263  0.0  0.0      0     0 ?        S    May14   0:05  \_ [kworker/9:0]
root      63258  0.0  0.0      0     0 ?        S    May14   0:17  \_ [kworker/13:1]
root      40425  0.0  0.0      0     0 ?        S    May15   0:00  \_ [kworker/31:2]
root       1498  0.0  0.0      0     0 ?        S    May15   0:00  \_ [kworker/25:1]
root      14408  0.0  0.0      0     0 ?        S    May15   0:08  \_ [kworker/25:0]
root     108465  0.0  0.0      0     0 ?        S    May16   0:07  \_ [kworker/17:2]
root      45698  0.0  0.0      0     0 ?        S    May16   0:00  \_ [kworker/5:0]
root      77347  0.0  0.0      0     0 ?        S    May17   0:06  \_ [kworker/26:1]
root      41737  0.0  0.0      0     0 ?        S    May17   0:00  \_ [kworker/26:0]
root     105346  0.0  0.0      0     0 ?        S    May19   0:00  \_ [kworker/6:0]
root      42708  0.0  0.0      0     0 ?        S    May19   0:11  \_ [kworker/11:1]
root       4856  0.0  0.0      0     0 ?        S    May19   0:00  \_ [kworker/4:0]
root      23826  0.0  0.0      0     0 ?        S    May20   0:04  \_ [kworker/9:2]
root      24977  0.0  0.0      0     0 ?        S    May20   0:00  \_ [kworker/2:1]
root      25366  0.0  0.0      0     0 ?        S    May20   0:00  \_ [kworker/28:2]
root      25380  0.0  0.0      0     0 ?        S    May20   0:00  \_ [kworker/1:0]
root      25995  0.0  0.0      0     0 ?        S    May20   0:00  \_ [kworker/21:0]
root      46215  0.0  0.0      0     0 ?        S    May20   0:00  \_ [kworker/13:0]
root     118018  0.0  0.0      0     0 ?        S    May20   0:09  \_ [kworker/2:0]
root     101857  0.0  0.0      0     0 ?        S    May20   0:00  \_ [kworker/u65:1]
root      86811  0.0  0.0      0     0 ?        S    May20   0:00  \_ [kworker/12:2]
root      65413  0.0  0.0      0     0 ?        S    May21   0:00  \_ [kworker/7:1]
root      41984  0.0  0.0      0     0 ?        S    May21   0:03  \_ [kworker/10:0]
root      50293  0.0  0.0      0     0 ?        S    May21   2:15  \_ [kworker/0:2]
root       1205  0.0  0.0      0     0 ?        S    May22   0:00  \_ [kworker/15:1]
root      14367  0.0  0.0      0     0 ?        S    May23   0:01  \_ [kworker/17:0]
root      13696  0.0  0.0      0     0 ?        S    May23   0:00  \_ [kworker/10:2]
root      24583  0.0  0.0      0     0 ?        S    00:38   0:00  \_ [kworker/u66:0]
root      96328  0.0  0.0      0     0 ?        S    03:02   0:00  \_ [kworker/u66:1]
root      76423  0.0  0.0      0     0 ?        S    04:46   0:00  \_ [kworker/11:2]
root     126649  0.0  0.0      0     0 ?        S    07:01   0:00  \_ [kworker/3:2]
root      29157  0.0  0.0      0     0 ?        S    08:11   0:00  \_ [kworker/u65:2]
root     130131  0.0  0.0      0     0 ?        S    11:40   0:02  \_ [kworker/u64:0]
root      42619  0.0  0.0      0     0 ?        S    11:59   0:00  \_ [kworker/3:0]
root      59332  0.0  0.0      0     0 ?        S    13:02   0:02  \_ [kworker/u64:1]
root     121850  0.0  0.0      0     0 ?        S    16:19   0:00  \_ [kworker/14:0]
root     130786  0.0  0.0      0     0 ?        S    16:23   0:00  \_ [kworker/0:0]
root       3903  0.0  0.0      0     0 ?        S    16:24   0:00  \_ [kworker/14:2]
root      11954  0.0  0.0      0     0 ?        S    16:28   0:00  \_ [kworker/0:1]
root      17042  0.0  0.0      0     0 ?        S    16:30   0:00  \_ [kworker/14:1]
root          1  0.0  0.0 195760  9036 ?        Ss   May03   9:40 /usr/lib/systemd/systemd --switched-root --system --deserialize 22
root       7157  0.0  0.0  48076  5472 ?        Ss   May03   0:01 /usr/lib/systemd/systemd-udevd
root      13490  0.0  0.0  55520  1116 ?        S<sl May03   0:23 /sbin/auditd
dbus      13513  0.0  0.0  66764  2932 ?        Ssl  May03   0:57 /usr/bin/dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation
root      13515  0.0  0.0  21804  1384 ?        Ss   May03   8:07 /usr/sbin/irqbalance --foreground
polkitd   13521  0.0  0.0 613016 13384 ?        Ssl  May03   0:08 /usr/lib/polkit-1/polkitd --no-debug
root      13522  0.0  0.0  26376  1764 ?        Ss   May03   0:08 /usr/lib/systemd/systemd-logind
root      13543  0.0  0.0 126288  1696 ?        Ss   May03   0:02 /usr/sbin/crond -n
root      13548  0.0  0.0 110104   868 tty1     Ss+  May03   0:00 /sbin/agetty --noclear tty1 linux
root      13575  0.0  0.0 362496 33660 ?        Ssl  May03   0:22 /usr/bin/python -Es /usr/sbin/firewalld --nofork --nopid
root      14191  0.0  0.0 115708   728 ?        Ss   May03   0:00 /usr/bin/rhsmcertd
root      14197  0.0  0.0 107968   636 ?        Ss   May03   0:00 rhnsd
root      14832  0.0  0.0  89648  2180 ?        Ss   May03   0:08 /usr/libexec/postfix/master -w
postfix   14857  0.0  0.0  89820  4084 ?        S    May03   0:01  \_ qmgr -l -t unix -u
postfix   69511  0.0  0.0  89752  4096 ?        S    15:56   0:00  \_ pickup -l -t unix -u
root       8300  0.0  0.0 112864  4340 ?        Ss   May04   0:00 /usr/sbin/sshd -D
root      20216  0.4  0.0 161420  6296 ?        Ss   16:31   0:00  \_ sshd: root@pts/1
root      20287  0.6  0.0 120860  7424 pts/1    Ss   16:31   0:00  |   \_ -bash
root      21155  0.0  0.0 155740  2304 pts/1    R+   16:32   0:00  |   |   \_ ps aufx ww
root      20290  0.1  0.0 113180  1584 ?        Ss   16:31   0:00  |   \_ bash -c while [ -d /proc/$PPID ]; do sleep 1;head -v -n 8 /proc/meminfo; head -v -n 2 /proc/stat /proc/version /proc/uptime /proc/loadavg /proc/sys/fs/file-nr /proc/sys/kernel/hostname; tail -v -n 16 /proc/net/dev;echo '==> /proc/df <==';df;echo '==> /proc/who <==';who;echo '==> /proc/end <==';echo '##Moba##'; done
root      21157  0.0  0.0 107952   356 ?        S    16:32   0:00  |       \_ sleep 1
root      20239  0.1  0.0 161096  5812 ?        Ss   16:31   0:00  \_ sshd: root@notty
root      20253  0.0  0.0  72200  2864 ?        Ss   16:31   0:00      \_ /usr/libexec/openssh/sftp-server
chrony     8546  0.0  0.0  22524  1352 ?        S    May04   0:01 /usr/sbin/chronyd
root       8752  0.0  0.0 1785180 56856 ?       Ssl  May04  15:32 /usr/sbin/rsyslogd -n
root      12472  0.0  0.0 127348  4076 ?        Ss   May04   0:00 /usr/sbin/lvmetad -f
root      13188  0.0  0.0 2583108 25988 ?       Ssl  May04   5:36 /usr/libexec/docker/rhel-push-plugin
root      30026  0.1  0.0 4772540 56088 ?       Ssl  May04  52:44 /usr/bin/dockerd-current --add-runtime docker-runc=/usr/libexec/docker/docker-runc-current --default-runtime=docker-runc --authorization-plugin=rhel-push-plugin --exec-opt native.cgroupdriver=systemd --userland-proxy-path=/usr/libexec/docker/docker-proxy-current --init-path=/usr/libexec/docker/docker-init-current --seccomp-profile=/etc/docker/seccomp.json --selinux-enabled --signature-verification=False --storage-driver overlay2 --mtu=1450 --add-registry registry.redhat.io --add-registry docker.io
root      30043  0.0  0.0 2834008 33712 ?       Ssl  May04  22:05  \_ /usr/bin/docker-containerd-current -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --metrics-interval=0 --start-timeout 2m --state-dir /var/run/docker/libcontainerd/containerd --shim docker-containerd-shim --runtime docker-runc --runtime-args --systemd-cgroup=true
root       6260  0.0  0.0  40216  7668 ?        Ss   May04  21:34 /usr/lib/systemd/systemd-journald
rpc        8105  0.0  0.0  69264  1200 ?        Ss   May04   0:02 /sbin/rpcbind -w
root       8178  0.0  0.0  31516   504 ?        Ss   May04   0:40 /usr/sbin/iscsid
root       8179  0.0  0.0  32020  5332 ?        S<Ls May04   0:00 /usr/sbin/iscsid
root       8543  0.0  0.0 257316  7428 ?        SLl  May04   0:55 /sbin/multipathd
nobody    39509  0.0  0.0  54980  3236 ?        Ss   May06   2:36 /usr/sbin/dnsmasq -k
root      39910  1.1  0.0 3999536 93808 ?       Ssl  May06 295:53 /usr/bin/crio
root      96255  0.0  0.0 352128 10884 pts/0    Ssl+ May13   0:00  \_ /usr/bin/runc exec --process /tmp/exec-process-848172846 f95c2be21b43dc17c7d243a51a35009452f5dbd81260329a8d63da8674b0264d
root      96264  0.0  0.0  51892  2468 pts/0    Ss+  May13   0:00  |   \_ socat unix-connect://var/run/kubevirt-private/2c5f2902-7557-11e9-83a9-7ca23e90ca35/virt-serial0 stdio,cfmakeraw
root      21097  0.0  0.0 220544 10136 ?        Sl   10:55   0:00  \_ /usr/bin/runc exec --process /tmp/exec-process-761988342 f95c2be21b43dc17c7d243a51a35009452f5dbd81260329a8d63da8674b0264d
root      21108  0.0  0.0  51892  2468 ?        Ss   10:55   0:00      \_ socat unix-connect://var/run/kubevirt-private/2c5f2902-7557-11e9-83a9-7ca23e90ca35/virt-vnc stdio
root      40011  0.0  0.0 548300  9640 ?        Ssl  May06   0:56 /usr/sbin/NetworkManager --no-daemon
root      40073  0.0  0.0 107464  5520 ?        S    May06   0:06  \_ /sbin/dhclient -d -q -sf /usr/libexec/nm-dhcp-helper -pf /var/run/dhclient-enp0s29u1u1u5.pid -lf /var/lib/NetworkManager/dhclient-001b81c6-fce8-4c09-bd21-de213e7cc3bb-enp0s29u1u1u5.lease -cf /var/lib/NetworkManager/dhclient-enp0s29u1u1u5.conf enp0s29u1u1u5
root       2557  0.0  0.0  85896   828 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c c4226f4799f86e4bf9b01eca0287d9969bcbe1ccc682d8e627dc6c30e73ed284 -u c4226f4799f86e4bf9b01eca0287d9969bcbe1ccc682d8e627dc6c30e73ed284 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/c4226f4799f86e4bf9b01eca0287d9969bcbe1ccc682d8e627dc6c30e73ed284/userdata -p /var/run/containers/storage/overlay-containers/c4226f4799f86e4bf9b01eca0287d9969bcbe1ccc682d8e627dc6c30e73ed284/userdata/pidfile -l /var/log/pods/536301a9-6fa2-11e9-966c-7ca23e90ca35/c4226f4799f86e4bf9b01eca0287d9969bcbe1ccc682d8e627dc6c30e73ed284.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root       2570  0.0  0.0   2740   992 ?        Ssl  May06   0:01  \_ /usr/bin/pod
root       2605  0.0  0.0  85896   828 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c c67653629fcb02c55cb1cd58b9df015e21ae6fb6ee6349954aaa7658cc580490 -u c67653629fcb02c55cb1cd58b9df015e21ae6fb6ee6349954aaa7658cc580490 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/c67653629fcb02c55cb1cd58b9df015e21ae6fb6ee6349954aaa7658cc580490/userdata -p /var/run/containers/storage/overlay-containers/c67653629fcb02c55cb1cd58b9df015e21ae6fb6ee6349954aaa7658cc580490/userdata/pidfile -l /var/log/pods/5364adac-6fa2-11e9-966c-7ca23e90ca35/c67653629fcb02c55cb1cd58b9df015e21ae6fb6ee6349954aaa7658cc580490.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root       2638  0.0  0.0   2740   996 ?        Ssl  May06   0:01  \_ /usr/bin/pod
root       2614  0.0  0.0  85896   832 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c 48925881c4d1b08841d5e59e317395e5e357f98946649319c23ac65013e8af31 -u 48925881c4d1b08841d5e59e317395e5e357f98946649319c23ac65013e8af31 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/48925881c4d1b08841d5e59e317395e5e357f98946649319c23ac65013e8af31/userdata -p /var/run/containers/storage/overlay-containers/48925881c4d1b08841d5e59e317395e5e357f98946649319c23ac65013e8af31/userdata/pidfile -l /var/log/pods/53636c60-6fa2-11e9-966c-7ca23e90ca35/48925881c4d1b08841d5e59e317395e5e357f98946649319c23ac65013e8af31.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root       2645  0.0  0.0   2740   996 ?        Ssl  May06   0:01  \_ /usr/bin/pod
root       2623  0.0  0.0  85896   880 ?        Ssl  May06   0:01 /usr/libexec/crio/conmon -s -c 077a8dd7cb467effe217bbeb04fbd19591140da83f3c06e279b0716727a0ff37 -u 077a8dd7cb467effe217bbeb04fbd19591140da83f3c06e279b0716727a0ff37 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/077a8dd7cb467effe217bbeb04fbd19591140da83f3c06e279b0716727a0ff37/userdata -p /var/run/containers/storage/overlay-containers/077a8dd7cb467effe217bbeb04fbd19591140da83f3c06e279b0716727a0ff37/userdata/pidfile -l /var/log/pods/536301a9-6fa2-11e9-966c-7ca23e90ca35/sync/0.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root       2663  0.0  0.0  13208  3000 ?        Ss   May06   1:37  \_ /bin/bash -c #!/bin/bash set -euo pipefail  # set by the node image unset KUBECONFIG  trap 'kill $(jobs -p); exit 0' TERM  # track the current state of the config if [[ -f /etc/origin/node/node-config.yaml ]]; then   md5sum /etc/origin/node/node-config.yaml > /tmp/.old else   touch /tmp/.old fi  if [[ -f /etc/origin/node/volume-config.yaml ]]; then   md5sum /etc/origin/node/volume-config.yaml > /tmp/.old-volume.config else   touch /tmp/.old-volume-config fi  # loop until BOOTSTRAP_CONFIG_NAME is set while true; do   file=/etc/sysconfig/origin-node   if [[ -f /etc/sysconfig/atomic-openshift-node ]]; then     file=/etc/sysconfig/atomic-openshift-node   elif [[ -f /etc/sysconfig/origin-node ]]; then     file=/etc/sysconfig/origin-node   else     echo "info: Waiting for the node sysconfig file to be created" 2>&1     sleep 15 & wait     continue   fi   name="$(sed -nE 's|^BOOTSTRAP_CONFIG_NAME=([^#].+)|\1|p' "${file}" | head -1)"   if [[ -z "${name}" ]]; then     echo "info: Waiting for BOOTSTRAP_CONFIG_NAME to be set" 2>&1     sleep 15 & wait     continue   fi   # in the background check to see if the value changes and exit if so   pid=$BASHPID   (     while true; do       if ! updated="$(sed -nE 's|^BOOTSTRAP_CONFIG_NAME=([^#].+)|\1|p' "${file}" | head -1)"; then         echo "error: Unable to check for bootstrap config, exiting" 2>&1         kill $pid         exit 1       fi       if [[ "${updated}" != "${name}" ]]; then         echo "info: Bootstrap configuration profile name changed, exiting" 2>&1         kill $pid         exit 0       fi       sleep 15     done   ) &   break done mkdir -p /etc/origin/node/tmp # periodically refresh both node-config.yaml and relabel the node while true; do   if ! oc extract "configmaps/${name}" -n openshift-node --to=/etc/origin/node/tmp --confirm --request-timeout=10s --config /etc/origin/node/node.kubeconfig "--token=$( cat /var/run/secrets/kubernetes.io/serviceaccount/token )"  > /dev/null; then     echo "error: Unable to retrieve latest config for node" 2>&1     sleep 15 &     wait $!     continue   fi    KUBELET_HOSTNAME_OVERRIDE=$(cat /etc/sysconfig/KUBELET_HOSTNAME_OVERRIDE 2>/dev/null) || :   if ! [[ -z "$KUBELET_HOSTNAME_OVERRIDE" ]]; then         #Patching node-config for hostname override         echo "nodeName: $KUBELET_HOSTNAME_OVERRIDE" >> /etc/origin/node/tmp/node-config.yaml   fi    # detect whether the node-config.yaml has changed, and if so trigger a restart of the kubelet.   if [[ ! -f /etc/origin/node/node-config.yaml ]]; then     cat /dev/null > /tmp/.old   fi    if [[ ! -f /etc/origin/node/volume-config.yaml ]]; then     cat /dev/null > /tmp/.old-volume-config   fi    md5sum /etc/origin/node/tmp/node-config.yaml > /tmp/.new    if [[ ! -f /etc/origin/node/tmp/volume-config.yaml ]]; then     cat /dev/null > /tmp/.new-volume-config   else     md5sum /etc/origin/node/tmp/volume-config.yaml > /tmp/.new-volume-config   fi    trigger_restart=false   if [[ "$( cat /tmp/.old )" != "$( cat /tmp/.new )" ]]; then     mv /etc/origin/node/tmp/node-config.yaml /etc/origin/node/node-config.yaml     trigger_restart=true   fi    if [[ "$( cat /tmp/.old-volume-config )" != "$( cat /tmp/.new-volume-config )" ]]; then     mv /etc/origin/node/tmp/volume-config.yaml /etc/origin/node/volume-config.yaml     trigger_restart=true   fi      if [[ "$trigger_restart" = true ]]; then     SYSTEMD_IGNORE_CHROOT=1 systemctl restart tuned || :     echo "info: Configuration changed, restarting kubelet" 2>&1     # TODO: kubelet doesn't relabel nodes, best effort for now     # https://github.com/kubernetes/kubernetes/issues/59314     if args="$(openshift-node-config --config /etc/origin/node/node-config.yaml)"; then       labels=$(tr ' ' '\n' <<<$args | sed -ne '/^--node-labels=/ { s/^--node-labels=//; p; }' | tr ',\n' ' ')       if [[ -n "${labels}" ]]; then         echo "info: Applying node labels $labels" 2>&1         if ! oc label --config=/etc/origin/node/node.kubeconfig "node/${NODE_NAME}" ${labels} --overwrite; then           echo "error: Unable to apply labels, will retry in 10" 2>&1           sleep 10 &           wait $!           continue         fi       fi     else       echo "error: The downloaded node configuration is invalid, retrying later" 2>&1       sleep 10 &       wait $!       continue     fi     if ! pkill -U 0 -f '(^|/)hyperkube kubelet '; then       echo "error: Unable to restart Kubelet" 2>&1       sleep 10 &       wait $!       continue     fi   fi   # annotate node with md5sum of the config   oc annotate --config=/etc/origin/node/node.kubeconfig "node/${NODE_NAME}" \     node.openshift.io/md5sum="$( cat /tmp/.new | cut -d' ' -f1 )" --overwrite   cp -f /tmp/.new /tmp/.old   cp -f /tmp/.new-volume-config /tmp/.old-volume-config   sleep 180 &   wait $! done 
root       2751  0.0  0.0  13360  2484 ?        S    May06   3:12      \_ /bin/bash -c #!/bin/bash set -euo pipefail  # set by the node image unset KUBECONFIG  trap 'kill $(jobs -p); exit 0' TERM  # track the current state of the config if [[ -f /etc/origin/node/node-config.yaml ]]; then   md5sum /etc/origin/node/node-config.yaml > /tmp/.old else   touch /tmp/.old fi  if [[ -f /etc/origin/node/volume-config.yaml ]]; then   md5sum /etc/origin/node/volume-config.yaml > /tmp/.old-volume.config else   touch /tmp/.old-volume-config fi  # loop until BOOTSTRAP_CONFIG_NAME is set while true; do   file=/etc/sysconfig/origin-node   if [[ -f /etc/sysconfig/atomic-openshift-node ]]; then     file=/etc/sysconfig/atomic-openshift-node   elif [[ -f /etc/sysconfig/origin-node ]]; then     file=/etc/sysconfig/origin-node   else     echo "info: Waiting for the node sysconfig file to be created" 2>&1     sleep 15 & wait     continue   fi   name="$(sed -nE 's|^BOOTSTRAP_CONFIG_NAME=([^#].+)|\1|p' "${file}" | head -1)"   if [[ -z "${name}" ]]; then     echo "info: Waiting for BOOTSTRAP_CONFIG_NAME to be set" 2>&1     sleep 15 & wait     continue   fi   # in the background check to see if the value changes and exit if so   pid=$BASHPID   (     while true; do       if ! updated="$(sed -nE 's|^BOOTSTRAP_CONFIG_NAME=([^#].+)|\1|p' "${file}" | head -1)"; then         echo "error: Unable to check for bootstrap config, exiting" 2>&1         kill $pid         exit 1       fi       if [[ "${updated}" != "${name}" ]]; then         echo "info: Bootstrap configuration profile name changed, exiting" 2>&1         kill $pid         exit 0       fi       sleep 15     done   ) &   break done mkdir -p /etc/origin/node/tmp # periodically refresh both node-config.yaml and relabel the node while true; do   if ! oc extract "configmaps/${name}" -n openshift-node --to=/etc/origin/node/tmp --confirm --request-timeout=10s --config /etc/origin/node/node.kubeconfig "--token=$( cat /var/run/secrets/kubernetes.io/serviceaccount/token )"  > /dev/null; then     echo "error: Unable to retrieve latest config for node" 2>&1     sleep 15 &     wait $!     continue   fi    KUBELET_HOSTNAME_OVERRIDE=$(cat /etc/sysconfig/KUBELET_HOSTNAME_OVERRIDE 2>/dev/null) || :   if ! [[ -z "$KUBELET_HOSTNAME_OVERRIDE" ]]; then         #Patching node-config for hostname override         echo "nodeName: $KUBELET_HOSTNAME_OVERRIDE" >> /etc/origin/node/tmp/node-config.yaml   fi    # detect whether the node-config.yaml has changed, and if so trigger a restart of the kubelet.   if [[ ! -f /etc/origin/node/node-config.yaml ]]; then     cat /dev/null > /tmp/.old   fi    if [[ ! -f /etc/origin/node/volume-config.yaml ]]; then     cat /dev/null > /tmp/.old-volume-config   fi    md5sum /etc/origin/node/tmp/node-config.yaml > /tmp/.new    if [[ ! -f /etc/origin/node/tmp/volume-config.yaml ]]; then     cat /dev/null > /tmp/.new-volume-config   else     md5sum /etc/origin/node/tmp/volume-config.yaml > /tmp/.new-volume-config   fi    trigger_restart=false   if [[ "$( cat /tmp/.old )" != "$( cat /tmp/.new )" ]]; then     mv /etc/origin/node/tmp/node-config.yaml /etc/origin/node/node-config.yaml     trigger_restart=true   fi    if [[ "$( cat /tmp/.old-volume-config )" != "$( cat /tmp/.new-volume-config )" ]]; then     mv /etc/origin/node/tmp/volume-config.yaml /etc/origin/node/volume-config.yaml     trigger_restart=true   fi      if [[ "$trigger_restart" = true ]]; then     SYSTEMD_IGNORE_CHROOT=1 systemctl restart tuned || :     echo "info: Configuration changed, restarting kubelet" 2>&1     # TODO: kubelet doesn't relabel nodes, best effort for now     # https://github.com/kubernetes/kubernetes/issues/59314     if args="$(openshift-node-config --config /etc/origin/node/node-config.yaml)"; then       labels=$(tr ' ' '\n' <<<$args | sed -ne '/^--node-labels=/ { s/^--node-labels=//; p; }' | tr ',\n' ' ')       if [[ -n "${labels}" ]]; then         echo "info: Applying node labels $labels" 2>&1         if ! oc label --config=/etc/origin/node/node.kubeconfig "node/${NODE_NAME}" ${labels} --overwrite; then           echo "error: Unable to apply labels, will retry in 10" 2>&1           sleep 10 &           wait $!           continue         fi       fi     else       echo "error: The downloaded node configuration is invalid, retrying later" 2>&1       sleep 10 &       wait $!       continue     fi     if ! pkill -U 0 -f '(^|/)hyperkube kubelet '; then       echo "error: Unable to restart Kubelet" 2>&1       sleep 10 &       wait $!       continue     fi   fi   # annotate node with md5sum of the config   oc annotate --config=/etc/origin/node/node.kubeconfig "node/${NODE_NAME}" \     node.openshift.io/md5sum="$( cat /tmp/.new | cut -d' ' -f1 )" --overwrite   cp -f /tmp/.new /tmp/.old   cp -f /tmp/.new-volume-config /tmp/.old-volume-config   sleep 180 &   wait $! done 
root      20549  0.0  0.0   4360   356 ?        S    16:31   0:00      |   \_ sleep 15
root      20508  0.0  0.0   4360   356 ?        S    16:31   0:00      \_ sleep 180
root       2760  0.0  0.0  85896   880 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c 156c94ca3094ef7245d6709255ed7032b4c5babac4227c28dcb5c399c0440564 -u 156c94ca3094ef7245d6709255ed7032b4c5babac4227c28dcb5c399c0440564 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/156c94ca3094ef7245d6709255ed7032b4c5babac4227c28dcb5c399c0440564/userdata -p /var/run/containers/storage/overlay-containers/156c94ca3094ef7245d6709255ed7032b4c5babac4227c28dcb5c399c0440564/userdata/pidfile -l /var/log/pods/53636c60-6fa2-11e9-966c-7ca23e90ca35/sdn/0.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root       2807  0.6  0.0 2745372 103812 ?      Ssl  May06 163:49  \_ openshift start network --config=/etc/origin/node/node-config.yaml --kubeconfig=/tmp/kubeconfig --loglevel=2
root       2773  0.0  0.0  85896   872 ?        Ssl  May06   0:01 /usr/libexec/crio/conmon -s -c 3346bf00edf3d83c51f0d19808be74980072a0fb1a4fbc3b2578de23a1d4efe2 -u 3346bf00edf3d83c51f0d19808be74980072a0fb1a4fbc3b2578de23a1d4efe2 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/3346bf00edf3d83c51f0d19808be74980072a0fb1a4fbc3b2578de23a1d4efe2/userdata -p /var/run/containers/storage/overlay-containers/3346bf00edf3d83c51f0d19808be74980072a0fb1a4fbc3b2578de23a1d4efe2/userdata/pidfile -l /var/log/pods/5364adac-6fa2-11e9-966c-7ca23e90ca35/openvswitch/0.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root       2828  0.0  0.0  14848  4704 ?        Ss   May06   4:34  \_ /bin/bash -c #!/bin/bash set -euo pipefail  # if another process is listening on the cni-server socket, wait until it exits trap 'kill $(jobs -p); exit 0' TERM retries=0 while true; do   if /usr/share/openvswitch/scripts/ovs-ctl status &>/dev/null; then     echo "warning: Another process is currently managing OVS, waiting 15s ..." 2>&1     sleep 15 & wait     (( retries += 1 ))   else     break   fi   if [[ "${retries}" -gt 40 ]]; then     echo "error: Another process is currently managing OVS, exiting" 2>&1     exit 1   fi done  # launch OVS function quit {     /usr/share/openvswitch/scripts/ovs-ctl stop     exit 0 } trap quit SIGTERM /usr/share/openvswitch/scripts/ovs-ctl start --no-ovs-vswitchd --system-id=random  # Restrict the number of pthreads ovs-vswitchd creates to reduce the # amount of RSS it uses on hosts with many cores # https://bugzilla.redhat.com/show_bug.cgi?id=1571379 # https://bugzilla.redhat.com/show_bug.cgi?id=1572797 if [[ `nproc` -gt 12 ]]; then     ovs-vsctl --no-wait set Open_vSwitch . other_config:n-revalidator-threads=4     ovs-vsctl --no-wait set Open_vSwitch . other_config:n-handler-threads=10 fi /usr/share/openvswitch/scripts/ovs-ctl start --no-ovsdb-server --system-id=random  tail --follow=name /var/log/openvswitch/ovs-vswitchd.log /var/log/openvswitch/ovsdb-server.log & sleep 20 while true; do   if ! /usr/share/openvswitch/scripts/ovs-ctl status &>/dev/null; then     echo "OVS seems to have crashed, exiting"     quit   fi   sleep 15 done 
root       2995  0.0  0.0   4400   616 ?        S    May06   0:01  |   \_ tail --follow=name /var/log/openvswitch/ovs-vswitchd.log /var/log/openvswitch/ovsdb-server.log
root      20887  0.0  0.0   4360   360 ?        S    16:32   0:00  |   \_ sleep 15
root       2945  0.0  0.0  52608   860 ?        S<s  May06   0:00  \_ ovsdb-server: monitoring pid 2946 (healthy)
root       2946  0.0  0.0  53488  3384 ?        S<   May06   6:07  |   \_ ovsdb-server /etc/openvswitch/conf.db -vconsole:emer -vsyslog:err -vfile:info --remote=punix:/var/run/openvswitch/db.sock --private-key=db:Open_vSwitch,SSL,private_key --certificate=db:Open_vSwitch,SSL,certificate --bootstrap-ca-cert=db:Open_vSwitch,SSL,ca_cert --no-chdir --log-file=/var/log/openvswitch/ovsdb-server.log --pidfile=/var/run/openvswitch/ovsdb-server.pid --detach --monitor
root       2984  0.0  0.0  73632  3136 ?        S<s  May06   0:00  \_ ovs-vswitchd: monitoring pid 2985 (healthy)
root       2985  0.3  0.0 1180756 143264 ?      S<Ll May06 104:05      \_ ovs-vswitchd unix:/var/run/openvswitch/db.sock -vconsole:emer -vsyslog:err -vfile:info --mlockall --no-chdir --log-file=/var/log/openvswitch/ovs-vswitchd.log --pidfile=/var/run/openvswitch/ovs-vswitchd.pid --detach --monitor
root       3038  0.0  0.0 574188 17352 ?        Ssl  May06   2:37 /usr/bin/python2 -Es /usr/sbin/tuned -l -P
root       3280  5.4  0.0 6452124 172080 ?      Ssl  May06 1432:51 /usr/bin/hyperkube kubelet --v=2 --address=0.0.0.0 --allow-privileged=true --anonymous-auth=true --authentication-token-webhook=true --authentication-token-webhook-cache-ttl=5m --authorization-mode=Webhook --authorization-webhook-cache-authorized-ttl=5m --authorization-webhook-cache-unauthorized-ttl=5m --bootstrap-kubeconfig=/etc/origin/node/bootstrap.kubeconfig --cadvisor-port=0 --cert-dir=/etc/origin/node/certificates --cgroup-driver=systemd --client-ca-file=/etc/origin/node/client-ca.crt --cluster-dns=192.168.39.152 --cluster-domain=cluster.local --container-runtime=remote --container-runtime-endpoint=/var/run/crio/crio.sock --containerized=false --enable-controller-attach-detach=true --experimental-dockershim-root-directory=/var/lib/dockershim --fail-swap-on=false --feature-gates=RotateKubeletClientCertificate=true,RotateKubeletServerCertificate=true --healthz-bind-address= --healthz-port=0 --host-ipc-sources=api --host-ipc-sources=file --host-network-sources=api --host-network-sources=file --host-pid-sources=api --host-pid-sources=file --hostname-override= --http-check-frequency=0s --image-service-endpoint=/var/run/crio/crio.sock --iptables-masquerade-bit=0 --kubeconfig=/etc/origin/node/node.kubeconfig --max-pods=250 --network-plugin=cni --node-ip= --node-labels=node-role.kubernetes.io/compute=true,runtime=cri-o --pod-infra-container-image=kni-registry.redhat.ren:5021/openshift3/ose-pod:v3.11.98 --pod-manifest-path=/etc/origin/node/pods --port=10250 --read-only-port=0 --register-node=true --root-dir=/var/lib/origin/openshift.local.volumes --rotate-certificates=true --rotate-server-certificates=true --runtime-request-timeout=10m --tls-cert-file= --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305 --tls-cipher-suites=TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256 --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA --tls-cipher-suites=TLS_RSA_WITH_AES_128_GCM_SHA256 --tls-cipher-suites=TLS_RSA_WITH_AES_256_GCM_SHA384 --tls-cipher-suites=TLS_RSA_WITH_AES_128_CBC_SHA --tls-cipher-suites=TLS_RSA_WITH_AES_256_CBC_SHA --tls-min-version=VersionTLS12 --tls-private-key-file=
root       7845  0.0  0.0  85896   832 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c 6e0ee056695d6fb6298982f8ad056ee8d52624d97a1e4e28b02a26089db25947 -u 6e0ee056695d6fb6298982f8ad056ee8d52624d97a1e4e28b02a26089db25947 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/6e0ee056695d6fb6298982f8ad056ee8d52624d97a1e4e28b02a26089db25947/userdata -p /var/run/containers/storage/overlay-containers/6e0ee056695d6fb6298982f8ad056ee8d52624d97a1e4e28b02a26089db25947/userdata/pidfile -l /var/log/pods/07344c23-6fa3-11e9-966c-7ca23e90ca35/6e0ee056695d6fb6298982f8ad056ee8d52624d97a1e4e28b02a26089db25947.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root       7859  0.0  0.0   2740   996 ?        Ssl  May06   0:00  \_ /usr/bin/pod
root       7925  0.0  0.0  85896   884 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c 25a0a6a00e571934f179147bf339adac10ce115efccdd4c14143fb63749388de -u 25a0a6a00e571934f179147bf339adac10ce115efccdd4c14143fb63749388de -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/25a0a6a00e571934f179147bf339adac10ce115efccdd4c14143fb63749388de/userdata -p /var/run/containers/storage/overlay-containers/25a0a6a00e571934f179147bf339adac10ce115efccdd4c14143fb63749388de/userdata/pidfile -l /var/log/pods/07344c23-6fa3-11e9-966c-7ca23e90ca35/glusterblock-provisioner/0.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
1000110+   7937  0.0  0.0 2843016 31940 ?       Ssl  May06   2:50  \_ /usr/bin/glusterblock-provisioner
root       9962  0.0  0.0  85896   832 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c 53f8aa02e93b8cedb731dcec076d271d556a041dabfb8d202fff5d761ad6b879 -u 53f8aa02e93b8cedb731dcec076d271d556a041dabfb8d202fff5d761ad6b879 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/53f8aa02e93b8cedb731dcec076d271d556a041dabfb8d202fff5d761ad6b879/userdata -p /var/run/containers/storage/overlay-containers/53f8aa02e93b8cedb731dcec076d271d556a041dabfb8d202fff5d761ad6b879/userdata/pidfile -l /var/log/pods/5fd5ea6a-6fa3-11e9-966c-7ca23e90ca35/53f8aa02e93b8cedb731dcec076d271d556a041dabfb8d202fff5d761ad6b879.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root       9976  0.0  0.0   2740   992 ?        Ssl  May06   0:01  \_ /usr/bin/pod
root      10051  0.0  0.0  85896   940 ?        Ssl  May06   0:05 /usr/libexec/crio/conmon -s -c 236b7b5ed0982ec1324ed48dff93ab975fcc212e638f4d06bf6a947285c44823 -u 236b7b5ed0982ec1324ed48dff93ab975fcc212e638f4d06bf6a947285c44823 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/236b7b5ed0982ec1324ed48dff93ab975fcc212e638f4d06bf6a947285c44823/userdata -p /var/run/containers/storage/overlay-containers/236b7b5ed0982ec1324ed48dff93ab975fcc212e638f4d06bf6a947285c44823/userdata/pidfile -l /var/log/pods/5fd5ea6a-6fa3-11e9-966c-7ca23e90ca35/dockergc/0.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      10063  0.0  0.0 2509080 60348 ?       Ssl  May06   6:41  \_ /usr/bin/oc ex dockergc --image-gc-low-threshold=60 --image-gc-high-threshold=80 --minimum-ttl-duration=1h0m0s
root      12860  0.0  0.0  85896   828 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c e5eb6e55aaf4abf7a490c6b2e33cf24ce9e1451393653e1055fb59da7e8d09d6 -u e5eb6e55aaf4abf7a490c6b2e33cf24ce9e1451393653e1055fb59da7e8d09d6 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/e5eb6e55aaf4abf7a490c6b2e33cf24ce9e1451393653e1055fb59da7e8d09d6/userdata -p /var/run/containers/storage/overlay-containers/e5eb6e55aaf4abf7a490c6b2e33cf24ce9e1451393653e1055fb59da7e8d09d6/userdata/pidfile -l /var/log/pods/d1f53872-6fa3-11e9-966c-7ca23e90ca35/e5eb6e55aaf4abf7a490c6b2e33cf24ce9e1451393653e1055fb59da7e8d09d6.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      12874  0.0  0.0   2740   992 ?        Ssl  May06   0:01  \_ /usr/bin/pod
root      12930  0.0  0.0  85896   884 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c b72e0ce076b8c0e5aa4dee7b92ae2368754964c8ab94076b0079cf38c64864a7 -u b72e0ce076b8c0e5aa4dee7b92ae2368754964c8ab94076b0079cf38c64864a7 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/b72e0ce076b8c0e5aa4dee7b92ae2368754964c8ab94076b0079cf38c64864a7/userdata -p /var/run/containers/storage/overlay-containers/b72e0ce076b8c0e5aa4dee7b92ae2368754964c8ab94076b0079cf38c64864a7/userdata/pidfile -l /var/log/pods/d1f53872-6fa3-11e9-966c-7ca23e90ca35/node-exporter/0.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
nobody    12942  0.4  0.0 2569840 38612 ?       Ssl  May06 122:48  \_ /bin/node_exporter --web.listen-address=127.0.0.1:9101 --path.procfs=/host/proc --path.sysfs=/host/sys --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/) --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$ --no-collector.wifi
root      13046  0.0  0.0  85896   888 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c b8de53d164cc07d785030b31122c1bb151f169cbd9f06eb28a36f23a34692af5 -u b8de53d164cc07d785030b31122c1bb151f169cbd9f06eb28a36f23a34692af5 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/b8de53d164cc07d785030b31122c1bb151f169cbd9f06eb28a36f23a34692af5/userdata -p /var/run/containers/storage/overlay-containers/b8de53d164cc07d785030b31122c1bb151f169cbd9f06eb28a36f23a34692af5/userdata/pidfile -l /var/log/pods/d1f53872-6fa3-11e9-966c-7ca23e90ca35/kube-rbac-proxy/0.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
nobody    13059  0.0  0.0  41764 17196 ?        Ssl  May06   4:05  \_ /usr/bin/kube-rbac-proxy --secure-listen-address=:9100 --upstream=http://127.0.0.1:9101/ --tls-cert-file=/etc/tls/private/tls.crt --tls-private-key-file=/etc/tls/private/tls.key --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
root      17431  0.0  0.0  85896   832 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c 8b8269d4f581a8a8b7f5bf34014fa86040dfcea31faa11768bdc6fa7514d6810 -u 8b8269d4f581a8a8b7f5bf34014fa86040dfcea31faa11768bdc6fa7514d6810 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/8b8269d4f581a8a8b7f5bf34014fa86040dfcea31faa11768bdc6fa7514d6810/userdata -p /var/run/containers/storage/overlay-containers/8b8269d4f581a8a8b7f5bf34014fa86040dfcea31faa11768bdc6fa7514d6810/userdata/pidfile -l /var/log/pods/90635e8b-6fa4-11e9-966c-7ca23e90ca35/8b8269d4f581a8a8b7f5bf34014fa86040dfcea31faa11768bdc6fa7514d6810.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      17446  0.0  0.0   2740   992 ?        Ssl  May06   0:01  \_ /usr/bin/pod
root      17607  0.0  0.0  85896   880 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c b55b00e9034a494a28586a80ff46a78684f0155e55ad9448761a1fadb2bb4884 -u b55b00e9034a494a28586a80ff46a78684f0155e55ad9448761a1fadb2bb4884 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/b55b00e9034a494a28586a80ff46a78684f0155e55ad9448761a1fadb2bb4884/userdata -p /var/run/containers/storage/overlay-containers/b55b00e9034a494a28586a80ff46a78684f0155e55ad9448761a1fadb2bb4884/userdata/pidfile -l /var/log/pods/90635e8b-6fa4-11e9-966c-7ca23e90ca35/fluentd-elasticsearch/0.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      17619  0.1  0.2 1199992 600968 ?      Ssl  May06  33:50  \_ /usr/bin/ruby /usr/bin/fluentd --no-supervisor
root      86009  0.0  0.0  85896   828 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c 51f55ba22b51d4a84425ce46c71c533ef8bc73a8295dd4b8f675b688c0007e9e -u 51f55ba22b51d4a84425ce46c71c533ef8bc73a8295dd4b8f675b688c0007e9e -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/51f55ba22b51d4a84425ce46c71c533ef8bc73a8295dd4b8f675b688c0007e9e/userdata -p /var/run/containers/storage/overlay-containers/51f55ba22b51d4a84425ce46c71c533ef8bc73a8295dd4b8f675b688c0007e9e/userdata/pidfile -l /var/log/pods/1c874570-6fcd-11e9-966c-7ca23e90ca35/51f55ba22b51d4a84425ce46c71c533ef8bc73a8295dd4b8f675b688c0007e9e.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      86035  0.0  0.0   2740   996 ?        Ssl  May06   0:01  \_ /usr/bin/pod
root      86020  0.0  0.0  85896   832 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c e55adcfa6b66cb75bbc32d4b550a294915b84902eb7a601ca7156d1c0c61374c -u e55adcfa6b66cb75bbc32d4b550a294915b84902eb7a601ca7156d1c0c61374c -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/e55adcfa6b66cb75bbc32d4b550a294915b84902eb7a601ca7156d1c0c61374c/userdata -p /var/run/containers/storage/overlay-containers/e55adcfa6b66cb75bbc32d4b550a294915b84902eb7a601ca7156d1c0c61374c/userdata/pidfile -l /var/log/pods/1c96f5d5-6fcd-11e9-966c-7ca23e90ca35/e55adcfa6b66cb75bbc32d4b550a294915b84902eb7a601ca7156d1c0c61374c.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      86042  0.0  0.0   2740   988 ?        Ssl  May06   0:01  \_ /usr/bin/pod
root      86108  0.0  0.0  85896   828 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c 15e1ccf237d9e9d279b3dcb6e358e119161d0ffd3536fdc2f1c05c87607e727c -u 15e1ccf237d9e9d279b3dcb6e358e119161d0ffd3536fdc2f1c05c87607e727c -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/15e1ccf237d9e9d279b3dcb6e358e119161d0ffd3536fdc2f1c05c87607e727c/userdata -p /var/run/containers/storage/overlay-containers/15e1ccf237d9e9d279b3dcb6e358e119161d0ffd3536fdc2f1c05c87607e727c/userdata/pidfile -l /var/log/pods/1d24d18b-6fcd-11e9-966c-7ca23e90ca35/15e1ccf237d9e9d279b3dcb6e358e119161d0ffd3536fdc2f1c05c87607e727c.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      86141  0.0  0.0   2740   996 ?        Ssl  May06   0:01  \_ /usr/bin/pod
root      86442  0.0  0.0  85896   828 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c e17cb594639dae5b99cde74bbbf6dd323c02bb574c7c81c08b7aeeb82875fd00 -u e17cb594639dae5b99cde74bbbf6dd323c02bb574c7c81c08b7aeeb82875fd00 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/e17cb594639dae5b99cde74bbbf6dd323c02bb574c7c81c08b7aeeb82875fd00/userdata -p /var/run/containers/storage/overlay-containers/e17cb594639dae5b99cde74bbbf6dd323c02bb574c7c81c08b7aeeb82875fd00/userdata/pidfile -l /var/log/pods/1c874570-6fcd-11e9-966c-7ca23e90ca35/kube-ovs-cni-plugin-amd64/0.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      86455  0.0  0.0  11680  1380 ?        Ss   May06   0:00  \_ sh -c cp /usr/src/ovs-cni/bin/ovs /host/opt/cni/bin/ovs && sleep infinity
root      86491  0.0  0.0   4360   360 ?        S    May06   0:00      \_ sleep infinity
root      86515  0.0  0.0  85896   876 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c 35cb2f13ac2bac636271893d7005ea0e0118575b86bd8f72e1a031051d4d501b -u 35cb2f13ac2bac636271893d7005ea0e0118575b86bd8f72e1a031051d4d501b -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/35cb2f13ac2bac636271893d7005ea0e0118575b86bd8f72e1a031051d4d501b/userdata -p /var/run/containers/storage/overlay-containers/35cb2f13ac2bac636271893d7005ea0e0118575b86bd8f72e1a031051d4d501b/userdata/pidfile -l /var/log/pods/1c96f5d5-6fcd-11e9-966c-7ca23e90ca35/kube-multus/0.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      86529  0.0  0.0  11684  1524 ?        Ss   May06   0:00  \_ /bin/bash /entrypoint.sh --multus-conf-file=/usr/src/multus-cni/images/00-multus.conf
root      86586  0.0  0.0   4360   360 ?        S    May06   0:00      \_ sleep infinity
root      86843  0.0  0.0  85896   832 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c 8edc2d137219588de57be8b1ddea7c1f7d3b3844251bd6407fdb1caff50968d1 -u 8edc2d137219588de57be8b1ddea7c1f7d3b3844251bd6407fdb1caff50968d1 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/8edc2d137219588de57be8b1ddea7c1f7d3b3844251bd6407fdb1caff50968d1/userdata -p /var/run/containers/storage/overlay-containers/8edc2d137219588de57be8b1ddea7c1f7d3b3844251bd6407fdb1caff50968d1/userdata/pidfile -l /var/log/pods/32241dce-6fcd-11e9-966c-7ca23e90ca35/8edc2d137219588de57be8b1ddea7c1f7d3b3844251bd6407fdb1caff50968d1.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      86880  0.0  0.0   2740   992 ?        Ssl  May06   0:00  \_ /usr/bin/pod
root      86852  0.0  0.0  85896   828 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c 6bf176fd2d78c5ffb62984872f9511e7dcca7b70142c07e12e39dea5b6cbb1a5 -u 6bf176fd2d78c5ffb62984872f9511e7dcca7b70142c07e12e39dea5b6cbb1a5 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/6bf176fd2d78c5ffb62984872f9511e7dcca7b70142c07e12e39dea5b6cbb1a5/userdata -p /var/run/containers/storage/overlay-containers/6bf176fd2d78c5ffb62984872f9511e7dcca7b70142c07e12e39dea5b6cbb1a5/userdata/pidfile -l /var/log/pods/322289ad-6fcd-11e9-966c-7ca23e90ca35/6bf176fd2d78c5ffb62984872f9511e7dcca7b70142c07e12e39dea5b6cbb1a5.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      86891  0.0  0.0   2740   996 ?        Ssl  May06   0:01  \_ /usr/bin/pod
root      86861  0.0  0.0  85896   824 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c f4fbb25b2a9a67d42af4436262e9606e239b1a0679a0649c8cd667462955c977 -u f4fbb25b2a9a67d42af4436262e9606e239b1a0679a0649c8cd667462955c977 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/f4fbb25b2a9a67d42af4436262e9606e239b1a0679a0649c8cd667462955c977/userdata -p /var/run/containers/storage/overlay-containers/f4fbb25b2a9a67d42af4436262e9606e239b1a0679a0649c8cd667462955c977/userdata/pidfile -l /var/log/pods/3224def4-6fcd-11e9-966c-7ca23e90ca35/f4fbb25b2a9a67d42af4436262e9606e239b1a0679a0649c8cd667462955c977.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      86902  0.0  0.0   2740   996 ?        Ssl  May06   0:01  \_ /usr/bin/pod
root      87360  0.0  0.0  85896   884 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c c06c0d543e797d1bb3b3ea30d824367dae8ec01939cab629b02ee54db0e8954f -u c06c0d543e797d1bb3b3ea30d824367dae8ec01939cab629b02ee54db0e8954f -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/c06c0d543e797d1bb3b3ea30d824367dae8ec01939cab629b02ee54db0e8954f/userdata -p /var/run/containers/storage/overlay-containers/c06c0d543e797d1bb3b3ea30d824367dae8ec01939cab629b02ee54db0e8954f/userdata/pidfile -l /var/log/pods/3224def4-6fcd-11e9-966c-7ca23e90ca35/virt-handler/0.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      87372  0.3  0.0 2979016 53804 ?       Ssl  May06  83:32  \_ virt-handler --port 8443 --hostname-override kni-node4.redhat.ren --pod-ip-address 10.244.8.11 -v 2
root      87702  0.0  0.0  85896   948 ?        Ssl  May06   0:22 /usr/libexec/crio/conmon -s -c 6ffcd6908c6888407612bb3089407e245872f0301fbf45c087a2afb017f278e0 -u 6ffcd6908c6888407612bb3089407e245872f0301fbf45c087a2afb017f278e0 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/6ffcd6908c6888407612bb3089407e245872f0301fbf45c087a2afb017f278e0/userdata -p /var/run/containers/storage/overlay-containers/6ffcd6908c6888407612bb3089407e245872f0301fbf45c087a2afb017f278e0/userdata/pidfile -l /var/log/pods/322289ad-6fcd-11e9-966c-7ca23e90ca35/virt-api/0.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
1000320+  87714  0.3  0.0 2823520 89908 ?       Ssl  May06  85:30  \_ virt-api --port 8443 --subresources-only -v 2
root      88332  0.0  0.0  85896   832 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c fe4d2b63bf52000db52efd7caf987ab00a7c3fbb5199160445bbcc86003c42d4 -u fe4d2b63bf52000db52efd7caf987ab00a7c3fbb5199160445bbcc86003c42d4 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/fe4d2b63bf52000db52efd7caf987ab00a7c3fbb5199160445bbcc86003c42d4/userdata -p /var/run/containers/storage/overlay-containers/fe4d2b63bf52000db52efd7caf987ab00a7c3fbb5199160445bbcc86003c42d4/userdata/pidfile -l /var/log/pods/5119dbba-6fcd-11e9-966c-7ca23e90ca35/fe4d2b63bf52000db52efd7caf987ab00a7c3fbb5199160445bbcc86003c42d4.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      88346  0.0  0.0   2740   992 ?        Ssl  May06   0:01  \_ /usr/bin/pod
root      88800  0.0  0.0  85896   884 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c 2b01236ae5da24bc1192b6647bdbcf52c54c96bdd72b39617cac22a389d6786e -u 2b01236ae5da24bc1192b6647bdbcf52c54c96bdd72b39617cac22a389d6786e -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/2b01236ae5da24bc1192b6647bdbcf52c54c96bdd72b39617cac22a389d6786e/userdata -p /var/run/containers/storage/overlay-containers/2b01236ae5da24bc1192b6647bdbcf52c54c96bdd72b39617cac22a389d6786e/userdata/pidfile -l /var/log/pods/5119dbba-6fcd-11e9-966c-7ca23e90ca35/kubevirt-web-ui-operator/0.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      88812  0.3  0.0 3048544 37112 ?       Ssl  May06  80:54  \_ kubevirt-web-ui-operator
root      90474  0.0  0.0  85896   832 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c 5cf3cf8b8b82996cead94e981161f0954177c62b77d1c36e4bc04d3728c5fbd9 -u 5cf3cf8b8b82996cead94e981161f0954177c62b77d1c36e4bc04d3728c5fbd9 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/5cf3cf8b8b82996cead94e981161f0954177c62b77d1c36e4bc04d3728c5fbd9/userdata -p /var/run/containers/storage/overlay-containers/5cf3cf8b8b82996cead94e981161f0954177c62b77d1c36e4bc04d3728c5fbd9/userdata/pidfile -l /var/log/pods/815e29ae-6fcd-11e9-966c-7ca23e90ca35/5cf3cf8b8b82996cead94e981161f0954177c62b77d1c36e4bc04d3728c5fbd9.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      90489  0.0  0.0   2740   992 ?        Ssl  May06   0:00  \_ /usr/bin/pod
root      90745  0.0  0.0  85896   952 ?        Ssl  May06   2:16 /usr/libexec/crio/conmon -s -c d927850f266ce39995f9e47b5347bba0781ed48ad1fce9667909c43689a1a208 -u d927850f266ce39995f9e47b5347bba0781ed48ad1fce9667909c43689a1a208 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/d927850f266ce39995f9e47b5347bba0781ed48ad1fce9667909c43689a1a208/userdata -p /var/run/containers/storage/overlay-containers/d927850f266ce39995f9e47b5347bba0781ed48ad1fce9667909c43689a1a208/userdata/pidfile -l /var/log/pods/815e29ae-6fcd-11e9-966c-7ca23e90ca35/cdi-apiserver/0.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
1000370+  90757  0.0  0.0 2755112 34108 ?       Ssl  May06  20:25  \_ /usr/bin/virt-cdi-apiserver -alsologtostderr -v=1
root      91104  0.0  0.0  85896   828 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c 50c345a2173e80d6091d9e562b0559cec5835f6a6f9bec9e938edfe475de0cb2 -u 50c345a2173e80d6091d9e562b0559cec5835f6a6f9bec9e938edfe475de0cb2 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/50c345a2173e80d6091d9e562b0559cec5835f6a6f9bec9e938edfe475de0cb2/userdata -p /var/run/containers/storage/overlay-containers/50c345a2173e80d6091d9e562b0559cec5835f6a6f9bec9e938edfe475de0cb2/userdata/pidfile -l /var/log/pods/91dd1793-6fcd-11e9-966c-7ca23e90ca35/50c345a2173e80d6091d9e562b0559cec5835f6a6f9bec9e938edfe475de0cb2.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      91118  0.0  0.0   2740   996 ?        Ssl  May06   0:01  \_ /usr/bin/pod
root      92027  0.0  0.0  85896   832 ?        Ssl  May06   0:00 /usr/libexec/crio/conmon -s -c 8c8cc2d3523f37b1d5f733741e044aed7c1736557ff44a1c0f808737b1653184 -u 8c8cc2d3523f37b1d5f733741e044aed7c1736557ff44a1c0f808737b1653184 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/8c8cc2d3523f37b1d5f733741e044aed7c1736557ff44a1c0f808737b1653184/userdata -p /var/run/containers/storage/overlay-containers/8c8cc2d3523f37b1d5f733741e044aed7c1736557ff44a1c0f808737b1653184/userdata/pidfile -l /var/log/pods/91dd1793-6fcd-11e9-966c-7ca23e90ca35/kubevirt-cpu-node-labeller-sleeper/0.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      92039  0.0  0.0   4360   360 ?        Ss   May06   0:00  \_ sleep infinity
root      64778  0.0  0.0 148768   732 ?        Ss   May13   0:00 /usr/sbin/glusterfs --log-level=ERROR --log-file=/var/lib/origin/openshift.local.volumes/plugins/kubernetes.io/glusterfs/pvc-3c98362c-746d-11e9-83a9-7ca23e90ca35/virt-launcher-win7-2hhh5-glusterfs.log --fuse-mountopts=auto_unmount --volfile-server=192.168.39.32 --volfile-server=192.168.39.32 --volfile-server=192.168.39.33 --volfile-server=192.168.39.34 --volfile-id=vol_8267a29e4e95d1f58080541b8160b6ba --fuse-mountopts=auto_unmount /var/lib/origin/openshift.local.volumes/pods/2c616815-7557-11e9-83a9-7ca23e90ca35/volumes/kubernetes.io~glusterfs/pvc-3c98362c-746d-11e9-83a9-7ca23e90ca35
root      64779  0.0  0.0 614184 25068 ?        Ssl  May13   5:38 /usr/sbin/glusterfs --log-level=ERROR --log-file=/var/lib/origin/openshift.local.volumes/plugins/kubernetes.io/glusterfs/pvc-3c98362c-746d-11e9-83a9-7ca23e90ca35/virt-launcher-win7-2hhh5-glusterfs.log --fuse-mountopts=auto_unmount --volfile-server=192.168.39.32 --volfile-server=192.168.39.32 --volfile-server=192.168.39.33 --volfile-server=192.168.39.34 --volfile-id=vol_8267a29e4e95d1f58080541b8160b6ba --fuse-mountopts=auto_unmount /var/lib/origin/openshift.local.volumes/pods/2c616815-7557-11e9-83a9-7ca23e90ca35/volumes/kubernetes.io~glusterfs/pvc-3c98362c-746d-11e9-83a9-7ca23e90ca35
root      64795  0.0  0.0  85896   832 ?        Ssl  May13   0:00 /usr/libexec/crio/conmon -s -c a98c7fa4f8acf380112aa9545aebcbdd1ce429698c293e05ff8ccf5abb1249eb -u a98c7fa4f8acf380112aa9545aebcbdd1ce429698c293e05ff8ccf5abb1249eb -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/a98c7fa4f8acf380112aa9545aebcbdd1ce429698c293e05ff8ccf5abb1249eb/userdata -p /var/run/containers/storage/overlay-containers/a98c7fa4f8acf380112aa9545aebcbdd1ce429698c293e05ff8ccf5abb1249eb/userdata/pidfile -l /var/log/pods/2c616815-7557-11e9-83a9-7ca23e90ca35/a98c7fa4f8acf380112aa9545aebcbdd1ce429698c293e05ff8ccf5abb1249eb.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      64808  0.0  0.0   2740   992 ?        Ssl  May13   0:00  \_ /usr/bin/pod
root      65692  0.0  0.0  85896   884 ?        Ssl  May13   0:00 /usr/libexec/crio/conmon -s -c 4038d5f421e10e6acd4c6f8d96ea2556779bb6a837a2a0fecdfe5e60f3c51d69 -u 4038d5f421e10e6acd4c6f8d96ea2556779bb6a837a2a0fecdfe5e60f3c51d69 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/4038d5f421e10e6acd4c6f8d96ea2556779bb6a837a2a0fecdfe5e60f3c51d69/userdata -p /var/run/containers/storage/overlay-containers/4038d5f421e10e6acd4c6f8d96ea2556779bb6a837a2a0fecdfe5e60f3c51d69/userdata/pidfile -l /var/log/pods/2c616815-7557-11e9-83a9-7ca23e90ca35/volumeinstallcd/0.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      65708  0.0  0.0  13940  1696 ?        Ss   May13   1:12  \_ /bin/bash /entry-point.sh
root      21019  0.0  0.0  22952   936 ?        S    16:32   0:00      \_ /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 5
root      65783  0.0  0.0  85896   876 ?        Ssl  May13   0:00 /usr/libexec/crio/conmon -s -c bfcdf55247c7a9415777fe9bcf9238e554ea975e5b016815e4275fb5397e1ba7 -u bfcdf55247c7a9415777fe9bcf9238e554ea975e5b016815e4275fb5397e1ba7 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/bfcdf55247c7a9415777fe9bcf9238e554ea975e5b016815e4275fb5397e1ba7/userdata -p /var/run/containers/storage/overlay-containers/bfcdf55247c7a9415777fe9bcf9238e554ea975e5b016815e4275fb5397e1ba7/userdata/pidfile -l /var/log/pods/2c616815-7557-11e9-83a9-7ca23e90ca35/volumevirtiocontainerdisk/0.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      65806  0.0  0.0  14888  4712 ?        Ss   May13   2:40  \_ /bin/bash /entry-point.sh
root      21125  0.0  0.0   4364   364 ?        S    16:32   0:00      \_ sleep 5
root      65877  0.0  0.0  85896   880 ?        Ssl  May13   0:03 /usr/libexec/crio/conmon -s -c f95c2be21b43dc17c7d243a51a35009452f5dbd81260329a8d63da8674b0264d -u f95c2be21b43dc17c7d243a51a35009452f5dbd81260329a8d63da8674b0264d -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/f95c2be21b43dc17c7d243a51a35009452f5dbd81260329a8d63da8674b0264d/userdata -p /var/run/containers/storage/overlay-containers/f95c2be21b43dc17c7d243a51a35009452f5dbd81260329a8d63da8674b0264d/userdata/pidfile -l /var/log/pods/2c616815-7557-11e9-83a9-7ca23e90ca35/compute/0.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
root      65889  0.0  0.0 2797040 45360 ?       Ssl  May13   1:44  \_ /usr/bin/virt-launcher --qemu-timeout 5m --name win7 --uid 2c5f2902-7557-11e9-83a9-7ca23e90ca35 --namespace default --kubevirt-share-dir /var/run/kubevirt --ephemeral-disk-dir /var/run/kubevirt-ephemeral-disks --readiness-file /var/run/kubevirt-infra/healthy --grace-period-seconds 15 --hook-sidecars 0 --less-pvc-space-toleration 10
root      65963  0.0  0.0 5365856 58376 ?       Sl   May13   9:40      \_ /usr/bin/virt-launcher --qemu-timeout 5m --name win7 --uid 2c5f2902-7557-11e9-83a9-7ca23e90ca35 --namespace default --kubevirt-share-dir /var/run/kubevirt --ephemeral-disk-dir /var/run/kubevirt-ephemeral-disks --readiness-file /var/run/kubevirt-infra/healthy --grace-period-seconds 15 --hook-sidecars 0 --less-pvc-space-toleration 10 --no-fork true
root      65991  0.0  0.0 122396  4252 ?        S    May13   0:00      |   \_ /usr/sbin/virtlogd -f /etc/libvirt/virtlogd.conf
root      65992  0.0  0.0 1426692 16316 ?       Sl   May13   0:45      |   \_ /usr/sbin/libvirtd
107       66989  2.1  1.4 4831276 3892744 ?     Sl   May13 340:22      \_ /usr/libexec/qemu-kvm -name guest=default_win7,debug-threads=on -S -object secret,id=masterKey0,format=raw,file=/var/lib/libvirt/qemu/domain-1-default_win7/master-key.aes -machine pc-q35-rhel7.6.0,accel=kvm,usb=off,dump-guest-core=off -cpu IvyBridge-IBRS,ss=on,pcid=on,hypervisor=on,arat=on,tsc_adjust=on,stibp=on,ssbd=on,xsaveopt=on,pdpe1gb=on,hv_time,hv_relaxed,hv_vapic,hv_spinlocks=0x1fff -m 3815 -realtime mlock=off -smp 2,sockets=1,cores=2,threads=1 -object iothread,id=iothread1 -uuid f08c781b-a2b4-5cbe-9017-c4f68d8bf981 -no-user-config -nodefaults -chardev socket,id=charmonitor,fd=24,server,nowait -mon chardev=charmonitor,id=monitor,mode=control -rtc base=utc,driftfix=slew -global kvm-pit.lost_tick_policy=delay -no-hpet -no-shutdown -boot strict=on -device pcie-root-port,port=0x10,chassis=1,id=pci.1,bus=pcie.0,multifunction=on,addr=0x2 -device pcie-root-port,port=0x11,chassis=2,id=pci.2,bus=pcie.0,addr=0x2.0x1 -device pcie-root-port,port=0x12,chassis=3,id=pci.3,bus=pcie.0,addr=0x2.0x2 -device virtio-serial-pci,id=virtio-serial0,bus=pci.2,addr=0x0 -drive file=/var/run/kubevirt-ephemeral-disks/container-disk-data/default/win7/disk_installcd/disk-image.raw,format=raw,if=none,id=drive-ua-installcd,media=cdrom,readonly=on,cache=none -device ide-cd,bus=ide.0,drive=drive-ua-installcd,id=ua-installcd,bootindex=2,write-cache=on -drive file=/var/run/kubevirt-private/vmi-disks/win7-kni/disk.img,format=raw,if=none,id=drive-ua-win7-kni,cache=none -device ide-hd,bus=ide.1,drive=drive-ua-win7-kni,id=ua-win7-kni,bootindex=1,write-cache=on -drive file=/var/run/kubevirt-ephemeral-disks/container-disk-data/default/win7/disk_virtiocontainerdisk/disk-image.raw,format=raw,if=none,id=drive-ua-virtiocontainerdisk,media=cdrom,readonly=on,cache=none -device ide-cd,bus=ide.2,drive=drive-ua-virtiocontainerdisk,id=ua-virtiocontainerdisk,write-cache=on -netdev tap,fd=26,id=hostua-nic0 -device e1000e,netdev=hostua-nic0,id=ua-nic0,mac=0a:58:0a:f4:08:68,bus=pci.1,addr=0x0 -chardev socket,id=charserial0,fd=27,server,nowait -device isa-serial,chardev=charserial0,id=serial0 -chardev socket,id=charchannel0,fd=28,server,nowait -device virtserialport,bus=virtio-serial0.0,nr=1,chardev=charchannel0,id=channel0,name=org.qemu.guest_agent.0 -vnc vnc=unix:/var/run/kubevirt-private/2c5f2902-7557-11e9-83a9-7ca23e90ca35/virt-vnc -device VGA,id=video0,vgamem_mb=16,bus=pcie.0,addr=0x1 -sandbox on,obsolete=deny,elevateprivileges=deny,spawn=deny,resourcecontrol=deny -msg timestamp=on
root      46799  0.0  0.0  85896   884 ?        Ssl  May14   0:00 /usr/libexec/crio/conmon -s -c 23f7365f00199c89f8fe78871a92d1fface49afa9f27f33d3b8c3fe494da3b32 -u 23f7365f00199c89f8fe78871a92d1fface49afa9f27f33d3b8c3fe494da3b32 -r /usr/bin/runc -b /var/run/containers/storage/overlay-containers/23f7365f00199c89f8fe78871a92d1fface49afa9f27f33d3b8c3fe494da3b32/userdata -p /var/run/containers/storage/overlay-containers/23f7365f00199c89f8fe78871a92d1fface49afa9f27f33d3b8c3fe494da3b32/userdata/pidfile -l /var/log/pods/32241dce-6fcd-11e9-966c-7ca23e90ca35/virt-controller/12.log --exit-dir /var/run/crio/exits --socket-dir-path /var/run/crio --log-level error --log-size-max 52428800
1000320+  46839  0.1  0.0 2805792 48536 ?       Ssl  May14  24:44  \_ virt-controller --launcher-image kni-registry.redhat.ren:5021/cnv-tech-preview/virt-launcher:latest --port 8443 -v 2

<!DOCTYPE HTML>
<html lang="zh" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>IPI模式 单节点 离线 单网络模式 安装 - OpenShift4 慢慢走</title>
                

        <!-- Custom HTML head -->
        <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-E3FRMDB7L2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-E3FRMDB7L2');
</script>

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

                <link rel="icon" href="../../favicon.svg">
                        <link rel="shortcut icon" href="../../favicon.png">
                <link rel="stylesheet" href="../../css/variables.css">
        <link rel="stylesheet" href="../../css/general.css">
        <link rel="stylesheet" href="../../css/chrome.css">
                <link rel="stylesheet" href="../../css/print.css" media="print">
        
        <!-- Fonts -->
        <link rel="stylesheet" href="../../FontAwesome/css/font-awesome.css">
                <link rel="stylesheet" href="../../fonts/fonts.css">
        
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../highlight.css">
        <link rel="stylesheet" href="../../tomorrow-night.css">
        <link rel="stylesheet" href="../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        
            </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../../index.html">介绍</a></li><li class="chapter-item expanded "><a href="../../install.html"><strong aria-hidden="true">1.</strong> openshift4 安装系列</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.ocp.pull.secret.html"><strong aria-hidden="true">1.1.</strong> 如何获得 openshift4 免费下载密钥</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.build.dist.html"><strong aria-hidden="true">1.2.</strong> openshift4 离线安装介质的制作</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.sno.static.ip.local.assisted.connected.html"><strong aria-hidden="true">1.3.</strong> assisted install 联线模式下 单节点ocp 无需dhcp 静态ip部署</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.sno.static.ip.local.assisted.disconnected.html"><strong aria-hidden="true">1.4.</strong> assisted install 离线模式下 单节点ocp 无需dhcp 静态ip部署</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.disconnect.bm.upi.static.ip.on.rhel7.html"><strong aria-hidden="true">1.5.</strong> openshift4 rhel7物理机 baremetal UPI模式 离线安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.disconnect.bm.upi.static.ip.on.rhel8.html"><strong aria-hidden="true">1.6.</strong> openshift4 rhel8物理机 baremetal UPI模式 离线安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.disconnect.bm.ipi.on.rhel8.html"><strong aria-hidden="true">1.7.</strong> openshift4 物理机 baremetal IPI模式 离线安装 单网络模式</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.disconnect.bm.ipi.on.rhel8.provisionning.network.html"><strong aria-hidden="true">1.8.</strong> openshift4 物理机 baremetal IPI模式 离线安装 双网络模式</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.cilium.html"><strong aria-hidden="true">1.9.</strong> openshift4 尝鲜 cilium CNI</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.nvidia.gpu.disconnected.html"><strong aria-hidden="true">1.10.</strong> nvidia gpu for openshift 4.6 disconnected 英伟达GPU离线安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.add.image.html"><strong aria-hidden="true">1.11.</strong> openshift4 初始安装后 补充镜像</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.is.sample.html"><strong aria-hidden="true">1.12.</strong> openshift4 补充samples operator 需要的 image stream</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.calico.html"><strong aria-hidden="true">1.13.</strong> openshift4 calico 离线部署</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.2/4.2.upgrade.html"><strong aria-hidden="true">1.14.</strong> openshift4 集群升级</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.shrink.sysroot.html"><strong aria-hidden="true">1.15.</strong> 缩小根分区 / sysroot 的大小</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.update.service.html"><strong aria-hidden="true">1.16.</strong> 部署升级服务 完善离线升级功能</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.windows.node.html"><strong aria-hidden="true">1.17.</strong> 添加 win10 worker 节点</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.sno.using.bootstrap.disconnected.html"><strong aria-hidden="true">1.18.</strong> 单节点ocp 安装 无需dhcp 静态ip部署</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.disconnect.bm.ipi.sno.static.ip.html" class="active"><strong aria-hidden="true">1.19.</strong> IPI模式 单节点 离线 单网络模式 安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.acm.ztp.disconnected.auto.html"><strong aria-hidden="true">1.20.</strong> ACM zero touch provision 远程单节点集群 全自动安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.coreos.boot.html"><strong aria-hidden="true">1.21.</strong> coreos 启动和分区挂载分析</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.installer.html"><strong aria-hidden="true">1.22.</strong> openshift4 单节点 命令行安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.partition.quay.html"><strong aria-hidden="true">1.23.</strong> openshift4 单节点 在第一块硬盘上添加更多分区</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.nfs.lvm.html"><strong aria-hidden="true">1.24.</strong> openshift4 单节点 使用 lvm 和 nfs 在集群内提供存储</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.boot.from.linux.html"><strong aria-hidden="true">1.25.</strong> openshift4 单节点 从centos7/8 开始安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.odf.html"><strong aria-hidden="true">1.26.</strong> openshift4 单节点 安装精简版 ODF/ceph</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.replace.coreos.html"><strong aria-hidden="true">1.27.</strong> 定制 rhcos</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.rpm-ostree.install.html"><strong aria-hidden="true">1.28.</strong> rhcos 里面安装 rpm</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.component.version.html"><strong aria-hidden="true">1.29.</strong> openshift 4 组件版本</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.embeded.dns.haproxy.registry.html"><strong aria-hidden="true">1.30.</strong> 内嵌 dns, haproxy, registrty</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.replace.coreos.rhel.9.0.html"><strong aria-hidden="true">1.31.</strong> 升级 openshift 4.10 内核到 rhel 9.1 支持 海光 x86 cpu</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.11/4.11.acm.hypershift.html"><strong aria-hidden="true">1.32.</strong> 使用 hypershift 安装控制面托管的 openshift 集群</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.12/4.12.3node.upi.agent.html"><strong aria-hidden="true">1.33.</strong> 使用 agent based installer 安装 3 节点集群</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.12/4.12.single.node.upi.agent.html"><strong aria-hidden="true">1.34.</strong> 使用 agent based installer 安装 单节点集群</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.12/4.12.ocp.driver.build.html"><strong aria-hidden="true">1.35.</strong> 在 openshift 内部编译内核驱动 rpm 并使用</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.12/4.12.demo.lab.html"><strong aria-hidden="true">1.36.</strong> how to build an openshift 4.12 demo lab from scratch</a></li></ol></li><li class="chapter-item expanded "><a href="../../usage.html"><strong aria-hidden="true">2.</strong> openshift4 使用系列</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.11/4.11.3node.ipi.for.osp.prod.html"><strong aria-hidden="true">2.1.</strong> 在 openshift 4.11 上安装和运行 openstack</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.flexran.20.11.pf.deploy.html"><strong aria-hidden="true">2.2.</strong> 在openshift4上运行 OpenRAN 无线基站应用</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.netflow.table.html"><strong aria-hidden="true">2.3.</strong> openshift4 可视化 ovs netflow</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.flexran.20.11.html"><strong aria-hidden="true">2.4.</strong> intel o-ran flexran 方案在openshift4上的安装和使用</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.ci.cd.demo.html"><strong aria-hidden="true">2.5.</strong> ci/cd pipeline gitops演示</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.oc.exec.html"><strong aria-hidden="true">2.6.</strong> oc/kubectl exec 原理分析</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.nf.conntrack.html"><strong aria-hidden="true">2.7.</strong> nf_conntrack 在 openshift4.9上的处理</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.load.3rd.part.driver.html"><strong aria-hidden="true">2.8.</strong> 加载第三方设备驱动</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.nep.containerized.helm.html"><strong aria-hidden="true">2.9.</strong> helm chart/helm operator</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.metalb.l2.html"><strong aria-hidden="true">2.10.</strong> 使用 MetalLB 用 Layer2 发布 LoadBalancer</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.metalb.html"><strong aria-hidden="true">2.11.</strong> 使用 MetalLB 用 BGP 发布 LoadBalancer</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.kata.html"><strong aria-hidden="true">2.12.</strong> kata / 沙盒容器</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.sriov.html"><strong aria-hidden="true">2.13.</strong> 在非官方支持的网卡上，测试SRIOV/DPDK</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.keepalived.operator.html"><strong aria-hidden="true">2.14.</strong> 使用 keepalived 激活 LoadBalancer 服务类型</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.real-time.kernel.html"><strong aria-hidden="true">2.15.</strong> 在节点上启用实时操作系统 real-time kernel</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.install.kmod.driver.html"><strong aria-hidden="true">2.16.</strong> 从容器向宿主机注入内核模块 kmod / driver</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.vgpu.sharing.deploy.html"><strong aria-hidden="true">2.17.</strong> GPU/vGPU 共享</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.4/4.4.headless.service.html"><strong aria-hidden="true">2.18.</strong> openshift headless service讲解</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.volumn.html"><strong aria-hidden="true">2.19.</strong> openshift volumn 存储的各种测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.SupportPodPidsLimit.html"><strong aria-hidden="true">2.20.</strong> openshift 设置 SupportPodPidsLimit 解除 pids 限制</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.sso.html"><strong aria-hidden="true">2.21.</strong> openshift4 配置 SSO 点单认证</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.scc.html"><strong aria-hidden="true">2.22.</strong> openshift4 SCC 相关安全能力测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.recover.node.not.ready.html"><strong aria-hidden="true">2.23.</strong> openshift4 从 node not ready 状态恢复</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.QoS.nic.html"><strong aria-hidden="true">2.24.</strong> openshift4 QoS 能力</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.QoS.nic.high.html"><strong aria-hidden="true">2.25.</strong> openshift4 QoS 在流量压力下的表现</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.proxy.html"><strong aria-hidden="true">2.26.</strong> openshift4 使用 image proxy 来下载镜像</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.numa.html"><strong aria-hidden="true">2.27.</strong> openshift4 NUMA 绑核测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.network.policy.html"><strong aria-hidden="true">2.28.</strong> openshift4 Network Policy 测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.multicast.html"><strong aria-hidden="true">2.29.</strong> openshift4 网络多播 测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.firewall.html"><strong aria-hidden="true">2.30.</strong> openshift4 配置节点防火墙</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.ldap.html"><strong aria-hidden="true">2.31.</strong> openshift4 集成 ldap</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.image.pull.html"><strong aria-hidden="true">2.32.</strong> openshift4 维护 image pull secret</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.huge.page.html"><strong aria-hidden="true">2.33.</strong> openshift4 使用大页内存 huge page</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.helm.html"><strong aria-hidden="true">2.34.</strong> openshift4 使用 helm</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.haproxy.html"><strong aria-hidden="true">2.35.</strong> openshift4 定制router 支持 TCP ingress</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.grafana.html"><strong aria-hidden="true">2.36.</strong> openshift4 监控能力展示 grafana</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.cpu.manager.html"><strong aria-hidden="true">2.37.</strong> openshift4 CPU 绑核 测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.build.config.html"><strong aria-hidden="true">2.38.</strong> openshift4 build config &amp; hpa 自动化编译和自动扩缩容</a></li></ol></li><li class="chapter-item expanded "><a href="../../ccn.html"><strong aria-hidden="true">3.</strong> 应用上云系列教程 CCN</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.4/4.4.ccn.devops.deploy.html"><strong aria-hidden="true">3.1.</strong> 应用上云系列教程 containerized cloud native (CCN) for openshift 4.4</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.4/4.4.ccn.devops.build.html"><strong aria-hidden="true">3.2.</strong> CCN 安装介质制作 for openshift 4.4</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.ccn.devops.deploy.html"><strong aria-hidden="true">3.3.</strong> 应用上云系列教程 containerized cloud native (CCN) for openshift 4.6</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.ccn.devops.build.html"><strong aria-hidden="true">3.4.</strong> CCN 安装介质制作 for openshift 4.6</a></li></ol></li><li class="chapter-item expanded "><a href="../../rh.cloud.html"><strong aria-hidden="true">4.</strong> 红帽其他产品系列</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.acm.observ.html"><strong aria-hidden="true">4.1.</strong> ACM observability for openshift 4.10</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.01.ansible.install.html"><strong aria-hidden="true">4.2.</strong> 离线安装 ansible platform</a></li><li class="chapter-item expanded "><a href="../../notes/2021/2021.08.virus.html"><strong aria-hidden="true">4.3.</strong> RHACS 应对log4j 原理和实践</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.ocp.ocs.cnv.ceph.html"><strong aria-hidden="true">4.4.</strong> openshift承载虚拟化业务(CNV)</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.rhacs.html"><strong aria-hidden="true">4.5.</strong> RHACS / stackrox</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.rhacs.deep.html"><strong aria-hidden="true">4.6.</strong> 为 RHACS 找个应用场景: 安全合规测试云 </a></li></ol></li><li class="chapter-item expanded "><a href="../../os.html"><strong aria-hidden="true">5.</strong> 操作系统相关</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../notes/2023/satellite.demo.html"><strong aria-hidden="true">5.1.</strong> satellite 红帽注册和内容分发代理</a></li><li class="chapter-item expanded "><a href="../../notes/2023/rhel.subscription.register.html"><strong aria-hidden="true">5.2.</strong> RHEL 订阅在线注册相关问题</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.12.boot.to.install.html"><strong aria-hidden="true">5.3.</strong> 通过新增系统启动项来原地重装操作系统</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.04.os.backup.ReaR.html"><strong aria-hidden="true">5.4.</strong> Relax and Recover(ReaR) 系统备份和灾难恢复</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.04.no-cost.rhel.sub.html"><strong aria-hidden="true">5.5.</strong> 红帽免费的开发者订阅申请和使用</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.01.rpm.belongs.html"><strong aria-hidden="true">5.6.</strong> 在红帽官网查询rpm属于哪个repo</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.01.rhel7.upgrade.to.rhel8.html"><strong aria-hidden="true">5.7.</strong> 离线环境下 原地升级 rhel7-&gt;rhel8</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.01.sysctl.html"><strong aria-hidden="true">5.8.</strong> 系统启动自动加载sysctl配置</a></li><li class="chapter-item expanded "><a href="../../notes/2021/2021.12.ocp.bf2.dpi.url.filter.html"><strong aria-hidden="true">5.9.</strong> Mellanox BF2 刷固件并测试DPI URL-filter场景</a></li><li class="chapter-item expanded "><a href="../../notes/2021/2021.11.bf2.snap.try.html"><strong aria-hidden="true">5.10.</strong> Mellanox BF2 网卡激活snap功能，配置nvme over fabrics 支持</a></li><li class="chapter-item expanded "><a href="../../notes/2021/2021.10.cx6dx.vdpa.offload.html"><strong aria-hidden="true">5.11.</strong> Mellanox CX6 vdpa 硬件卸载 ovs-kernel 方式</a></li><li class="chapter-item expanded "><a href="../../rhel/rhel.build.kernel.html"><strong aria-hidden="true">5.12.</strong> RHEL8编译定制化内核</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.check.whether.vm.html"><strong aria-hidden="true">5.13.</strong> 检查OS是否是运行在虚拟机上</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.4/4.4.ovs.html"><strong aria-hidden="true">5.14.</strong> 两个主机用ovs组网</a></li></ol></li><li class="chapter-item expanded "><a href="../../workshop.html"><strong aria-hidden="true">6.</strong> 优秀的workshop</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.ocp.ocs.workshop.html"><strong aria-hidden="true">6.1.</strong> openshift4 &amp; openshift storage workshop</a></li></ol></li><li class="chapter-item expanded "><a href="../../poc.html"><strong aria-hidden="true">7.</strong> POC</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.3/poc.sc/install.poc.sc.html"><strong aria-hidden="true">7.1.</strong> 2020.04 某次POC openshift LVM调优</a></li></ol></li><li class="chapter-item expanded "><a href="../../osx.html"><strong aria-hidden="true">8.</strong> OSX使用技巧</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../osx/osx.record.system.audio.html"><strong aria-hidden="true">8.1.</strong> 如何录制系统声音</a></li></ol></li></ol>            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                                                <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                                            </div>

                    <h1 class="menu-title">OpenShift4 慢慢走</h1>

                    <div class="right-buttons">
                                                <a href="../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                                                                        <a href="https://github.com/wangzheng422/docker_env" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                                                                        <a href="https://github.com/wangzheng422/docker_env/blob/dev/redhat/ocp4/4.10/4.10.disconnect.bm.ipi.sno.static.ip.md" title="Suggest an edit" aria-label="Suggest an edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>
                        
                    </div>
                </div>

                                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="openshift-410-离线-baremetal-ipi-全自动安装-单网络-静态ip模式"><a class="header" href="#openshift-410-离线-baremetal-ipi-全自动安装-单网络-静态ip模式">openshift 4.10 离线 baremetal IPI (全自动)安装 单网络 静态IP模式</a></h1>
<h2 id="简介"><a class="header" href="#简介">简介</a></h2>
<p><a href="https://www.bilibili.com/video/BV1Q94y1d7cU/"><kbd><img src="imgs/20220414212727.png" width="600"></kbd></a></p>
<ul>
<li><a href="https://www.bilibili.com/video/BV1Q94y1d7cU/">bilibili</a></li>
<li><a href="https://www.youtube.com/watch?v=SR4-8Xxejw8">youtube</a></li>
</ul>
<p>本文描述ocp4.10在baremetal(kvm模拟)上面，IPI (全自动)安装。由于4.10支持nmstat，所以他原生支持静态IP安装了。</p>
<p>根据openshift文档，baremetal IPI安装有两种模式，一种是provisioning网络独立，另外一种是provisioning网络和baremetal(服务)网络合并的模式。考虑到POC现场的环境，本次实验，使用简单的网络部署，也就是合并的网络模式。</p>
<p>以下是本次实验的架构图:</p>
<p><img src="./dia/4.10.bm.ipi.sno.static.ip.drawio.svg" alt="" /></p>
<p>注意：本文使用single node (sno) 模式，并使用 IPI (全自动) 安装，这种模式官方是不支持的，我们这么做，是为了后续的ACM zero touch provision 实验， ZTP实验，需要ACM hub集群是IPI模式安装，而我们做实验资源紧张，所以我们搞了一个sno with IPI 模式的安装步骤。本文中有一些手动执行的步骤，都是因为官方IPI不支持sno，我们需要做一些小小的patch操作。</p>
<h2 id="离线安装包下载"><a class="header" href="#离线安装包下载">离线安装包下载</a></h2>
<p>打包好的安装包，在这里下载，百度盘下载链接，版本是4.10.4:</p>
<p>链接：https://pan.baidu.com/s/16H8goM8AQ5ASXXPsWT4GAg?pwd=426x 
提取码：426x </p>
<p>其中包括如下类型的文件：</p>
<ul>
<li>ocp4.tgz  这个文件包含了iso等安装介质，以及各种安装脚本，全部下载的镜像列表等。需要复制到宿主机，以及工具机上去。</li>
<li>registry.tgz  这个文件也是docker image registry的仓库打包文件。需要先补充镜像的话，按照这里操作: <a href="./4.6.add.image.html">4.6.add.image.md</a></li>
<li>nexus-image.tgz 这个是nexus的镜像仓库打包，集群的镜像proxy指向nexus，由nexus提供镜像的cache</li>
<li>poc.image.tgz 这个是给registry.tgz补充的一些镜像，主要是ccn使用，补充的镜像列表在这里 <a href="./ccn/poc.image.list">poc.image.list</a> ，按照这里操作: <a href="./4.6.add.image.html">4.6.add.image.md</a></li>
</ul>
<p>合并这些切分文件，使用类似如下的命令</p>
<pre><code class="language-bash">cat registry.?? &gt; registry.tgz
</code></pre>
<p>注意，可能需要更新离线镜像包中的helper用的ansible脚本。</p>
<h2 id="在外网云主机上面准备离线安装源"><a class="header" href="#在外网云主机上面准备离线安装源">在外网云主机上面准备离线安装源</a></h2>
<p>准备离线安装介质的文档，已经转移到了这里：<a href="./4.10.build.dist.html">4.10.build.dist.md</a></p>
<h1 id="前期准备主要在宿主机上"><a class="header" href="#前期准备主要在宿主机上">前期准备，主要在宿主机上</a></h1>
<p>本次实验，是在一个24C， 128G 的主机上面，用很多个虚拟机安装测试。所以先准备这个宿主机。</p>
<p>如果是多台宿主机，记得一定要调整时间配置，让这些宿主机的时间基本一致，否则证书会出问题。</p>
<p>主要的准备工作有</p>
<ul>
<li>配置yum源</li>
<li>配置dns</li>
<li>安装镜像仓库</li>
<li>配置vnc环境</li>
<li>配置kvm需要的网络</li>
<li>创建helper kvm</li>
</ul>
<p>以上准备工作，dns部分需要根据实际项目环境有所调整。</p>
<p>本次的宿主机是一台rhel8, 参考这里进行离线repo等基本的配置<a href="../../rhel/rhel8.build.kernel.repo.cache.html">rhel8.build.kernel.repo.cache.md</a></p>
<pre><code class="language-bash">cat &lt;&lt; EOF &gt; /root/.ssh/config
StrictHostKeyChecking no
UserKnownHostsFile=/dev/null
EOF

cat &lt;&lt; EOF &gt;&gt;  /etc/hosts
127.0.0.1 registry.ocp4.redhat.ren nexus.ocp4.redhat.ren git.ocp4.redhat.ren
EOF

dnf clean all
dnf repolist

dnf -y install byobu htop jq ipmitool

systemctl disable --now firewalld

# 配置registry
mkdir -p /etc/crts/ &amp;&amp; cd /etc/crts

# https://access.redhat.com/documentation/en-us/red_hat_codeready_workspaces/2.1/html/installation_guide/installing-codeready-workspaces-in-tls-mode-with-self-signed-certificates_crw
openssl genrsa -out /etc/crts/redhat.ren.ca.key 4096
openssl req -x509 \
  -new -nodes \
  -key /etc/crts/redhat.ren.ca.key \
  -sha256 \
  -days 36500 \
  -out /etc/crts/redhat.ren.ca.crt \
  -subj /CN=&quot;Local Red Hat Ren Signer&quot; \
  -reqexts SAN \
  -extensions SAN \
  -config &lt;(cat /etc/pki/tls/openssl.cnf \
      &lt;(printf '[SAN]\nbasicConstraints=critical, CA:TRUE\nkeyUsage=keyCertSign, cRLSign, digitalSignature'))

openssl genrsa -out /etc/crts/redhat.ren.key 2048

openssl req -new -sha256 \
    -key /etc/crts/redhat.ren.key \
    -subj &quot;/O=Local Red Hat Ren /CN=*.ocp4.redhat.ren&quot; \
    -reqexts SAN \
    -config &lt;(cat /etc/pki/tls/openssl.cnf \
        &lt;(printf &quot;\n[SAN]\nsubjectAltName=DNS:*.ocp4.redhat.ren,DNS:*.apps.ocp4.redhat.ren,DNS:*.redhat.ren\nbasicConstraints=critical, CA:FALSE\nkeyUsage=digitalSignature, keyEncipherment, keyAgreement, dataEncipherment\nextendedKeyUsage=serverAuth&quot;)) \
    -out /etc/crts/redhat.ren.csr

openssl x509 \
    -req \
    -sha256 \
    -extfile &lt;(printf &quot;subjectAltName=DNS:*.ocp4.redhat.ren,DNS:*.apps.ocp4.redhat.ren,DNS:*.redhat.ren\nbasicConstraints=critical, CA:FALSE\nkeyUsage=digitalSignature, keyEncipherment, keyAgreement, dataEncipherment\nextendedKeyUsage=serverAuth&quot;) \
    -days 36500 \
    -in /etc/crts/redhat.ren.csr \
    -CA /etc/crts/redhat.ren.ca.crt \
    -CAkey /etc/crts/redhat.ren.ca.key \
    -CAcreateserial -out /etc/crts/redhat.ren.crt

openssl x509 -in /etc/crts/redhat.ren.crt -text

/bin/cp -f /etc/crts/redhat.ren.ca.crt /etc/pki/ca-trust/source/anchors/
update-ca-trust extract

</code></pre>
<h2 id="配置镜像仓库"><a class="header" href="#配置镜像仓库">配置镜像仓库</a></h2>
<p>这里是旧的，使用docker registry的配置镜像仓库的方法，如果想配置quay，可以<a href="../4.9/4.9.ci.cd.demo.html#quay">参考这里</a> 。</p>
<pre><code class="language-bash">cd /data
mkdir -p /data/registry
# tar zxf registry.tgz
dnf -y install podman pigz skopeo jq 
# pigz -dc registry.tgz | tar xf -
cd /data/ocp4
podman load -i /data/ocp4/registry.tgz

podman run --name local-registry -p 5443:5000 \
  -d --restart=always \
  -v /data/registry/:/var/lib/registry:z \
  -v /etc/crts:/certs:z \
  -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/redhat.ren.crt \
  -e REGISTRY_HTTP_TLS_KEY=/certs/redhat.ren.key \
  docker.io/library/registry:2

podman start local-registry

# firewall-cmd --permanent --add-port=5443/tcp
# firewall-cmd --reload

# 加载更多的镜像
# 解压缩 ocp4.tgz
bash add.image.load.sh /data/install.image 'registry.ocp4.redhat.ren:5443'

# https://github.com/christianh814/ocp4-upi-helpernode/blob/master/docs/quickstart.md

oc image mirror -a /data/registry.auth.json --from-dir=/data/file.registry/ 'file://openshift/release:4.10.4-x86_64*' quaylab.infra.redhat.ren/ocp4/openshift4

</code></pre>
<h2 id="准备vnc环境"><a class="header" href="#准备vnc环境">准备vnc环境</a></h2>
<pre><code class="language-bash">vncpasswd

cat &lt;&lt; EOF &gt; ~/.vnc/config
session=gnome
securitytypes=vncauth,tlsvnc
desktop=sandbox
geometry=1440x855
alwaysshared
EOF

cat &lt;&lt; EOF &gt;&gt; /etc/tigervnc/vncserver.users
:1=root
EOF

systemctl start vncserver@:1
# 如果你想停掉vnc server，这么做
systemctl stop vncserver@:1

# firewall-cmd --permanent --add-port=6001/tcp
# firewall-cmd --permanent --add-port=5901/tcp
# firewall-cmd --reload

# connect vnc at port 5901
# export DISPLAY=:1
</code></pre>
<h2 id="创建实验用虚拟网络"><a class="header" href="#创建实验用虚拟网络">创建实验用虚拟网络</a></h2>
<pre><code class="language-bash">cat &lt;&lt; 'EOF' &gt; /data/kvm/bridge.sh
#!/usr/bin/env bash

PUB_CONN='eno1'
PUB_IP='172.21.6.105/24'
PUB_GW='172.21.6.254'
PUB_DNS='172.21.1.1'

nmcli con down &quot;$PUB_CONN&quot;
nmcli con delete &quot;$PUB_CONN&quot;
nmcli con down baremetal
nmcli con delete baremetal
# RHEL 8.1 appends the word &quot;System&quot; in front of the connection,delete in case it exists
nmcli con down &quot;System $PUB_CONN&quot;
nmcli con delete &quot;System $PUB_CONN&quot;
nmcli connection add ifname baremetal type bridge con-name baremetal ipv4.method 'manual' \
    ipv4.address &quot;$PUB_IP&quot; \
    ipv4.gateway &quot;$PUB_GW&quot; \
    ipv4.dns &quot;$PUB_DNS&quot;
    
nmcli con add type bridge-slave ifname &quot;$PUB_CONN&quot; master baremetal
nmcli con down &quot;$PUB_CONN&quot;;pkill dhclient;dhclient baremetal
nmcli con up baremetal
EOF

nmcli con mod baremetal +ipv4.address '192.168.7.1/24'
nmcli networking off; nmcli networking on

</code></pre>
<h2 id="创建工具机"><a class="header" href="#创建工具机">创建工具机</a></h2>
<pre><code class="language-bash">mkdir -p /data/kvm
cd /data/kvm

lvremove -f rhel/helperlv
lvcreate -y -L 200G -n helperlv rhel

virt-install --name=&quot;ocp4-aHelper&quot; --vcpus=2 --ram=4096 \
--disk path=/dev/rhel/helperlv,device=disk,bus=virtio,format=raw \
--os-variant rhel8.0 --network bridge=baremetal,model=virtio \
--boot menu=on --location /data/kvm/rhel-8.3-x86_64-dvd.iso \
--initrd-inject helper-ks-rhel8-ipi.cfg --extra-args &quot;inst.ks=file:/helper-ks-rhel8-ipi.cfg&quot; 

virsh start ocp4-aHelper

# DO NOT USE, restore kvm
virsh destroy ocp4-aHelper
virsh undefine ocp4-aHelper

# virt-viewer --domain-name ocp4-aHelper
# virsh start ocp4-aHelper
# virsh list --all

</code></pre>
<h2 id="配置时间服务"><a class="header" href="#配置时间服务">配置时间服务</a></h2>
<pre><code class="language-bash"># start chrony/ntp server on host
/bin/cp -f /etc/chrony.conf /etc/chrony.conf.default
cat &lt;&lt; EOF &gt; /etc/chrony.conf
# pool 2.rhel.pool.ntp.org iburst
driftfile /var/lib/chrony/drift
makestep 1.0 3
rtcsync
allow 192.0.0.0/8
local stratum 10
logdir /var/log/chrony
EOF
systemctl enable --now chronyd
# systemctl restart chronyd
chronyc tracking
chronyc sources -v
chronyc sourcestats -v
chronyc makestep

# setup ftp data root
mount --bind /data/dnf /var/ftp/dnf
chcon -R -t public_content_t  /var/ftp/dnf

</code></pre>
<h2 id="在helper上配置静态变量"><a class="header" href="#在helper上配置静态变量">在helper上配置静态变量</a></h2>
<p>在 helper / 工具机上，配置静态变量。这些变量，将帮助配置工作可以在不同项目之间复用。后续也许可以考虑把相关的脚本，放到ansible项目里面去。</p>
<pre><code class="language-bash"># on helper define static parameter

NODE_SSH_KEY=&quot;$(cat ~/.ssh/id_rsa.pub)&quot;
INSTALL_IMAGE_REGISTRY=quaylab.infra.redhat.ren

PULL_SECRET='{&quot;auths&quot;:{&quot;registry.redhat.io&quot;: {&quot;auth&quot;: &quot;ZHVtbXk6ZHVtbXk=&quot;,&quot;email&quot;: &quot;noemail@localhost&quot;},&quot;registry.ocp4.redhat.ren:5443&quot;: {&quot;auth&quot;: &quot;ZHVtbXk6ZHVtbXk=&quot;,&quot;email&quot;: &quot;noemail@localhost&quot;},&quot;'${INSTALL_IMAGE_REGISTRY}'&quot;: {&quot;auth&quot;: &quot;'$( echo -n 'quayadmin:password' | openssl base64 )'&quot;,&quot;email&quot;: &quot;noemail@localhost&quot;}}}'

NTP_SERVER=192.168.7.1
HELP_SERVER=192.168.7.11
KVM_HOST=192.168.7.1
API_VIP=192.168.7.100
INGRESS_VIP=192.168.7.101
CLUSTER_PROVISION_IP=192.168.7.103
BOOTSTRAP_IP=192.168.7.12

ACM_DEMO_MNGED_CLUSTER=acm-demo1
ACM_DEMO_MNGED_SNO_IP=192.168.7.15

echo $PULL_SECRET

# 定义单节点集群的节点信息
SNO_CLUSTER_NAME=acm-demo-hub
SNO_BASE_DOMAIN=redhat.ren
SNO_IP=192.168.7.13
SNO_GW=192.168.7.1
SNO_NETMAST=255.255.255.0
SNO_NETMAST_S=24
SNO_HOSTNAME=acm-demo-hub-master
SNO_IF=enp1s0
SNO_IF_MAC=`printf '00:60:2F:%02X:%02X:%02X' $[RANDOM%256] $[RANDOM%256] $[RANDOM%256]`
SNO_DNS=192.168.7.11
SNO_DISK=/dev/vda
SNO_CORE_PWD=redhat

echo ${SNO_IF_MAC} &gt; /data/sno/sno.mac

</code></pre>
<h2 id="创建openshift4集群节点vm模板"><a class="header" href="#创建openshift4集群节点vm模板">创建openshift4集群节点vm模板</a></h2>
<pre><code class="language-bash"># back to kvm host

# create the master and worker vm, but not start them
export KVM_DIRECTORY=/data/kvm
mkdir -p ${KVM_DIRECTORY}
cd ${KVM_DIRECTORY}
# scp root@192.168.7.11:/data/install/*.iso ${KVM_DIRECTORY}/
scp root@192.168.7.11:/data/sno/sno.mac ${KVM_DIRECTORY}/

remove_lv() {
    var_vg=$1
    var_lv=$2
    lvremove -f $var_vg/$var_lv
}

create_lv() {
    var_vg=$1
    var_lv=$2
    lvcreate -y -L 120G -n $var_lv $var_vg
    wipefs --all --force /dev/$var_vg/$var_lv
}

remove_lv vgdata lvacmdemo1
# remove_lv vgdata lvbootstrap
# remove_lv vgdata lvdata01
# remove_lv vgdata lvdata02
remove_lv vgdata lvmaster0
# remove_lv vgdata lvsno

# create_lv rhel bootstraplv
create_lv vgdata lvmaster0

virt-install --name=ocp4-master0 --vcpus=16 --ram=49152 \
--cpu=host-model \
--disk path=/dev/vgdata/lvmaster0,device=disk,bus=virtio,format=raw \
--os-variant rhel8.0 --network bridge=baremetal,model=virtio,mac=$(&lt;sno.mac) \
--boot uefi,nvram_template=/usr/share/OVMF/OVMF_VARS.fd,menu=on  \
--print-xml &gt; ${KVM_DIRECTORY}/ocp4-master0.xml
virsh define --file ${KVM_DIRECTORY}/ocp4-master0.xml

# --boot uefi,nvram_template=/usr/share/OVMF/OVMF_VARS.fd,menu=on  \
# --boot hd,cdrom,menu=on  \

cd /data/kvm/
# for i in master{0..2} worker{0..2}
for i in master{0..0}
do
  echo -ne &quot;${i}\t&quot; ; 
  virsh dumpxml ocp4-${i} | grep &quot;mac address&quot; | cut -d\' -f2 | tr '\n' '\t'
  echo 
done &gt; mac.list
cat /data/kvm/mac.list
# master0 00:60:2f:86:fc:ba

# GOTO image registry &amp; kvm host
# copy crt files to helper node
ssh-copy-id root@192.168.7.11

ssh root@192.168.7.11 mkdir -p /data/install
ssh root@192.168.7.11 mkdir -p /data/ocp4
ssh root@192.168.7.11 mkdir -p /etc/crts
scp /data/down/ocp4.tgz root@192.168.7.11:/data/
rsync -e ssh --info=progress2 -P --delete -arz /data/ocp4/ 192.168.7.11:/data/ocp4/

# scp /etc/crts/redhat.ren.ca.crt root@192.168.7.11:/data/install/
scp /etc/crts/redhat.ren.ca.crt root@192.168.7.11:/etc/crts/

scp /data/kvm/mac.list root@192.168.7.11:/data/install/

</code></pre>
<h2 id="配置redfish模拟"><a class="header" href="#配置redfish模拟">配置redfish模拟</a></h2>
<pre><code class="language-bash">
# install redfish for kvm
# https://access.redhat.com/solutions/4315581
# https://access.redhat.com/solutions/3057171
# https://docs.openstack.org/virtualbmc/latest/user/index.html
# https://docs.openstack.org/sushy-tools/latest/user/dynamic-emulator.html
dnf -y install python3-pip
# pip3 install --user sushy-tools

mkdir -p /data/install
cd /data/install

# podman create --name swap docker.io/wangzheng422/imgs:openshift-baremetal-install-4.6.5 ls
# podman cp swap:/openshift-baremetal-install ./
# podman rm -fv swap
# quay.io/wangzheng422/qimgs:ocp.bm.ipi.python.dep.rhel8-4.6.7

podman create --name swap quay.io/wangzheng422/qimgs:ocp.bm.ipi.python.dep.rhel8-4.10.4 ls
podman cp swap:/wheelhouse.tar.gz - &gt; wheelhouse.tar.gz.tar
tar xvf wheelhouse.tar.gz.tar
tar zvxf wheelhouse.tar.gz
podman rm -fv swap

dnf groupinstall -y 'Development Tools'
dnf -y install python3-pip libvirt libvirt-devel python3-devel openssl-devel

pip3 install --user --no-index --find-links wheelhouse setuptools-rust
# export CRYPTOGRAPHY_DONT_BUILD_RUST=1
dnf install -y rust cargo
pip3 install --user -r wheelhouse/requirements.txt --no-index --find-links wheelhouse

/root/.local/bin/sushy-emulator -i 0.0.0.0 --ssl-certificate /etc/crts/redhat.ren.crt --ssl-key /etc/crts/redhat.ren.key

# curl https://registry.ocp4.redhat.ren:8000/redfish/v1/Systems/

# DO NOT USE, restore 
# if you want to stop or delete vm, try this
virsh list --all
# virsh destroy ocp4-bootstrap
virsh destroy ocp4-master0 
# virsh destroy ocp4-master1 
# virsh destroy ocp4-master2 
# virsh destroy ocp4-worker0 
# virsh destroy ocp4-worker1 
# virsh destroy ocp4-worker2
# virsh undefine ocp4-bootstrap
virsh undefine ocp4-master0 --nvram
# virsh undefine ocp4-master1 --nvram
# virsh undefine ocp4-master2 --nvram
# virsh undefine ocp4-worker0 --nvram
# virsh undefine ocp4-worker1 --nvram
# virsh undefine ocp4-worker2 --nvram

</code></pre>
<h1 id="工具机上的准备工作"><a class="header" href="#工具机上的准备工作">工具机上的准备工作</a></h1>
<p>以下是在工具机里面，进行的安装操作。</p>
<p>主要的操作有</p>
<ul>
<li>配置yum源</li>
<li>运行ansible脚本，自动配置工具机</li>
<li>上传定制的安装配置文件</li>
<li>生成ignition文件</li>
</ul>
<h2 id="工具机的基础配置"><a class="header" href="#工具机的基础配置">工具机的基础配置</a></h2>
<pre><code class="language-bash">
sed -i 's/#UseDNS yes/UseDNS no/g' /etc/ssh/sshd_config
systemctl restart sshd

cat &lt;&lt; EOF &gt; /root/.ssh/config
StrictHostKeyChecking no
UserKnownHostsFile=/dev/null
EOF

systemctl disable --now firewalld

# in helper node
mkdir /etc/yum.repos.d.bak
mv /etc/yum.repos.d/* /etc/yum.repos.d.bak

export YUMIP=&quot;192.168.7.1&quot;
cat &lt;&lt; EOF &gt; /etc/yum.repos.d/remote.repo
[remote-epel]
name=epel
baseurl=ftp://${YUMIP}/dnf/epel
enabled=1
gpgcheck=0

[remote-epel-modular]
name=epel-modular
baseurl=ftp://${YUMIP}/dnf/epel-modular
enabled=1
gpgcheck=0

[remote-appstream]
name=appstream
baseurl=ftp://${YUMIP}/dnf/rhel-8-for-x86_64-appstream-rpms
enabled=1
gpgcheck=0

[remote-baseos]
name=baseos
baseurl=ftp://${YUMIP}/dnf/rhel-8-for-x86_64-baseos-rpms
enabled=1
gpgcheck=0

[remote-baseos-source]
name=baseos-source
baseurl=ftp://${YUMIP}/dnf/rhel-8-for-x86_64-baseos-source-rpms
enabled=1
gpgcheck=0

[remote-supplementary]
name=supplementary
baseurl=ftp://${YUMIP}/dnf/rhel-8-for-x86_64-supplementary-rpms
enabled=1
gpgcheck=0

[remote-codeready-builder]
name=supplementary
baseurl=ftp://${YUMIP}/dnf/codeready-builder-for-rhel-8-x86_64-rpms
enabled=1
gpgcheck=0

EOF

yum clean all
yum makecache
yum repolist

yum -y install ansible git unzip podman python3

yum -y update

reboot

# yum -y install ansible git unzip podman python36
</code></pre>
<h2 id="准备-openshift-的定制化-ansible-安装工具"><a class="header" href="#准备-openshift-的定制化-ansible-安装工具">准备 openshift 的定制化 ansible 安装工具</a></h2>
<pre><code class="language-bash">
mkdir -p /data/ocp4/
# scp ocp4.tgz to /data
# scp /data/down/ocp4.tgz root@192.168.7.11:/data/
cd /data
tar zvxf ocp4.tgz
cd /data/ocp4

# 这里使用了一个ansible的项目，用来部署helper节点的服务。
# https://github.com/wangzheng422/ocp4-upi-helpernode
unzip ocp4-upi-helpernode.zip
# 这里使用了一个ignition文件合并的项目，用来帮助自定义ignition文件。
# https://github.com/wangzheng422/filetranspiler
podman load -i filetranspiler.tgz

mkdir -p /data/install

# on helper

mkdir -p /data/ocp4/
cd /data/ocp4/
cat &lt;&lt; EOF &gt; redfish.sh
#!/usr/bin/env bash

curl -k -s https://${KVM_HOST}:8000/redfish/v1/Systems/ | jq -r '.Members[].&quot;@odata.id&quot;' &gt;  list

while read -r line; do
    curl -k -s https://${KVM_HOST}:8000/\$line | jq -j '.Id, &quot; &quot;, .Name, &quot;\n&quot; '
done &lt; list

EOF
bash redfish.sh &gt; /data/install/vm.list
cat /data/install/vm.list
# 1bc0116f-d376-45e2-b28c-d6b4b772b2bf ocp4-master0
# e70f66bc-7878-4617-811d-89cdaf62cc8c ocp4-Helper

# 配置ansible脚本的参数，注意修改里面的静态参数

cat &lt;&lt; EOF &gt; /data/ocp4/ocp4-upi-helpernode-master/vars.yaml
---
ocp_version: 4.10.4
ssh_gen_key: false
staticips: true
bm_ipi: true
firewalld: false
dns_forward: true
iso:
  iso_dl_url: &quot;file:///data/ocp4/rhcos-live.x86_64.iso&quot;
  my_iso: &quot;rhcos-live.iso&quot;
helper:
  name: &quot;helper&quot;
  ipaddr: &quot;${HELP_SERVER}&quot;
  networkifacename: &quot;enp1s0&quot;
  gateway: &quot;${SNO_GW}&quot;
  netmask: &quot;${SNO_NETMAST}&quot;
dns:
  domain: &quot;redhat.ren&quot;
  clusterid: &quot;ocp4&quot;
  forwarder1: &quot;172.21.1.1&quot;
  forwarder2: &quot;172.21.1.1&quot;
  api_vip: &quot;${API_VIP}&quot;
  ingress_vip: &quot;${INGRESS_VIP}&quot;
bootstrap:
  name: &quot;bootstrap&quot;
  ipaddr: &quot;${BOOTSTRAP_IP}&quot;
  interface: &quot;enp1s0&quot;
  install_drive: &quot;vda&quot;
masters:
  - name: &quot;master-0&quot;
    ipaddr: &quot;192.168.7.13&quot;
    interface: &quot;enp1s0&quot;
    install_drive: &quot;vda&quot;
others:
  - name: &quot;registry&quot;
    ipaddr: &quot;192.168.7.103&quot;
  - name: &quot;yum&quot;
    ipaddr: &quot;172.21.6.103&quot;
  - name: &quot;quay&quot;
    ipaddr: &quot;172.21.6.103&quot;
  - name: &quot;nexus&quot;
    ipaddr: &quot;172.21.6.103&quot;
  - name: &quot;git&quot;
    ipaddr: &quot;172.21.6.103&quot;
otherdomains:
  - domain: &quot;infra.redhat.ren&quot;
    hosts:
    - name: &quot;registry&quot;
      ipaddr: &quot;192.168.7.1&quot;
    - name: &quot;yum&quot;
      ipaddr: &quot;192.168.7.1&quot;
    - name: &quot;quay&quot;
      ipaddr: &quot;192.168.7.1&quot;
    - name: &quot;quaylab&quot;
      ipaddr: &quot;192.168.7.1&quot;
    - name: &quot;nexus&quot;
      ipaddr: &quot;192.168.7.1&quot;
    - name: &quot;git&quot;
      ipaddr: &quot;192.168.7.1&quot;
  - domain: &quot;${ACM_DEMO_MNGED_CLUSTER}.${SNO_BASE_DOMAIN}&quot;
    hosts:
    - name: &quot;api&quot;
      ipaddr: &quot;${ACM_DEMO_MNGED_SNO_IP}&quot;
    - name: &quot;api-int&quot;
      ipaddr: &quot;${ACM_DEMO_MNGED_SNO_IP}&quot;
    - name: &quot;${ACM_DEMO_MNGED_CLUSTER}-master&quot;
      ipaddr: &quot;${ACM_DEMO_MNGED_SNO_IP}&quot;
    - name: &quot;*.apps&quot;
      ipaddr: &quot;${ACM_DEMO_MNGED_SNO_IP}&quot;
  - domain: &quot;${SNO_CLUSTER_NAME}.${SNO_BASE_DOMAIN}&quot;
    hosts:
    - name: &quot;api&quot;
      ipaddr: &quot;${SNO_IP}&quot;
    - name: &quot;api-int&quot;
      ipaddr: &quot;${SNO_IP}&quot;
    - name: &quot;${SNO_CLUSTER_NAME}-master&quot;
      ipaddr: &quot;${SNO_IP}&quot;
    - name: &quot;*.apps&quot;
      ipaddr: &quot;${SNO_IP}&quot;
force_ocp_download: false
remove_old_config_files: false
ocp_client: &quot;file:///data/ocp4/{{ ocp_version }}/openshift-client-linux-{{ ocp_version }}.tar.gz&quot;
ocp_installer: &quot;file:///data/ocp4/{{ ocp_version }}/openshift-install-linux-{{ ocp_version }}.tar.gz&quot;
ppc64le: false
arch: 'x86_64'
chronyconfig:
  enabled: true
  content:
    - server: &quot;${NTP_SERVER}&quot;
      options: iburst
setup_registry: # don't worry about this, just leave it here
  deploy: false
  registry_image: docker.io/library/registry:2
  local_repo: &quot;ocp4/openshift4&quot;
  product_repo: &quot;openshift-release-dev&quot;
  release_name: &quot;ocp-release&quot;
  release_tag: &quot;4.6.1-x86_64&quot;
ocp_filetranspiler: &quot;file:///data/ocp4/filetranspiler.tgz&quot;

EOF

# 接下来，我们使用ansible来配置helper节点，装上各种openshift集群需要的服务
# 根据现场环境，修改 ocp4-upi-helpernode-master/vars-static.yaml
cd /data/ocp4/ocp4-upi-helpernode-master
ansible-playbook -e @vars.yaml -e '{ staticips: true, bm_ipi: true }'  tasks/main.yml


# generate image registry proxy related config
cd /data/ocp4
bash image.registries.conf.sh nexus.ocp4.redhat.ren:8083


# try this:
/usr/local/bin/helpernodecheck

mkdir -p /data/install

# GO back to help node
# apply registry's CA
/bin/cp -f /etc/crts/redhat.ren.ca.crt /etc/pki/ca-trust/source/anchors/
update-ca-trust extract

</code></pre>
<h2 id="配置-ignition-点火配置文件"><a class="header" href="#配置-ignition-点火配置文件">配置 ignition 点火配置文件</a></h2>
<p>openshift4安装的关键，就是ignition文件，更准确的说，是rhcos的点火配置文件，所有项目现场想做的定制，都在ignition文件里面。</p>
<p>rhcos就是一个rhel，所有你想要的定制化，都可以写成配置文件和脚本，加到ignition文件中去。但是，openshift4在安装过程中，至少要重启3次，我们的ignition文件中的配置，更多的是影响第一次启动，而之后的启动，rhcos会根据自身的升级机制，使用新的ignition去启动，这个新的ignition文件在哪里？怎么影响这个igntion文件的生成？作者现在也还在探索中，但是大致的方向是定制 /opt/openshift/openshift/ 下面的machine config yaml文件，把machine config写进去。</p>
<pre><code class="language-bash"># on helper

# 根据现场环境，修改 install-config.yaml
# 至少要修改ssh key， 还有 additionalTrustBundle，这个是镜像仓库的csr 

# copy your pull secret file into helper
# SEC_FILE='/data/pull-secret.json'
# cat &lt;&lt; 'EOF' &gt; $SEC_FILE

# 定制ignition
mkdir -p /data/install

cd /data/install

# vi install-config.yaml 
cat &lt;&lt; EOF &gt; /data/install/install-config.yaml 
apiVersion: v1
baseDomain: ${SNO_BASE_DOMAIN}
# bootMode: legacy
platform:
  baremetal:
    apiVIP: ${API_VIP}
    ingressVIP: ${INGRESS_VIP}
    bootstrapProvisioningIP: ${BOOTSTRAP_IP}
    clusterProvisioningIP: ${CLUSTER_PROVISION_IP}
    provisioningNetwork: &quot;Disabled&quot;
    externalBridge: baremetal
    bootstrapOSImage: http://${HELP_SERVER}:8080/install/rhcos-qemu.x86_64.qcow2.gz?sha256=$(zcat /var/www/html/install/rhcos-qemu.x86_64.qcow2.gz | sha256sum | awk '{print $1}')
    clusterOSImage: http://${HELP_SERVER}:8080/install/rhcos-openstack.x86_64.qcow2.gz?sha256=$(zcat /var/www/html/install/rhcos-openstack.x86_64.qcow2.gz | sha256sum  | awk '{print $1}')
    hosts:
      - name: ${SNO_HOSTNAME}
        role: master
        bmc:
          address: redfish-virtualmedia://${KVM_HOST}:8000/redfish/v1/Systems/$(cat vm.list | grep master0 | awk '{print $1}')
          username: admin
          password: password
          disableCertificateVerification: True
        bootMACAddress: $(cat mac.list | grep master0 | awk '{print $2}')
        rootDeviceHints:
          deviceName: &quot;${SNO_DISK}&quot;
        networkConfig: 
          dns-resolver:
            config:
              server:
              - ${SNO_DNS}
          interfaces:
          - ipv4:
              address:
              - ip: ${SNO_IP}
                prefix-length: ${SNO_NETMAST_S}
              # - ip: ${API_VIP}
              #   prefix-length: 32
              # - ip: ${INGRESS_VIP}
              #   prefix-length: 32
              # - ip: ${CLUSTER_PROVISION_IP}
              #   prefix-length: 32
              dhcp: false
              enabled: true
            name: ${SNO_IF}
            state: up
            type: ethernet
          routes:
            config:
            - destination: 0.0.0.0/0
              next-hop-address: ${SNO_GW}
              next-hop-interface: ${SNO_IF}
              table-id: 254
metadata:
  name: ${SNO_CLUSTER_NAME}
networking:
  clusterNetworks:
  - cidr: 10.254.0.0/16
    hostPrefix: 24
  networkType: OpenShiftSDN
  serviceNetwork:
  - 172.30.0.0/16
  machineCIDR: 192.168.7.0/24
compute:
- name: worker
  replicas: 0
controlPlane:
  name: master
  replicas: 1
  platform:
    baremetal: {}
pullSecret: '${PULL_SECRET}'
sshKey: |
$( cat /root/.ssh/id_rsa.pub | sed 's/^/   /g' )
additionalTrustBundle: |
$( cat /etc/crts/redhat.ren.ca.crt | sed 's/^/   /g' )
imageContentSources:
- mirrors:
  - ${INSTALL_IMAGE_REGISTRY}/ocp4/openshift4
  source: quay.io/openshift-release-dev/ocp-release
- mirrors:
  - ${INSTALL_IMAGE_REGISTRY}/ocp4/openshift4
  source: quay.io/openshift-release-dev/ocp-v4.0-art-dev
EOF

</code></pre>
<h1 id="在宿主机上开始安装"><a class="header" href="#在宿主机上开始安装">在宿主机上开始安装</a></h1>
<h2 id="将配置文件复制到宿主机上"><a class="header" href="#将配置文件复制到宿主机上">将配置文件复制到宿主机上</a></h2>
<pre><code class="language-bash">
# GO back to host
mkdir -p /data/install
cd /data/install
/bin/rm -rf .openshift_install.log .openshift_install_state.json terraform* auth tls *

scp root@192.168.7.11:/data/install/install-config.yaml /data/install/

cd /data/install
for i in $(sudo virsh list --all | tail -n +3 | grep bootstrap | awk {'print $2'});
do
  sudo virsh destroy $i;
  sudo virsh undefine $i;
  sudo virsh vol-delete $i --pool default;
  sudo virsh vol-delete $i.ign --pool default;
  virsh pool-destroy $i
  virsh pool-delete $i
  virsh pool-undefine $i
done

</code></pre>
<h2 id="从ignition点火配置文件创建安装配置文件"><a class="header" href="#从ignition点火配置文件创建安装配置文件">从ignition点火配置文件创建安装配置文件</a></h2>
<pre><code class="language-bash">
export BUILDNUMBER=4.10.4

/data/ocp4/${BUILDNUMBER}/openshift-baremetal-install --dir /data/install/ create manifests

# copy ntp related config
scp root@192.168.7.11:/data/ocp4/ocp4-upi-helpernode-master/machineconfig/* /data/install/openshift/

# /bin/cp -f /data/ocp4/image.registries.conf /etc/containers/registries.conf.d/

scp root@192.168.7.11:/data/ocp4/99-worker-container-registries.yaml /data/install/openshift
scp root@192.168.7.11:/data/ocp4/99-master-container-registries.yaml /data/install/openshift

# /data/ocp4/${BUILDNUMBER}/openshift-baremetal-install --dir /data/install/ --log-level debug create cluster
/data/ocp4/${BUILDNUMBER}/openshift-baremetal-install --dir /data/install/ create ignition-configs

</code></pre>
<h2 id="定制-bootstrap-的-ignition-点火配置文件"><a class="header" href="#定制-bootstrap-的-ignition-点火配置文件">定制 bootstrap 的 ignition 点火配置文件</a></h2>
<pre><code class="language-bash">mkdir -p /data/sno/disconnected/

# 定义单节点集群的节点信息
BTS_CLUSTER_NAME=ocp4s-ais
BTS_BASE_DOMAIN=redhat.ren
BTS_IP=192.168.7.12
BTS_GW=192.168.7.1
BTS_NETMAST=255.255.255.0
BTS_NETMAST_S=24
BTS_HOSTNAME=ocp4s-ais-bootstrap
# SNO_CON=&quot;Wired connection 1&quot;
BTS_CON=&quot;ens3&quot;
BTS_IF=ens3
BTS_DNS=192.168.7.11
BTS_DISK=/dev/vda
BTS_CORE_PWD=redhat

SNO_HOSTNAME=acm-demo-hub-master

cat &lt;&lt; EOF &gt; /data/sno/static.ip.bu
variant: openshift
version: 4.9.0
metadata:
  labels:
    machineconfiguration.openshift.io/role: master
  name: 99-zzz-master-static-ip
storage:
  files:
    - path: /etc/NetworkManager/system-connections/${BTS_CON}.nmconnection
      mode: 0600
      overwrite: true
      contents:
        inline: |
          [connection]
          id=${BTS_IF}
          # uuid=$(uuidgen)
          type=ethernet
          interface-name=${BTS_IF}
          autoconnect=true

          [ipv4]
          address1=${BTS_IP}/${BTS_NETMAST_S=24},${BTS_GW}
          dns=${BTS_DNS};
          dns-search=
          method=manual

          [ipv6]
          addr-gen-mode=eui64
          dhcp-hostname=${BTS_HOSTNAME}
          dhcp-timeout=90
          dns-search=
          method=disabled

          [proxy]

EOF

# set static hostname for master
# only works for sno
# do not use this in 3-master cluster
# in 3-master cluster, use dhcp to set hostname instead.

cat &lt;&lt; EOF &gt; /data/sno/static.hostname.bu
variant: openshift
version: 4.9.0
metadata:
  labels:
    machineconfiguration.openshift.io/role: master
  name: 99-zzz-master-static-hostname
storage:
  files:
    - path: /etc/hostname
      mode: 0644
      overwrite: true
      contents:
        inline: |
          ${SNO_HOSTNAME}

EOF

source /data/ocp4/acm.fn.sh

butane /data/sno/static.ip.bu &gt; /data/sno/disconnected/99-zzz-bootstrap-ip.yaml
get_file_content_for_ignition &quot;/opt/openshift/openshift/99-zzz-bootstrap-ip.yaml&quot; &quot;/data/sno/disconnected/99-zzz-bootstrap-ip.yaml&quot;
VAR_99_master_bootstrap_ip=$RET_VAL
VAR_99_master_bootstrap_ip_2=$RET_VAL_2

butane /data/sno/static.hostname.bu &gt; /data/sno/disconnected/99-zzz-master-static-hostname.yaml
get_file_content_for_ignition &quot;/opt/openshift/openshift/99-zzz-master-static-hostname.yaml&quot; &quot;/data/sno/disconnected/99-zzz-master-static-hostname.yaml&quot;
VAR_99_master_master_static_hostname=$RET_VAL
VAR_99_master_master_static_hostname_2=$RET_VAL_2

VAR_PWD_HASH=&quot;$(python3 -c 'import crypt,getpass; print(crypt.crypt(&quot;redhat&quot;))')&quot;

tmppath=$(mktemp)
cat /data/install/bootstrap.ign \
  | jq --arg VAR &quot;$VAR_PWD_HASH&quot; --arg VAR_SSH &quot;$NODE_SSH_KEY&quot; '.passwd.users += [{ &quot;name&quot;: &quot;wzh&quot;, &quot;system&quot;: true, &quot;passwordHash&quot;: $VAR , &quot;sshAuthorizedKeys&quot;: [ $VAR_SSH ], &quot;groups&quot;: [ &quot;adm&quot;, &quot;wheel&quot;, &quot;sudo&quot;, &quot;systemd-journal&quot;  ] }]' \
  | jq --argjson VAR &quot;$VAR_99_master_bootstrap_ip_2&quot; '.storage.files += [$VAR] ' \
  | jq --argjson VAR &quot;$VAR_99_master_master_static_hostname&quot; '.storage.files += [$VAR] ' \
  | jq -c . \
  &gt; ${tmppath}
/bin/cp -f ${tmppath} /data/install/bootstrap.ign
rm -f ${tmppath}

</code></pre>
<h2 id="开始-ipi-安装-openshift4"><a class="header" href="#开始-ipi-安装-openshift4">开始 IPI 安装 openshift4</a></h2>
<pre><code class="language-bash">
/data/ocp4/${BUILDNUMBER}/openshift-baremetal-install --dir /data/install/ --log-level debug create cluster

</code></pre>
<p>安装自动开始，等2分钟以后，可以看到自动创建了一个bootstrap虚拟机
<img src="imgs/2022-04-02-12-06-15.png" alt="" /></p>
<p>bootstrap运行一段时间后，会通过redfish，启动 master vm.</p>
<pre><code class="language-bash">
# we can login to the bootstrap by using username and password ( wzh/redhat ) in console
# or we can login using ssh
ssh core@192.168.7.12

# 在安装过程中，安装程序会检查master-0节点的hostname是不是localhost，不是的话等待网络配置
# 这个超时时间还有点长，等不及的话，登录到master-0节点上，直接用以下命令改一下
# hostnamectl set-hostname acm-demo-hub-master

# 在安装过程中，也许是bug，apiVIP, ingressVIP 无法漂移到master-0上正常加载
# 我们手动加上去就好了
# 这并不是一个bug，而是一个解决方案，因为IPI安装的设计，是要求3个master节点. 也许以后会内置支持吧。
# on master-0 kvm
nmcli con mod enp1s0 +ipv4.addresses 192.168.7.100/32
nmcli con mod enp1s0 +ipv4.addresses 192.168.7.101/32
nmcli con mod enp1s0 +ipv4.addresses 192.168.7.103/32
nmcli con up enp1s0

/data/ocp4/${BUILDNUMBER}/openshift-baremetal-install --dir /data/install/ wait-for bootstrap-complete --log-level debug
# DEBUG Bootstrap status: complete
# INFO It is now safe to remove the bootstrap resources
# DEBUG Time elapsed per stage:
# DEBUG Bootstrap Complete: 14s
# DEBUG                API: 14s
# INFO Time elapsed: 14s

/data/ocp4/${BUILDNUMBER}/openshift-baremetal-install --dir /data/install/  wait-for install-complete --log-level debug
# INFO Install complete!
# INFO To access the cluster as the system:admin user when using 'oc', run 'export KUBECONFIG=/data/install/auth/kubeconfig'
# INFO Access the OpenShift web-console here: https://console-openshift-console.apps.acm-demo-hub.redhat.ren
# INFO Login to the console with user: &quot;kubeadmin&quot;, and password: &quot;FpbMV-zasXr-8xczB-SSuIy&quot;
# DEBUG Time elapsed per stage:
# DEBUG Cluster Operators: 8m39s
# INFO Time elapsed: 8m39s

# on kvm host, copy back auth folder to helper node
rsync -arz /data/install/auth root@192.168.7.11:/data/install/

# Go back to helper
ansible localhost -m lineinfile -a 'path=$HOME/.bashrc regexp=&quot;^export KUBECONFIG&quot; line=&quot;export KUBECONFIG=/data/install/auth/kubeconfig&quot;'
source $HOME/.bashrc

oc get node
# NAME                  STATUS   ROLES           AGE    VERSION
# acm-demo-hub-master   Ready    master,worker   143m   v1.23.3+e419edf

oc get pod -n openshift-machine-api
# NAME                                          READY   STATUS    RESTARTS       AGE
# cluster-autoscaler-operator-86fb4975-ljssk    2/2     Running   8              137m
# cluster-baremetal-operator-5946dc9f9b-sksrh   2/2     Running   6              137m
# machine-api-controllers-9688d969d-qgn2j       7/7     Running   32 (34m ago)   135m
# machine-api-operator-568bb89984-s28kx         2/2     Running   6              137m
# metal3-d88947f6f-rbp9m                        7/7     Running   24 (35m ago)   134m
# metal3-image-cache-vf548                      1/1     Running   3              134m
# metal3-image-customization-577f886bb4-v7xg5   1/1     Running   3              134m

oc get all -n openshift-kni-infra
# NAME                                 READY   STATUS    RESTARTS   AGE
# pod/coredns-acm-demo-hub-master      2/2     Running   4          92m
# pod/haproxy-acm-demo-hub-master      2/2     Running   4          93m
# pod/keepalived-acm-demo-hub-master   2/2     Running   4          92m

oc get BareMetalHost -n openshift-machine-api
# NAME                  STATE                    CONSUMER                      ONLINE   ERROR   AGE
# acm-demo-hub-master   externally provisioned   acm-demo-hub-6rh7s-master-0   true             157m

oc get bmh -n openshift-machine-api
# NAME                  STATE                    CONSUMER                      ONLINE   ERROR   AGE
# acm-demo-hub-master   externally provisioned   acm-demo-hub-6rh7s-master-0   true             161m

</code></pre>
<p>可以看到web console上node的配置指向了bm
<img src="imgs/2022-04-02-21-07-47.png" alt="" /></p>
<p>我们也可以看到久违的machine配置
<img src="imgs/2022-04-02-21-08-12.png" alt="" /></p>
<p>machine set 也有了
<img src="imgs/2022-04-02-21-08-39.png" alt="" /></p>
<p>有了machine 自然 machine health check 也有了
<img src="imgs/2022-04-02-21-09-28.png" alt="" /></p>
<p>有一个单独的 baremetal hosts 的页面也出来了
<img src="imgs/2022-04-02-21-10-28.png" alt="" /></p>
<h2 id="静态添加-vip-for-api_server-ingress"><a class="header" href="#静态添加-vip-for-api_server-ingress">静态添加 vip for api_server, ingress</a></h2>
<p>我们是定制的 SNO IPI，其实不需要 api server , ingress 的 vip， 所以我们就写死到节点的启动脚本中，把这些 vip 给静态加上。 但是默认 ipi 安装会有一个 keepalived static pod ， 启动的时候，会清除到这些vip，那么我们还要把这个 keepalived static pod 关掉，否则会导致 vip 不可用。</p>
<pre><code class="language-bash"># on helper

cat &lt;&lt; EOF &gt; /data/install/wzh.script
#!/bin/bash

nmcli con mod enp1s0 +ipv4.addresses 192.168.7.100/32
nmcli con mod enp1s0 +ipv4.addresses 192.168.7.101/32
nmcli con mod enp1s0 +ipv4.addresses 192.168.7.103/32
nmcli con up enp1s0

EOF

var_local=$(cat /data/install/wzh.script | python3 -c &quot;import sys, urllib.parse; print(urllib.parse.quote(''.join(sys.stdin.readlines())))&quot;  )

cat &lt;&lt;EOF &gt; /data/install/45-master-wzh-service.yaml
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfig
metadata:
  labels:
    machineconfiguration.openshift.io/role: master
  name: 45-master-wzh-service
spec:
  config:
    ignition:
      version: 3.2.0
    storage:
      files:
      - contents:
          source: data:text/plain,${var_local}
          verification: {}
        filesystem: root
        mode: 0755
        path: /etc/rc.d/wzh.local
      - path: /etc/kubernetes/manifests/keepalived.yaml
        contents:
          source: data:text/plain,
          verification: {}
        filesystem: root
        mode: 0644
        overwrite: true
    systemd:
      units:
      - name: wzh.service
        enabled: true
        contents: |
          [Unit]
          Description=/etc/rc.d/wzh.local Compatibility
          ConditionFileIsExecutable=/etc/rc.d/wzh.local
          After=network.target

          [Service]
          Type=oneshot
          User=root
          Group=root
          ExecStart=/bin/bash -c /etc/rc.d/wzh.local

          [Install]
          WantedBy=multi-user.target

EOF
oc apply -f 45-master-wzh-service.yaml 

</code></pre>
<h1 id="安装后的操作"><a class="header" href="#安装后的操作">安装后的操作</a></h1>
<h2 id="添加一个新节点sno未验证"><a class="header" href="#添加一个新节点sno未验证">添加一个新节点（sno未验证）</a></h2>
<p>IPI 模式下，添加一个新节点非常方便，只要定义一个BareMetalHost就好了。</p>
<pre><code class="language-bash">cd /data/install/
cat &lt;&lt; EOF &gt; /data/install/bmh.yaml
---
apiVersion: v1
kind: Secret
metadata:
  name: worker-2-bmc-secret
type: Opaque
data:
  username: $(echo -ne &quot;admin&quot; | base64)
  password: $(echo -ne &quot;password&quot; | base64)
---
apiVersion: metal3.io/v1alpha1
kind: BareMetalHost
metadata:
  name: worker-2
spec:
  online: true
  bootMACAddress: $(cat mac.list | grep worker2 | awk '{print $2}')
  bmc:
    address: redfish-virtualmedia://192.168.7.1:8000/redfish/v1/Systems/$(cat vm.list | grep worker2 | awk '{print $1}')
    credentialsName: worker-2-bmc-secret
    disableCertificateVerification: true
  rootDeviceHints:
    deviceName: /dev/vda
EOF
oc -n openshift-machine-api create -f bmh.yaml

# DO NOT USE, restore, delete the vm
oc -n openshift-machine-api delete -f bmh.yaml

oc get bmh -n openshift-machine-api
# NAME       STATUS   PROVISIONING STATUS      CONSUMER                    BMC                                                                                               HARDWARE PROFILE   ONLINE   ERROR
# master-0   OK       externally provisioned   ocp4-zn8lq-master-0         redfish-virtualmedia://192.168.7.1:8000/redfish/v1/Systems/965c420a-f127-4639-9184-fe3546d2bde4                      true
# master-1   OK       externally provisioned   ocp4-zn8lq-master-1         redfish-virtualmedia://192.168.7.1:8000/redfish/v1/Systems/46f9dff4-1b44-4286-8a7c-691673340030                      true
# master-2   OK       externally provisioned   ocp4-zn8lq-master-2         redfish-virtualmedia://192.168.7.1:8000/redfish/v1/Systems/9e544eb6-1b98-4b0a-ad32-7df232ae582a                      true
# worker-0   OK       provisioned              ocp4-zn8lq-worker-0-mv4d7   redfish-virtualmedia://192.168.7.1:8000/redfish/v1/Systems/c399c6b7-525a-4f4e-8280-0472b6494fc5   unknown            true
# worker-1   OK       provisioned              ocp4-zn8lq-worker-0-9frt6   redfish-virtualmedia://192.168.7.1:8000/redfish/v1/Systems/a4052132-7598-4879-b3e1-c48c47cf67ed   unknown            true
# worker-2   OK       inspecting                                           redfish-virtualmedia://192.168.7.1:8000/redfish/v1/Systems/2eee2e57-e18b-460b-bb3f-7f048f84c69b                      true

oc get machinesets -n openshift-machine-api
# NAME                  DESIRED   CURRENT   READY   AVAILABLE   AGE
# ocp4-zn8lq-worker-0   2         2         2       2           155m

oc get machinesets -n openshift-machine-api -o json | jq -r .items[0].metadata.name

# 扩容worker到3副本，会触发worker-2的部署
oc scale --replicas=3 machineset $(oc get machinesets -n openshift-machine-api -o json | jq -r .items[0].metadata.name) -n openshift-machine-api

</code></pre>
<h2 id="镜像仓库代理--image-registry-proxy"><a class="header" href="#镜像仓库代理--image-registry-proxy">镜像仓库代理 / image registry proxy</a></h2>
<p>准备离线镜像仓库非常麻烦，好在我们找到了一台在线的主机，那么我们可以使用nexus构造image registry proxy，在在线环境上面，做一遍PoC，然后就能通过image registry proxy得到离线镜像了</p>
<ul>
<li>https://mtijhof.wordpress.com/2018/07/23/using-nexus-oss-as-a-proxy-cache-for-docker-images/</li>
</ul>
<pre><code class="language-bash">#####################################################
# init build the nexus fs
/bin/cp -f nexus-image.tgz /data/ccn/
tar zxf nexus-image.tgz
chown -R 200 /data/ccn/nexus-image

# podman run -d -p 8082:8081 -p 8083:8083 -it --name nexus-image -v /data/ccn/nexus-image:/nexus-data:Z docker.io/sonatype/nexus3:3.29.0

podman run -d -p 8082:8081 -p 8083:8083 -it --name nexus-image -v /data/ccn/nexus-image:/nexus-data:Z docker.io/wangzheng422/imgs:nexus3-3.29.0-wzh

podman stop nexus-image
podman rm nexus-image

# get the admin password
cat /data/ccn/nexus-image/admin.password &amp;&amp; echo
# 84091bcd-c82f-44a3-8b7b-dfc90f5b7da1

# open http://nexus.ocp4.redhat.ren:8082

# 开启 https
# https://blog.csdn.net/s7799653/article/details/105378645
# https://help.sonatype.com/repomanager3/system-configuration/configuring-ssl#ConfiguringSSL-InboundSSL-ConfiguringtoServeContentviaHTTPS
mkdir -p /data/install/tmp
cd /data/install/tmp

# 将证书导出成pkcs格式
# 这里需要输入密码  用 password，
openssl pkcs12 -export -out keystore.pkcs12 -inkey /etc/crts/redhat.ren.key -in /etc/crts/redhat.ren.crt

cat &lt;&lt; EOF &gt;&gt; Dockerfile
FROM docker.io/sonatype/nexus3:3.29.0
USER root
COPY keystore.pkcs12 /keystore.pkcs12
RUN keytool -v -importkeystore -srckeystore keystore.pkcs12 -srcstoretype PKCS12 -destkeystore keystore.jks -deststoretype JKS -storepass password -srcstorepass password  &amp;&amp;\
    cp keystore.jks /opt/sonatype/nexus/etc/ssl/
USER nexus
EOF
buildah bud --format=docker -t docker.io/wangzheng422/imgs:nexus3-3.29.0-wzh -f Dockerfile .
buildah push docker.io/wangzheng422/imgs:nexus3-3.29.0-wzh

######################################################
# go to helper, update proxy setting for ocp cluster
cd /data/ocp4
bash image.registries.conf.sh nexus.ocp4.redhat.ren:8083

mkdir -p /etc/containers/registries.conf.d
/bin/cp -f image.registries.conf /etc/containers/registries.conf.d/

cd /data/ocp4
oc apply -f ./99-worker-container-registries.yaml -n openshift-config
oc apply -f ./99-master-container-registries.yaml -n openshift-config

######################################################
# dump the nexus image fs out
podman stop nexus-image

var_date=$(date '+%Y-%m-%d-%H%M')
echo $var_date
cd /data/ccn

tar cf - ./nexus-image | pigz -c &gt; nexus-image.tgz 
buildah from --name onbuild-container scratch
buildah copy onbuild-container nexus-image.tgz  /
buildah umount onbuild-container 
buildah commit --rm --format=docker onbuild-container docker.io/wangzheng422/nexus-fs:image-$var_date
# buildah rm onbuild-container
# rm -f nexus-image.tgz 
buildah push docker.io/wangzheng422/nexus-fs:image-$var_date
echo &quot;docker.io/wangzheng422/nexus-fs:image-$var_date&quot;

# 以下这个版本，可以作为初始化的image proxy，里面包含了nfs provision，以及sample operator的metadata。很高兴的发现，image stream并不会完全下载镜像，好想只是下载metadata，真正用的时候，才去下载。
# docker.io/wangzheng422/nexus-fs:image-2020-12-26-1118

</code></pre>
<h2 id="配置镜像仓库的ca"><a class="header" href="#配置镜像仓库的ca">配置镜像仓库的ca</a></h2>
<p>安装过程里面，已经把镜像仓库的ca放进去了，但是好想image stream不认，让我们再试试</p>
<pre><code class="language-bash">oc project openshift-config
oc create configmap ca.for.registry -n openshift-config \
    --from-file=registry.ocp4.redhat.ren..5443=/data/install/redhat.ren.ca.crt \
    --from-file=nexus.ocp4.redhat.ren..8083=/data/install/redhat.ren.ca.crt 
oc patch image.config.openshift.io/cluster -p '{&quot;spec&quot;:{&quot;additionalTrustedCA&quot;:{&quot;name&quot;:&quot;ca.for.registry&quot;}}}'  --type=merge

# oc patch image.config.openshift.io/cluster -p '{&quot;spec&quot;:{&quot;registrySources&quot;:{&quot;insecureRegistries&quot;:[&quot;nexus.ocp4.redhat.ren:8083&quot;]}}}'  --type=merge

oc get image.config.openshift.io/cluster -o yaml

# openshift project下面的image stream重新加载一下把
oc get is -o json | jq -r '.items[].metadata.name' | xargs -L1 oc import-image --all 

</code></pre>
<h2 id="配置internal-registry"><a class="header" href="#配置internal-registry">配置internal registry</a></h2>
<p>我们的工具机是带nfs的，那么就给interneal registry配置高档一些的nfs存储吧，不要用emptydir</p>
<pre><code class="language-bash">bash /data/ocp4/ocp4-upi-helpernode-master/files/nfs-provisioner-setup.sh

# oc edit configs.imageregistry.operator.openshift.io
# 修改 storage 部分
# storage:
#   pvc:
#     claim:
oc patch configs.imageregistry.operator.openshift.io cluster -p '{&quot;spec&quot;:{&quot;managementState&quot;: &quot;Managed&quot;,&quot;storage&quot;:{&quot;pvc&quot;:{&quot;claim&quot;:&quot;&quot;}}}}' --type=merge

oc patch configs.imageregistry.operator.openshift.io cluster -p '{&quot;spec&quot;:{&quot;managementState&quot;: &quot;Removed&quot;}}' --type=merge

oc get clusteroperator image-registry

oc get configs.imageregistry.operator.openshift.io cluster -o yaml

# 把imagepruner给停掉
# https://bugzilla.redhat.com/show_bug.cgi?id=1852501#c24
# oc patch imagepruner.imageregistry/cluster --patch '{&quot;spec&quot;:{&quot;suspend&quot;:true}}' --type=merge
# oc -n openshift-image-registry delete jobs --all
</code></pre>
<h2 id="配置sample-operator"><a class="header" href="#配置sample-operator">配置sample operator</a></h2>
<p>openshift内置了一个sample operator，里面有一大堆红帽的产品。</p>
<pre><code class="language-bash">oc get configs.samples.operator.openshift.io/cluster -o yaml

oc patch configs.samples.operator.openshift.io/cluster -p '{&quot;spec&quot;:{&quot;managementState&quot;: &quot;Managed&quot;, &quot;samplesRegistry&quot;: &quot;nexus.ocp4.redhat.ren:8083&quot;}}' --type=merge

oc patch configs.samples.operator.openshift.io/cluster -p '{&quot;spec&quot;:{&quot;managementState&quot;: &quot;Unmanaged&quot;}}' --type=merge

oc patch configs.samples.operator.openshift.io/cluster -p '{&quot;spec&quot;:{&quot;managementState&quot;: &quot;Removed&quot;}}' --type=merge

</code></pre>
<h2 id="chronyntp-设置"><a class="header" href="#chronyntp-设置">chrony/NTP 设置</a></h2>
<p>在 ocp 4.6 里面，需要设定ntp同步，我们之前ansible脚本，已经创建好了ntp的mco配置，把他打到系统里面就好了。</p>
<pre><code class="language-bash">oc apply -f /data/ocp4/ocp4-upi-helpernode-master/machineconfig/

</code></pre>
<h2 id="operator-hub-离线安装"><a class="header" href="#operator-hub-离线安装">Operator Hub 离线安装</a></h2>
<p>使用nexus作为image proxy以后，就不需要做这个离线操作了，但是如果我们想搞CCN这种项目，因为他自带了一个catalog，为了避免冲突，我们可能还是需要屏蔽到默认的operator hub</p>
<pre><code class="language-bash">
oc patch OperatorHub cluster --type json \
    -p '[{&quot;op&quot;: &quot;add&quot;, &quot;path&quot;: &quot;/spec/disableAllDefaultSources&quot;, &quot;value&quot;: true}]'

oc get OperatorHub cluster -o yaml

</code></pre>
<h2 id="给-openshift-project-image-stream-打补丁"><a class="header" href="#给-openshift-project-image-stream-打补丁">给 openshift project image stream 打补丁</a></h2>
<p>在有代理的网络环境中，我们需要给openshift project下的image stream打一些补丁。</p>
<pre><code class="language-bash">cd /data/ocp4
bash is.patch.sh registry.ocp4.redhat.ren:5443/ocp4/openshift4

</code></pre>
<h2 id="给-router--ingress-更换证书"><a class="header" href="#给-router--ingress-更换证书">给 router / ingress 更换证书</a></h2>
<p>有时候，我们需要公网CA认证的证书，给router来用，那么我们就搞一下</p>
<p>https://docs.openshift.com/container-platform/4.6/security/certificates/replacing-default-ingress-certificate.html</p>
<pre><code class="language-bash">
mkdir -p /data/ccn/ingress-keys/etc
mkdir -p /data/ccn/ingress-keys/lib
cd /data/ccn/ingress-keys
podman run -it --rm --name certbot \
            -v &quot;/data/ccn/ingress-keys/etc:/etc/letsencrypt&quot;:Z \
            -v &quot;/data/ccn/ingress-keys/lib:/var/lib/letsencrypt&quot;:Z \
            docker.io/certbot/certbot certonly  -d &quot;*.apps.ocp4.redhat.ren&quot; --manual --preferred-challenges dns-01  --server https://acme-v02.api.letsencrypt.org/directory

cp ./etc/archive/apps.ocp4.redhat.ren/fullchain1.pem apps.ocp4.redhat.ren.crt
cp ./etc/archive/apps.ocp4.redhat.ren/privkey1.pem apps.ocp4.redhat.ren.key

ssh root@192.168.7.11 mkdir -p /data/install/ingress-key

scp apps.* root@192.168.7.11:/data/install/ingress-key

# on helper
cd /data/install/ingress-key

oc create secret tls wzh-ingress-key \
     --cert=apps.ocp4.redhat.ren.crt \
     --key=apps.ocp4.redhat.ren.key \
     -n openshift-ingress

oc patch ingresscontroller.operator default \
     --type=merge -p \
     '{&quot;spec&quot;:{&quot;defaultCertificate&quot;: {&quot;name&quot;: &quot;wzh-ingress-key&quot;}}}' \
     -n openshift-ingress-operator

</code></pre>
<h1 id="build-the-pip-dependencies-for-rhel8"><a class="header" href="#build-the-pip-dependencies-for-rhel8">build the pip dependencies for rhel8</a></h1>
<pre><code class="language-bash">
export BUILDNUMBER=4.10.4

dnf groupinstall -y 'Development Tools'
dnf -y install python3-pip libvirt libvirt-devel python3-devel

pip3 uninstall -y $(pip3 list --user --format=legacy | awk '{print $1}' | tr '\n' ' ' )

pip3 install --user setuptools-rust
pip3 install --user virtualbmc
pip3 install --user sushy-tools
pip3 freeze --user &gt; requirements.txt
# pip3 install -r requirements.txt --user
mkdir -p wheelhouse
pip3 download -r requirements.txt -d wheelhouse
/bin/cp -f requirements.txt wheelhouse/
tar -zcf wheelhouse.tar.gz wheelhouse

buildah from --name onbuild-container scratch
buildah copy onbuild-container wheelhouse.tar.gz /
buildah umount onbuild-container 
buildah commit --rm --format=docker onbuild-container quay.io/wangzheng422/qimgs:ocp.bm.ipi.python.dep.rhel8-${BUILDNUMBER}
# buildah rm onbuild-container
buildah push quay.io/wangzheng422/qimgs:ocp.bm.ipi.python.dep.rhel8-${BUILDNUMBER}
echo &quot;quay.io/wangzheng422/qimgs:ocp.bm.ipi.python.dep.rhel8-${BUILDNUMBER}&quot;

# quay.io/wangzheng422/qimgs:ocp.bm.ipi.python.dep.rhel8-4.10.4

</code></pre>
<h2 id="排错技巧"><a class="header" href="#排错技巧">排错技巧</a></h2>
<pre><code class="language-bash">
# login to bootstrap to debug
# find the ip from kvm console
ssh -i ~/.ssh/helper_rsa core@192.168.7.75
journalctl -b -f -u release-image.service -u bootkube.service
journalctl -b -u release-image.service -u bootkube.service | grep -i baremetal
sudo -i
export KUBECONFIG=/etc/kubernetes/kubeconfig
oc get pod -n openshift-machine-api
oc get BareMetalHost -n openshift-machine-api

# debug why bootstrap can't be ping...
cat .openshift_install_state.json | jq  '.&quot;*bootstrap.Bootstrap&quot;'.Config.storage.files[].path

cat .openshift_install_state.json | jq -r '.&quot;*bootstrap.Bootstrap&quot;'.File.Data | base64 -d | jq -r . &gt; ign.json

cat .openshift_install_state.json | jq  -r '.&quot;*bootstrap.Bootstrap&quot;.Config.storage.files[].contents.source ' | sed 's/.*base64,//g' | base64 -d &gt; decode

cat .openshift_install_state.json | jq  -r '.&quot;*bootstrap.Bootstrap&quot;.Config.storage.files[] | .path, .contents.source ' | while read -r line ; do if [[ $line =~ .*base64,.* ]]; then echo $(echo $line | sed 's/.*base64,//g' | base64 -d) ; else echo $line; fi; done &gt; files

cat bootstrap.ign | jq '.storage.files[] | select ( .path == &quot;/opt/openshift/openshift/99_baremetal-provisioning-config.yaml&quot; ) ' | jq  -r .contents.source | sed 's/.*base64,//g' | base64 -d

cat bootstrap.ign | jq '.storage.files[] | select ( .path | contains(&quot;/opt/openshift/openshift/&quot;) ) ' | jq  -r .contents.source | sed 's/.*base64,//g' | base64 -d


</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                                                    <a rel="prev" href="../../ocp4/4.9/4.9.sno.using.bootstrap.disconnected.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                        
                                                    <a rel="next" href="../../ocp4/4.10/4.10.acm.ztp.disconnected.auto.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                                    <a rel="prev" href="../../ocp4/4.9/4.9.sno.using.bootstrap.disconnected.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                
                                    <a rel="next" href="../../ocp4/4.10/4.10.acm.ztp.disconnected.auto.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
                            </nav>

        </div>

        
        
        
                <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        
        
                <script src="../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../searcher.js" type="text/javascript" charset="utf-8"></script>
        
        <script src="../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        
        
    </body>
</html>

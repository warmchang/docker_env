<!DOCTYPE HTML>
<html lang="zh" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>intel o-ran flexran 方案在openshift4上的安装和使用 - OpenShift4 慢慢走</title>
        <!-- Custom HTML head -->
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-E3FRMDB7L2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-E3FRMDB7L2');
</script>        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../../favicon.svg">
        <link rel="shortcut icon" href="../../favicon.png">
        <link rel="stylesheet" href="../../css/variables.css">
        <link rel="stylesheet" href="../../css/general.css">
        <link rel="stylesheet" href="../../css/chrome.css">
        <link rel="stylesheet" href="../../css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="../../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../../fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../highlight.css">
        <link rel="stylesheet" href="../../tomorrow-night.css">
        <link rel="stylesheet" href="../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../../index.html">介绍</a></li><li class="chapter-item expanded "><a href="../../install.html"><strong aria-hidden="true">1.</strong> openshift4 安装系列</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.ocp.pull.secret.html"><strong aria-hidden="true">1.1.</strong> 如何获得 openshift4 免费下载密钥</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.build.dist.html"><strong aria-hidden="true">1.2.</strong> openshift4 离线安装介质的制作</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.sno.static.ip.local.assisted.connected.html"><strong aria-hidden="true">1.3.</strong> assisted install 联线模式下 单节点ocp 无需dhcp 静态ip部署</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.sno.static.ip.local.assisted.disconnected.html"><strong aria-hidden="true">1.4.</strong> assisted install 离线模式下 单节点ocp 无需dhcp 静态ip部署</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.disconnect.bm.upi.static.ip.on.rhel7.html"><strong aria-hidden="true">1.5.</strong> openshift4 rhel7物理机 baremetal UPI模式 离线安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.disconnect.bm.upi.static.ip.on.rhel8.html"><strong aria-hidden="true">1.6.</strong> openshift4 rhel8物理机 baremetal UPI模式 离线安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.disconnect.bm.ipi.on.rhel8.html"><strong aria-hidden="true">1.7.</strong> openshift4 物理机 baremetal IPI模式 离线安装 单网络模式</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.disconnect.bm.ipi.on.rhel8.provisionning.network.html"><strong aria-hidden="true">1.8.</strong> openshift4 物理机 baremetal IPI模式 离线安装 双网络模式</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.cilium.html"><strong aria-hidden="true">1.9.</strong> openshift4 尝鲜 cilium CNI</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.nvidia.gpu.disconnected.html"><strong aria-hidden="true">1.10.</strong> nvidia gpu for openshift 4.6 disconnected 英伟达GPU离线安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.add.image.html"><strong aria-hidden="true">1.11.</strong> openshift4 初始安装后 补充镜像</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.is.sample.html"><strong aria-hidden="true">1.12.</strong> openshift4 补充samples operator 需要的 image stream</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.calico.html"><strong aria-hidden="true">1.13.</strong> openshift4 calico 离线部署</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.2/4.2.upgrade.html"><strong aria-hidden="true">1.14.</strong> openshift4 集群升级</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.shrink.sysroot.html"><strong aria-hidden="true">1.15.</strong> 缩小根分区 / sysroot 的大小</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.update.service.html"><strong aria-hidden="true">1.16.</strong> 部署升级服务 完善离线升级功能</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.windows.node.html"><strong aria-hidden="true">1.17.</strong> 添加 win10 worker 节点</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.sno.using.bootstrap.disconnected.html"><strong aria-hidden="true">1.18.</strong> 单节点ocp 安装 无需dhcp 静态ip部署</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.disconnect.bm.ipi.sno.static.ip.html"><strong aria-hidden="true">1.19.</strong> IPI模式 单节点 离线 单网络模式 安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.acm.ztp.disconnected.auto.html"><strong aria-hidden="true">1.20.</strong> ACM zero touch provision 远程单节点集群 全自动安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.coreos.boot.html"><strong aria-hidden="true">1.21.</strong> coreos 启动和分区挂载分析</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.installer.html"><strong aria-hidden="true">1.22.</strong> openshift4 单节点 命令行安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.partition.quay.html"><strong aria-hidden="true">1.23.</strong> openshift4 单节点 在第一块硬盘上添加更多分区</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.nfs.lvm.html"><strong aria-hidden="true">1.24.</strong> openshift4 单节点 使用 lvm 和 nfs 在集群内提供存储</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.boot.from.linux.html"><strong aria-hidden="true">1.25.</strong> openshift4 单节点 从centos7/8 开始安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.odf.html"><strong aria-hidden="true">1.26.</strong> openshift4 单节点 安装精简版 ODF/ceph</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.replace.coreos.html"><strong aria-hidden="true">1.27.</strong> 定制 rhcos</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.rpm-ostree.install.html"><strong aria-hidden="true">1.28.</strong> rhcos 里面安装 rpm</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.component.version.html"><strong aria-hidden="true">1.29.</strong> openshift 4 组件版本</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.embeded.dns.haproxy.registry.html"><strong aria-hidden="true">1.30.</strong> 内嵌 dns, haproxy, registrty</a></li></ol></li><li class="chapter-item expanded "><a href="../../usage.html"><strong aria-hidden="true">2.</strong> openshift4 使用系列</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.flexran.20.11.pf.deploy.html"><strong aria-hidden="true">2.1.</strong> 在openshift4上运行 OpenRAN 无线基站应用</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.netflow.table.html"><strong aria-hidden="true">2.2.</strong> openshift4 可视化 ovs netflow</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.flexran.20.11.html" class="active"><strong aria-hidden="true">2.3.</strong> intel o-ran flexran 方案在openshift4上的安装和使用</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.ci.cd.demo.html"><strong aria-hidden="true">2.4.</strong> ci/cd pipeline gitops演示</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.oc.exec.html"><strong aria-hidden="true">2.5.</strong> oc/kubectl exec 原理分析</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.nf.conntrack.html"><strong aria-hidden="true">2.6.</strong> nf_conntrack 在 openshift4.9上的处理</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.load.3rd.part.driver.html"><strong aria-hidden="true">2.7.</strong> 加载第三方设备驱动</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.nep.containerized.helm.html"><strong aria-hidden="true">2.8.</strong> helm chart/helm operator</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.metalb.l2.html"><strong aria-hidden="true">2.9.</strong> 使用 MetalLB 用 Layer2 发布 LoadBalancer</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.metalb.html"><strong aria-hidden="true">2.10.</strong> 使用 MetalLB 用 BGP 发布 LoadBalancer</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.kata.html"><strong aria-hidden="true">2.11.</strong> kata / 沙盒容器</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.sriov.html"><strong aria-hidden="true">2.12.</strong> 在非官方支持的网卡上，测试SRIOV/DPDK</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.keepalived.operator.html"><strong aria-hidden="true">2.13.</strong> 使用 keepalived 激活 LoadBalancer 服务类型</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.real-time.kernel.html"><strong aria-hidden="true">2.14.</strong> 在节点上启用实时操作系统 real-time kernel</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.install.kmod.driver.html"><strong aria-hidden="true">2.15.</strong> 从容器向宿主机注入内核模块 kmod / driver</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.vgpu.sharing.deploy.html"><strong aria-hidden="true">2.16.</strong> GPU/vGPU 共享</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.4/4.4.headless.service.html"><strong aria-hidden="true">2.17.</strong> openshift headless service讲解</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.volumn.html"><strong aria-hidden="true">2.18.</strong> openshift volumn 存储的各种测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.SupportPodPidsLimit.html"><strong aria-hidden="true">2.19.</strong> openshift 设置 SupportPodPidsLimit 解除 pids 限制</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.sso.html"><strong aria-hidden="true">2.20.</strong> openshift4 配置 SSO 点单认证</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.scc.html"><strong aria-hidden="true">2.21.</strong> openshift4 SCC 相关安全能力测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.recover.node.not.ready.html"><strong aria-hidden="true">2.22.</strong> openshift4 从 node not ready 状态恢复</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.QoS.nic.html"><strong aria-hidden="true">2.23.</strong> openshift4 QoS 能力</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.QoS.nic.high.html"><strong aria-hidden="true">2.24.</strong> openshift4 QoS 在流量压力下的表现</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.proxy.html"><strong aria-hidden="true">2.25.</strong> openshift4 使用 image proxy 来下载镜像</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.numa.html"><strong aria-hidden="true">2.26.</strong> openshift4 NUMA 绑核测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.network.policy.html"><strong aria-hidden="true">2.27.</strong> openshift4 Network Policy 测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.multicast.html"><strong aria-hidden="true">2.28.</strong> openshift4 网络多播 测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.firewall.html"><strong aria-hidden="true">2.29.</strong> openshift4 配置节点防火墙</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.ldap.html"><strong aria-hidden="true">2.30.</strong> openshift4 集成 ldap</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.image.pull.html"><strong aria-hidden="true">2.31.</strong> openshift4 维护 image pull secret</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.huge.page.html"><strong aria-hidden="true">2.32.</strong> openshift4 使用大页内存 huge page</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.helm.html"><strong aria-hidden="true">2.33.</strong> openshift4 使用 helm</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.haproxy.html"><strong aria-hidden="true">2.34.</strong> openshift4 定制router 支持 TCP ingress</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.grafana.html"><strong aria-hidden="true">2.35.</strong> openshift4 监控能力展示 grafana</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.cpu.manager.html"><strong aria-hidden="true">2.36.</strong> openshift4 CPU 绑核 测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.build.config.html"><strong aria-hidden="true">2.37.</strong> openshift4 build config & hpa 自动化编译和自动扩缩容</a></li></ol></li><li class="chapter-item expanded "><a href="../../ccn.html"><strong aria-hidden="true">3.</strong> 应用上云系列教程 CCN</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.4/4.4.ccn.devops.deploy.html"><strong aria-hidden="true">3.1.</strong> 应用上云系列教程 containerized cloud native (CCN) for openshift 4.4</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.4/4.4.ccn.devops.build.html"><strong aria-hidden="true">3.2.</strong> CCN 安装介质制作 for openshift 4.4</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.ccn.devops.deploy.html"><strong aria-hidden="true">3.3.</strong> 应用上云系列教程 containerized cloud native (CCN) for openshift 4.6</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.ccn.devops.build.html"><strong aria-hidden="true">3.4.</strong> CCN 安装介质制作 for openshift 4.6</a></li></ol></li><li class="chapter-item expanded "><a href="../../rh.cloud.html"><strong aria-hidden="true">4.</strong> 红帽其他产品系列</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.acm.observ.html"><strong aria-hidden="true">4.1.</strong> ACM observability for openshift 4.10</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.01.ansible.install.html"><strong aria-hidden="true">4.2.</strong> 离线安装 ansible platform</a></li><li class="chapter-item expanded "><a href="../../notes/2021/2021.08.virus.html"><strong aria-hidden="true">4.3.</strong> RHACS 应对log4j 原理和实践</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.ocp.ocs.cnv.ceph.html"><strong aria-hidden="true">4.4.</strong> openshift承载虚拟化业务(CNV)</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.rhacs.html"><strong aria-hidden="true">4.5.</strong> RHACS / stackrox</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.rhacs.deep.html"><strong aria-hidden="true">4.6.</strong> 为 RHACS 找个应用场景: 安全合规测试云 </a></li></ol></li><li class="chapter-item expanded "><a href="../../os.html"><strong aria-hidden="true">5.</strong> 操作系统相关</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../notes/2022/2022.04.os.backup.ReaR.html"><strong aria-hidden="true">5.1.</strong> Relax and Recover(ReaR) 系统备份和灾难恢复</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.04.no-cost.rhel.sub.html"><strong aria-hidden="true">5.2.</strong> 红帽免费的开发者订阅申请和使用</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.01.rpm.belongs.html"><strong aria-hidden="true">5.3.</strong> 在红帽官网查询rpm属于哪个repo</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.01.rhel7.upgrade.to.rhel8.html"><strong aria-hidden="true">5.4.</strong> 离线环境下 原地升级 rhel7-&gt;rhel8</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.01.sysctl.html"><strong aria-hidden="true">5.5.</strong> 系统启动自动加载sysctl配置</a></li><li class="chapter-item expanded "><a href="../../notes/2021/2021.12.ocp.bf2.dpi.url.filter.html"><strong aria-hidden="true">5.6.</strong> Mellanox BF2 刷固件并测试DPI URL-filter场景</a></li><li class="chapter-item expanded "><a href="../../notes/2021/2021.11.bf2.snap.try.html"><strong aria-hidden="true">5.7.</strong> Mellanox BF2 网卡激活snap功能，配置nvme over fabrics 支持</a></li><li class="chapter-item expanded "><a href="../../notes/2021/2021.10.cx6dx.vdpa.offload.html"><strong aria-hidden="true">5.8.</strong> Mellanox CX6 vdpa 硬件卸载 ovs-kernel 方式</a></li><li class="chapter-item expanded "><a href="../../rhel/rhel.build.kernel.html"><strong aria-hidden="true">5.9.</strong> RHEL8编译定制化内核</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.check.whether.vm.html"><strong aria-hidden="true">5.10.</strong> 检查OS是否是运行在虚拟机上</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.4/4.4.ovs.html"><strong aria-hidden="true">5.11.</strong> 两个主机用ovs组网</a></li><li class="chapter-item expanded "><a href="../../notes/2021/2021.01.ssh.tunnel.html"><strong aria-hidden="true">5.12.</strong> 内网隔离情况下，使用SSH正向和反向代理，实现连通外网http proxy</a></li></ol></li><li class="chapter-item expanded "><a href="../../workshop.html"><strong aria-hidden="true">6.</strong> 优秀的workshop</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.ocp.ocs.workshop.html"><strong aria-hidden="true">6.1.</strong> openshift4 & openshift storage workshop</a></li></ol></li><li class="chapter-item expanded "><a href="../../poc.html"><strong aria-hidden="true">7.</strong> POC</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.3/poc.sc/install.poc.sc.html"><strong aria-hidden="true">7.1.</strong> 2020.04 某次POC openshift LVM调优</a></li></ol></li><li class="chapter-item expanded "><a href="../../osx.html"><strong aria-hidden="true">8.</strong> OSX使用技巧</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../osx/osx.record.system.audio.html"><strong aria-hidden="true">8.1.</strong> 如何录制系统声音</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">OpenShift4 慢慢走</h1>

                    <div class="right-buttons">
                        <a href="../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/wangzheng422/docker_env" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        <a href="https://github.com/wangzheng422/docker_env/blob/dev/redhat/ocp4/4.10/4.10.flexran.20.11.md" title="Suggest an edit" aria-label="Suggest an edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="flexran-2011-enable-on-ocp4"><a class="header" href="#flexran-2011-enable-on-ocp4">FlexRAN 20.11 enable on ocp4</a></h1>
<p>本文描述，如何把 intel 的 oran 解决方案 flexran ，移植到 openshift 平台之上。</p>
<p>容器镜像构建和运行架构，文件目录结构：</p>
<p><img src="dia/4.10.flexran.drawio.svg" alt="" /></p>
<p>容器运行的时候，和operator以及硬件的关系结构图：</p>
<p><img src="dia/4.10.flexran.operator.drawio.svg" alt="" /></p>
<h2 id="问题"><a class="header" href="#问题">问题</a></h2>
<ol>
<li>ptp服务配置了，vbbu 怎么用？</li>
</ol>
<h1 id="prepare-public-cloud-env"><a class="header" href="#prepare-public-cloud-env">prepare public cloud env</a></h1>
<p>我们先在公网环境里面编译镜像，并且上传到quay.io</p>
<h2 id="basic-init-setup"><a class="header" href="#basic-init-setup">basic init setup</a></h2>
<pre><code class="language-bash">
# vultr, ssh enhance

# disable user/passwd login
# ChallengeResponseAuthentication no
# PasswordAuthentication no
# UsePAM no
sed -i 's/PasswordAuthentication yes/PasswordAuthentication no/g' /etc/ssh/sshd_config
sed -i 's/UsePAM yes/UsePAM no/g' /etc/ssh/sshd_config

systemctl restart sshd

ssh root@v.redhat.ren -o PubkeyAuthentication=no
# root@v.redhat.ren: Permission denied (publickey,gssapi-keyex,gssapi-with-mic).

subscription-manager register --auto-attach --username ******** --password ********

subscription-manager release --list
subscription-manager release --set=8.4

subscription-manager repos \
    --enable=&quot;codeready-builder-for-rhel-8-x86_64-rpms&quot; 

dnf -y install https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm

dnf install -y byobu htop fail2ban

cat &lt;&lt; EOF &gt; /etc/fail2ban/jail.d/wzh.conf
[sshd]
enabled = true
# [recidive]
# enabled = true
EOF

systemctl enable --now fail2ban

cat &lt;&lt; EOF &gt; /etc/fail2ban/jail.d/wzh.conf
[sshd]
enabled = true
[recidive]
enabled = true
EOF

systemctl restart fail2ban

# byobu
dnf update -y

reboot
</code></pre>
<h2 id="install-ocp-rhcos-rt-kernel"><a class="header" href="#install-ocp-rhcos-rt-kernel">install ocp rhcos rt kernel</a></h2>
<pre><code class="language-bash">mkdir -p /data/ostree

export BUILDNUMBER=4.9.5

wget -O openshift-client-linux-${BUILDNUMBER}.tar.gz https://mirror.openshift.com/pub/openshift-v4/clients/ocp/${BUILDNUMBER}/openshift-client-linux-${BUILDNUMBER}.tar.gz
wget -O openshift-install-linux-${BUILDNUMBER}.tar.gz https://mirror.openshift.com/pub/openshift-v4/clients/ocp/${BUILDNUMBER}/openshift-install-linux-${BUILDNUMBER}.tar.gz

tar -xzf openshift-client-linux-${BUILDNUMBER}.tar.gz -C /usr/local/sbin/
tar -xzf openshift-install-linux-${BUILDNUMBER}.tar.gz -C /usr/local/sbin/

oc image extract --path /:/data/ostree --registry-config /data/pull-secret.json   `  curl -s https://mirror.openshift.com/pub/openshift-v4/x86_64/clients/ocp/$BUILDNUMBER/release.txt | grep machine-os-content | awk '{print $2}'  `

mkdir -p /data/dnf
mv /data/ostree/extensions /data/dnf/
rm -rf /data/ostree

mkdir -p /etc/yum.repos.d
cat &gt; /etc/yum.repos.d/rt.repo &lt;&lt; 'EOF'
[rt]
name=rt
baseurl=file:///data/dnf/extensions
gpgcheck=0
EOF

dnf install -y kernel-rt-core kernel-rt-devel kernel-rt-modules kernel-rt-modules-extra kernel-headers libhugetlbfs-devel zlib-devel numactl-devel cmake gcc gcc-c++

reboot
</code></pre>
<h1 id="build-flexran-with-intel-iccicx"><a class="header" href="#build-flexran-with-intel-iccicx">build flexran with intel icc/icx</a></h1>
<pre><code class="language-bash">dnf groupinstall -y 'Development Tools'
dnf install -y cmake

# flexran install on host
# yum install centos-release-scl devtoolset-8 -y

# install intel icc icx

cd /data/down
tar zvxf  system_studio_2019_update_3_ultimate_edition_offline.tar.gz

cd /data/down/system_studio_2019_update_3_ultimate_edition_offline

cat &gt; s.cfg &lt;&lt; 'EOF'
ACCEPT_EULA=accept
CONTINUE_WITH_OPTIONAL_ERROR=yes
PSET_INSTALL_DIR=/opt/intel
CONTINUE_WITH_INSTALLDIR_OVERWRITE=yes
COMPONENTS=ALL
PSET_MODE=install
ACTIVATION_SERIAL_NUMBER=******************
ACTIVATION_TYPE=serial_number
EOF

./install.sh -s s.cfg

echo &quot;source  /opt/intel/system_studio_2019/bin/compilervars.sh intel64&quot; &gt;&gt; /root/.bashrc  


cd /data/down/

# wget https://registrationcenter-download.intel.com/akdlm/irc_nas/18236/l_BaseKit_p_2021.4.0.3422_offline.sh

bash l_BaseKit_p_2021.4.0.3422_offline.sh

# source /opt/intel/oneapi/setvars.sh
echo &quot;source /opt/intel/oneapi/setvars.sh&quot; &gt;&gt; /root/.bashrc  

</code></pre>
<h2 id="download-dpdk-and-patch-and-comile-flexran-sdk"><a class="header" href="#download-dpdk-and-patch-and-comile-flexran-sdk">download dpdk and patch, and comile flexran sdk</a></h2>
<pre><code class="language-bash">cd /data/down/

# wget https://fast.dpdk.org/rel/dpdk-19.11.tar.xz

tar xf dpdk-19.11.tar.xz
rm -rf /opt/dpdk-19.11
mv /data/down/dpdk-19.11 /opt

export RTE_SDK=/opt/dpdk-19.11
cd $RTE_SDK 
patch -p1 &lt; /data/down/dpdk_19.11_20.11.7.patch

# patch flexran
pip3 install meson ninja
# dnf install -y ninja-build

# dnf install -y cmake

rm -rf /data/flexran/
mkdir -p /data/flexran/
cd /data/down
tar zvxf FlexRAN-20.11.tar.gz -C /data/flexran/

export RTE_SDK=/opt/dpdk-19.11
cd /data/flexran
./extract.sh

cd /data/flexran
source set_env_var.sh -d
# for intel: /opt/intel/system_studio_2019/
# for dpdk: /opt/dpdk-19.11

# sourcing /opt/intel/system_studio_2019//bin/iccvars.sh  intel64 -platform linux
# Set RTE_SDK=/opt/dpdk-19.11
# Set RTE_TARGET=x86_64-native-linuxapp-icc


# ====================================================================================
# Environment Variables:
# ====================================================================================
# RTE_SDK=/opt/dpdk-19.11
# RTE_TARGET=x86_64-native-linuxapp-icc
# WIRELESS_SDK_TARGET_ISA=avx512
# RPE_DIR=/data/flexran/libs/ferrybridge
# CPA_DIR=/data/flexran/libs/cpa
# ROE_DIR=/data/flexran/libs/roe
# XRAN_DIR=/data/flexran/xran
# DIR_WIRELESS_SDK_ROOT=/data/flexran/sdk
# SDK_BUILD=build-avx512-icc
# DIR_WIRELESS_SDK=/data/flexran/sdk/build-avx512-icc
# FLEXRAN_SDK=/data/flexran/sdk/build-avx512-icc/install
# DIR_WIRELESS_FW=/data/flexran/framework
# DIR_WIRELESS_TEST_4G=/data/flexran/tests/lte
# DIR_WIRELESS_TEST_5G=/data/flexran/tests/nr5g
# DIR_WIRELESS_TABLE_5G=/data/flexran/bin/nr5g/gnb/l1/table
# ====================================================================================

./flexran_build.sh -e -r 5gnr_sub6 -i avx512 -m sdk

# https://www.i4k.xyz/article/qq_40982287/119571504
sed -i &quot;s/.ndo_tx_timeout = kni_net_tx_timeout,/\/\/.ndo_tx_timeout = kni_net_tx_timeout,/g&quot; /opt/dpdk-19.11/kernel/linux/kni/kni_net.c

sed -i 's/DEFAULT_PATH=.*/DEFAULT_PATH=\/opt\/intel\/system_studio_2019\/bin\/iccvars.sh/' /opt/dpdk-19.11/usertools/dpdk-setup.sh

sed -i 's/CONFIG_RTE_BBDEV_SDK_AVX2=.*/CONFIG_RTE_BBDEV_SDK_AVX2=y/' /opt/dpdk-19.11/config/common_base
sed -i 's/CONFIG_RTE_BBDEV_SDK_AVX512=.*/CONFIG_RTE_BBDEV_SDK_AVX512=y/' /opt/dpdk-19.11/config/common_base
# DEFAULT_PATH=/opt/intel/system_studio_2019/bin/iccvars.sh
# sed -i 's/CONFIG_RTE_BUILD_SHARED_LIB=.*/CONFIG_RTE_BUILD_SHARED_LIB=y/' /opt/dpdk-19.11/config/common_base

sed -i 's/MODULE_CFLAGS += -Wall -Werror/#MODULE_CFLAGS += -Wall -Werror/' /opt/dpdk-19.11/kernel/linux/kni/Makefile

cd /opt/dpdk-19.11/usertools/
./dpdk-setup.sh
# 39
# 62

sed -i 's/#include &lt;linux\/bootmem.h&gt;/\/\/#include &lt;linux\/bootmem.h&gt;/' /data/flexran/libs/cpa/sub6/rec/drv/src/nr_dev.c

# export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/flexran/wls_mod/lib

# export CC=icc

# export DEV_OPT=&quot; -Wl,--exclude-libs,/usr/lib64/libmvec_nonshared.a &quot;

# export LDFLAGS=&quot; -Wl,--exclude-libs,/usr/lib64/libmvec_nonshared.a &quot;

# export RTE_LIBS=&quot; -Wl,--exclude-libs,/usr/lib64/libmvec_nonshared.a &quot;

# -Wl,--exclude-libs=libmvec_nonshared.a
# -Wl,--allow-multiple-definition

sed -i 's/@$(LD) -o $@ $(LD_FLAGS) -Wl,-L $(BUILDDIR) $(INC_LIBS) -lm -lrt -lpthread/@$(LD) -o $@ $(LD_FLAGS) -Wl,-L $(BUILDDIR) $(INC_LIBS) -lm -lrt -lpthread  -Wl,--allow-multiple-definition/' /data/flexran/build/nr5g/gnb/l1app/makefile_phy

sed -i 's/@$(LD) -o $@ $(LD_FLAGS) -Wl,-L $(BUILDDIR) $(INC_LIBS) -lm -lrt -lpthread/@$(LD) -o $@ $(LD_FLAGS) -Wl,-L $(BUILDDIR) $(INC_LIBS) -lm -lrt -lpthread -Wl,--allow-multiple-definition -Wl,-lrte_port -Wl,-lrte_cryptodev -Wl,-lrte_eventdev/' /data/flexran/build/nr5g/gnb/testapp/linux/makefile_phy

sed -i 's/@$(LD) -o $@ $(LD_FLAGS) -Wl,-L $(BUILDDIR) $(INC_LIBS) -lm -lrt -lpthread/@$(LD) -o $@ $(LD_FLAGS) -Wl,-L $(BUILDDIR) $(INC_LIBS) -lm -lrt -lpthread -Wl,--allow-multiple-definition/' /data/flexran/build/lte/l1app_nbiot/makefile

sed -i 's/@$(LD) -o $@ $(LD_FLAGS) -Wl,-L $(BUILDDIR) $(INC_LIBS) -lm -lrt -lpthread/@$(LD) -o $@ $(LD_FLAGS) -Wl,-L $(BUILDDIR) $(INC_LIBS) -lm -lrt -lpthread -Wl,--allow-multiple-definition/' /data/flexran/build/lte/bbdevapp/Makefile

sed -i 's/@$(LD) -o $@ $(LD_FLAGS) -Wl,-L $(BUILDDIR) $(INC_LIBS) -lm -lrt -lpthread/@$(LD) -o $@ $(LD_FLAGS) -Wl,-L $(BUILDDIR) $(INC_LIBS) -lm -lrt -lpthread -Wl,--allow-multiple-definition/' /data/flexran/build/lte/l1app/makefile

sed -i 's/@$(LD) -o $@ $(LD_FLAGS) -Wl,-L $(BUILDDIR) $(INC_LIBS) -lm -lrt -lpthread/@$(LD) -o $@ $(LD_FLAGS) -Wl,-L $(BUILDDIR) $(INC_LIBS) -lm -lrt -lpthread -Wl,--allow-multiple-definition/' /data/flexran/build/nr5g/gnb/bbdevapp/Makefile

sed -i 's/@$(CC) -o $(APP) $(OBJS) $(RTE_LIBS) $(LDFLAGS)/@$(CC) -o $(APP) $(OBJS) $(RTE_LIBS) $(LDFLAGS) -Wl,--allow-multiple-definition/' /data/flexran/build/nr5g/gnb/testmac/makefile

sed -i 's/@$(CC) -o $(APP) $(OBJS) $(RTE_LIBS) $(LDFLAGS)/@$(CC) -o $(APP) $(OBJS) $(RTE_LIBS) $(LDFLAGS) -Wl,--allow-multiple-definition/' /data/flexran/build/lte/l1app_nbiot/makefile

# -Wl,-lrte_port -Wl,-lrte_cryptodev -Wl,-lrte_eventdev
# build/nr5g/gnb/testapp/linux/makefile_phy:540

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/flexran/wls_mod/lib

cd /data/flexran
./flexran_build.sh -e -r 5gnr_sub6 -i avx512 -b


# dnf install -y podman-docker

# export RTE_SDK=/opt/dpdk-19.11
# cd /data/flexran
# bash ./flexran_build_dockerfile.sh -v -e -i avx512 -r 5gnr_sub6 -b -m all

# podman image ls
# # REPOSITORY                           TAG         IMAGE ID      CREATED         SIZE
# # flexran.docker.registry/flexran_vdu  latest      8c5460a697e6  16 minutes ago  1.36 GB
# # quay.io/centos/centos                7.9.2009    8652b9f0cb4c  17 months ago   212 MB

# podman tag flexran.docker.registry/flexran_vdu:latest  quay.io/nepdemo/flexran_vdu:flexran-20.11-dpdk-20.11.3-ocp4.9.5-centos-7.9

# podman push quay.io/nepdemo/flexran_vdu:flexran-20.11-dpdk-20.11.3-ocp4.9.5-centos-7.9

</code></pre>
<h2 id="vsftpd"><a class="header" href="#vsftpd">vsftpd</a></h2>
<p>我们需要在本地准备一个ftp服务器，来承载rt-kernel的repo，后面编译容器镜像，需要访问这个临时的repo</p>
<pre><code class="language-bash">dnf install -y vsftpd
sed -i 's/anonymous_enable=NO/anonymous_enable=YES/g' /etc/vsftpd/vsftpd.conf
systemctl disable --now firewalld
systemctl enable --now vsftpd

mkdir -p /var/ftp/dnf
mount --bind /data/dnf /var/ftp/dnf
chcon -R -t public_content_t  /var/ftp/dnf
find /data/dnf/extensions -type f -exec chmod 644 {} \;

chmod +x /etc/rc.d/rc.local
cat &lt;&lt; EOF &gt;&gt;/etc/rc.d/rc.local

iptables -A INPUT -d 10.88.0.1 -j ACCEPT
iptables -A INPUT -p tcp --dport 21 -j REJECT

EOF
systemctl enable --now rc-local
</code></pre>
<h2 id="flexran_vdu-for-rhel84"><a class="header" href="#flexran_vdu-for-rhel84">flexran_vdu for rhel8.4</a></h2>
<pre><code class="language-bash">dnf install -y podman-docker

export RTE_SDK=/opt/dpdk-19.11
cd /data/flexran

bash ./flexran_build_dockerfile.wzh.sh -v -e -i avx512 -r 5gnr_sub6 -b -m all

podman tag flexran.docker.registry/flexran_vdu:latest  quay.io/nepdemo/flexran_vdu:flexran-20.11-dpdk-19.11-ocp4.9.5-ubi-8.4

podman push quay.io/nepdemo/flexran_vdu:flexran-20.11-dpdk-19.11-ocp4.9.5-ubi-8.4

</code></pre>
<!-- ## kernel module igb_uio

```bash

cd /data/git

cat << 'EOF' > ./flexran.sdk.dockerfile
FROM registry.access.redhat.com/ubi8/ubi-minimal

COPY dpdk-kmods /data/dpdk-kmods
EOF

cd /data/git
podman build --squash -t quay.io/nepdemo/flexran_vdu:dpdk-kmods-ocp-4.9.5-ubi -f flexran.sdk.dockerfile ./

podman push quay.io/nepdemo/flexran_vdu:dpdk-kmods-ocp-4.9.5-ubi

``` -->
<h2 id="copy-flexran-sdk-to-image"><a class="header" href="#copy-flexran-sdk-to-image">copy flexran sdk to image</a></h2>
<pre><code class="language-bash">cat &lt;&lt; 'EOF' &gt; /data/flexran.sdk.dockerfile
FROM registry.access.redhat.com/ubi8/ubi:8.4

RUN dnf repolist
RUN sed -i 's|enabled=1|enabled=0|g' /etc/yum/pluginconf.d/subscription-manager.conf
RUN sed -i 's|$releasever|8.4|g' /etc/yum.repos.d/redhat.repo
RUN sed -i '/codeready-builder-for-rhel-8-x86_64-rpms/,/\[/ s/enabled = 0/enabled = 1/' /etc/yum.repos.d/redhat.repo
RUN mv -f /etc/yum.repos.d/ubi.repo /etc/yum.repos.d/ubi.repo.bak

RUN dnf -y update
RUN dnf -y install rsync

COPY flexran /data/flexran
EOF

cd /data
podman build --squash -t quay.io/nepdemo/flexran_basekit:flexran-sdk-20.11-ocp-4.9.5-ubi-8.4 -f flexran.sdk.dockerfile ./

podman push quay.io/nepdemo/flexran_basekit:flexran-sdk-20.11-ocp-4.9.5-ubi-8.4

</code></pre>
<h2 id="copy-intel-icc-to-image"><a class="header" href="#copy-intel-icc-to-image">copy intel icc to image</a></h2>
<pre><code class="language-bash">cat &lt;&lt; 'EOF' &gt; /opt/intel/flexran.intel.icc.dockerfile
FROM registry.access.redhat.com/ubi8/ubi:8.4

RUN dnf repolist
RUN sed -i 's|enabled=1|enabled=0|g' /etc/yum/pluginconf.d/subscription-manager.conf
RUN sed -i 's|$releasever|8.4|g' /etc/yum.repos.d/redhat.repo
RUN sed -i '/codeready-builder-for-rhel-8-x86_64-rpms/,/\[/ s/enabled = 0/enabled = 1/' /etc/yum.repos.d/redhat.repo
RUN mv -f /etc/yum.repos.d/ubi.repo /etc/yum.repos.d/ubi.repo.bak

RUN dnf -y update
RUN dnf -y install rsync

COPY system_studio_2019 /opt/intel/system_studio_2019
COPY licenses /opt/intel/licenses
COPY packagemanager /opt/intel/packagemanager
EOF

cd /opt/intel
podman build --squash -t quay.io/nepdemo/flexran_basekit:intel.icc-21.11-ocp-4.9.5-ubi-8.4 -f flexran.intel.icc.dockerfile ./

podman push quay.io/nepdemo/flexran_basekit:intel.icc-21.11-ocp-4.9.5-ubi-8.4
</code></pre>
<h2 id="copy-intel-icx-to-image"><a class="header" href="#copy-intel-icx-to-image">copy intel icx to image</a></h2>
<pre><code class="language-bash">cat &lt;&lt; 'EOF' &gt; /opt/intel/flexran.intel.icx.dockerfile
FROM registry.access.redhat.com/ubi8/ubi:8.4

RUN dnf repolist
RUN sed -i 's|enabled=1|enabled=0|g' /etc/yum/pluginconf.d/subscription-manager.conf
RUN sed -i 's|$releasever|8.4|g' /etc/yum.repos.d/redhat.repo
RUN sed -i '/codeready-builder-for-rhel-8-x86_64-rpms/,/\[/ s/enabled = 0/enabled = 1/' /etc/yum.repos.d/redhat.repo
RUN mv -f /etc/yum.repos.d/ubi.repo /etc/yum.repos.d/ubi.repo.bak

RUN dnf -y update
RUN dnf -y install rsync

COPY oneapi /opt/intel/oneapi
COPY licenses /opt/intel/licenses
COPY packagemanager /opt/intel/packagemanager
EOF

cd /opt/intel
podman build --squash -t quay.io/nepdemo/flexran_basekit:intel.icx-21.11-ocp-4.9.5-ubi-8.4 -f flexran.intel.icx.dockerfile ./

podman push quay.io/nepdemo/flexran_basekit:intel.icx-21.11-ocp-4.9.5-ubi-8.4
</code></pre>
<h2 id="build-dev-docker-image-with-dpdk-1911"><a class="header" href="#build-dev-docker-image-with-dpdk-1911">build dev docker image with dpdk 19.11</a></h2>
<pre><code class="language-bash">cat &lt;&lt; 'EOF' &gt; /opt/flexran.dpdk.dockerfile
FROM registry.access.redhat.com/ubi8/ubi:8.4

RUN dnf repolist
RUN sed -i 's|enabled=1|enabled=0|g' /etc/yum/pluginconf.d/subscription-manager.conf
RUN sed -i 's|$releasever|8.4|g' /etc/yum.repos.d/redhat.repo
RUN sed -i '/codeready-builder-for-rhel-8-x86_64-rpms/,/\[/ s/enabled = 0/enabled = 1/' /etc/yum.repos.d/redhat.repo
RUN mv -f /etc/yum.repos.d/ubi.repo /etc/yum.repos.d/ubi.repo.bak

RUN echo -e &quot;\
[localrepo]\n\
name=LocalRepo\n\
baseurl=ftp://10.88.0.1/dnf/extensions/\n\
enabled=1\n\
gpgcheck=0&quot; \
&gt; /etc/yum.repos.d/local.repo

RUN dnf -y update
RUN dnf -y install rsync

RUN dnf -y install kernel-rt-core kernel-rt-devel kernel-rt-modules kernel-rt-modules-extra kernel-headers libhugetlbfs-devel zlib-devel numactl-devel cmake gcc gcc-c++ libhugetlbfs-utils libhugetlbfs-devel libhugetlbfs numactl-devel pciutils libaio libaio-devel net-tools libpcap python3-pip
RUN dnf install -y --allowerasing coreutils
RUN dnf groupinstall -y development server
RUN pip-3 install meson ninja

COPY dpdk-19.11 /opt/dpdk-19.11
# RUN ln -s /opt/dpdk-stable-20.11.3 /opt/dpdk-20.11

EOF

cd /opt/
podman build --squash -t quay.io/nepdemo/flexran_basekit:dpdk-19.11-ocp-4.9.5-ubi-8.4 -f flexran.dpdk.dockerfile ./

podman push quay.io/nepdemo/flexran_basekit:dpdk-19.11-ocp-4.9.5-ubi-8.4 

</code></pre>
<h1 id="build-in-nepdemo-env"><a class="header" href="#build-in-nepdemo-env">build in nepdemo env</a></h1>
<p>在nepdemo的内网环境中，编译镜像，并将镜像推送到nepdemo的镜像仓库</p>
<h2 id="create-a-image-registry-to-hold-the-large-container-image"><a class="header" href="#create-a-image-registry-to-hold-the-large-container-image">create a image registry to hold the large container image</a></h2>
<pre><code class="language-bash"># found a centos7 host

mkdir /etc/crts/ &amp;&amp; cd /etc/crts
openssl req \
   -newkey rsa:2048 -nodes -keyout redhat.ren.key \
   -x509 -days 3650 -out redhat.ren.crt -subj \
   &quot;/C=CN/ST=GD/L=SZ/O=Global Security/OU=IT Department/CN=*.redhat.ren&quot;

cp /etc/crts/redhat.ren.crt /etc/pki/ca-trust/source/anchors/
update-ca-trust extract

mkdir -p /home/data/registry
cd /data
# tar zxf registry.tgz
yum -y install docker-distribution

cat &lt;&lt; EOF &gt; /etc/docker-distribution/registry/config.yml
version: 0.1
log:
  fields:
    service: registry
storage:
    cache:
        layerinfo: inmemory
    filesystem:
        rootdirectory: /home/data/registry
    delete:
        enabled: true
http:
    addr: :5443
    tls:
       certificate: /etc/crts/redhat.ren.crt
       key: /etc/crts/redhat.ren.key
EOF
# systemctl restart docker
# systemctl stop docker-distribution
systemctl enable --now docker-distribution

</code></pre>
<h2 id="build-container-image-for-intel-sdk"><a class="header" href="#build-container-image-for-intel-sdk">build container image for intel sdk</a></h2>
<pre><code class="language-bash">cat &lt;&lt; EOF &gt;&gt;  /etc/hosts
192.168.123.252 reg-tmp.redhat.ren
EOF

export REG_TMP=&quot;reg-tmp.redhat.ren:5443&quot;

podman tag flexran.docker.registry/flexran_vdu:latest  ${REG_TMP}/nepdemo/flexran_vdu:flexran-20.11-dpdk-19.11-ocp4.9.5-ubi-8.4

podman push --tls-verify=false ${REG_TMP}/nepdemo/flexran_vdu:flexran-20.11-dpdk-19.11-ocp4.9.5-ubi-8.4

# copy flexran sdk to image
cd /data
podman build --squash -t ${REG_TMP}/nepdemo/flexran_basekit:flexran-sdk-20.11-ocp-4.9.5-ubi-8.4 -f flexran.sdk.dockerfile ./

podman push --tls-verify=false ${REG_TMP}/nepdemo/flexran_basekit:flexran-sdk-20.11-ocp-4.9.5-ubi-8.4

# dpdk-kmods
cd /data/git
podman build --squash -t ${REG_TMP}/nepdemo/flexran_vdu:dpdk-kmods-ocp-4.9.5-ubi -f flexran.sdk.dockerfile ./

podman push --tls-verify=false ${REG_TMP}/nepdemo/flexran_vdu:dpdk-kmods-ocp-4.9.5-ubi

# copy intel icc to image
cd /opt/intel
podman build --squash -t ${REG_TMP}/nepdemo/flexran_basekit:intel.icc-21.11-ocp-4.9.5-ubi-8.4 -f flexran.intel.icc.dockerfile ./

podman push --tls-verify=false ${REG_TMP}/nepdemo/flexran_basekit:intel.icc-21.11-ocp-4.9.5-ubi-8.4

# copy intel icx to image
cd /opt/intel
podman build --squash -t ${REG_TMP}/nepdemo/flexran_basekit:intel.icx-21.11-ocp-4.9.5-ubi-8.4 -f flexran.intel.icx.dockerfile ./

podman push --tls-verify=false ${REG_TMP}/nepdemo/flexran_basekit:intel.icx-21.11-ocp-4.9.5-ubi-8.4


# build dev docker image with dpdk 19.11
cat &lt;&lt; 'EOF' &gt; /opt/flexran.dpdk.dockerfile
FROM registry.access.redhat.com/ubi8/ubi:8.4

RUN dnf repolist
RUN sed -i 's|enabled=1|enabled=0|g' /etc/yum/pluginconf.d/subscription-manager.conf
RUN sed -i 's|$releasever|8.4|g' /etc/yum.repos.d/redhat.repo
RUN sed -i 's|cdn.redhat.com|china.cdn.redhat.com|g' /etc/yum.repos.d/redhat.repo
RUN sed -i '/codeready-builder-for-rhel-8-x86_64-rpms/,/\[/ s/enabled = 0/enabled = 1/' /etc/yum.repos.d/redhat.repo
RUN mv -f /etc/yum.repos.d/ubi.repo /etc/yum.repos.d/ubi.repo.bak

RUN echo -e &quot;\
[localrepo]\n\
name=LocalRepo\n\
baseurl=ftp://192.168.122.1/dnf/extensions/\n\
enabled=1\n\
gpgcheck=0&quot; \
&gt; /etc/yum.repos.d/local.repo

RUN dnf -y update
RUN dnf -y install rsync

RUN dnf -y install kernel-rt-core kernel-rt-devel kernel-rt-modules kernel-rt-modules-extra kernel-headers libhugetlbfs-devel zlib-devel numactl-devel cmake gcc gcc-c++ libhugetlbfs-utils libhugetlbfs-devel libhugetlbfs numactl-devel pciutils libaio libaio-devel net-tools libpcap python3-pip
RUN dnf install -y --allowerasing coreutils
RUN dnf groupinstall -y development server
RUN pip-3 install meson ninja

COPY dpdk-19.11 /opt/dpdk-19.11
# RUN ln -s /opt/dpdk-19.11 /opt/dpdk-20.11

EOF

cd /opt/
podman build --squash -t ${REG_TMP}/nepdemo/flexran_basekit:dpdk-19.11-ocp-4.9.5-ubi-8.4 -f flexran.dpdk.dockerfile ./

podman push --tls-verify=false ${REG_TMP}/nepdemo/flexran_basekit:dpdk-19.11-ocp-4.9.5-ubi-8.4 

</code></pre>
<h1 id="deploy-on-ocp-495"><a class="header" href="#deploy-on-ocp-495">deploy on ocp 4.9.5</a></h1>
<p>镜像都准备好了，我们开始在openshift4 上进行部署测试。</p>
<h2 id="set-security-for-temp-image-registry"><a class="header" href="#set-security-for-temp-image-registry">set security for temp image registry</a></h2>
<p>我们临时创建了一个镜像仓库，那么我们就要把这个配置放到集群里面去，主要是让ocp集群，不要检查这个新镜像仓库的证书。</p>
<ul>
<li><a href="https://access.redhat.com/solutions/4564851">How to remove worker role from master in Red Hat OpenShift Container Platform 4.x?</a></li>
</ul>
<pre><code class="language-bash">oc patch schedulers.config.openshift.io/cluster --type merge -p '{&quot;spec&quot;:{&quot;mastersSchedulable&quot;:false}}'

install /data/ocp4/clients/butane-amd64 /usr/local/bin/butane

cat &lt;&lt; EOF &gt; /data/sno/tmp.images.bu
variant: openshift
version: 4.9.0
metadata:
  labels:
    machineconfiguration.openshift.io/role: worker
  name: 99-zzz-worker-temp-images
storage:
  files:
    - path: /etc/containers/registries.conf.d/temp.registries.conf
      overwrite: true
      contents:
        inline: |

            [[registry]]
            location = &quot;tmp-registry.ocp4.redhat.ren:5443&quot;
            insecure = true
            blocked = false
            mirror-by-digest-only = false
            prefix = &quot;&quot;

EOF

butane /data/sno/tmp.images.bu &gt; /data/sno/99-zzz-worker-temp-images.yaml

oc create -f /data/sno/99-zzz-worker-temp-images.yaml

</code></pre>
<h2 id="set-a-host-path-dir-for-flexran-sdk"><a class="header" href="#set-a-host-path-dir-for-flexran-sdk">set a host-path dir for flexran sdk</a></h2>
<p>我们需要在 worker-2 上创建本地目录，好承载 flexran sdk, intel icc, intel icx 等超级大的目录和文件，主要是开发组有在容器平台做开发和测试的需求。如果是生成运行环境，这个本地目录是不应该存在的。</p>
<pre><code class="language-bash"># do not need, as it is already deployed
cat &lt;&lt; EOF &gt; /data/install/host-path.yaml
---
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfig
metadata:
  name: 50-set-selinux-for-hostpath-nepdemo-worker-rt-2
  labels:
    machineconfiguration.openshift.io/role: worker-rt-2
spec:
  config:
    ignition:
      version: 3.2.0
    systemd:
      units:
        - contents: |
            [Unit]
            Description=Set SELinux chcon for hostpath nepdemo
            Before=kubelet.service

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStartPre=-mkdir -p /var/nepdemo
            ExecStart=chcon -Rt container_file_t /var/nepdemo/

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: hostpath-nepdemo.service
EOF
oc create -f /data/install/host-path.yaml

</code></pre>
<h2 id="using-job-to-copy-files-to-local-path"><a class="header" href="#using-job-to-copy-files-to-local-path">using job to copy files to local path</a></h2>
<p>我们使用job的方式，把flexran sdk, intel icc/icx sdk复制到worker-2的本地目录，以便后续使用。用job的方式，主要考虑，这个是一次性的工作，并且我们在container image 里面还装了rsync，这样以后如果破坏了本地目录，重新运行以下job，就可以很快的同步目录。</p>
<pre><code class="language-bash">
export REG_TMP='tmp-registry.ocp4.redhat.ren:5443'

# copy dpdk to local
cat &lt;&lt; EOF &gt; /data/install/job.flexran.dpdk.yaml
---
apiVersion: batch/v1
kind: Job
metadata:
  name: flexran.basekit.dpdk.copy
  namespace: default
spec:
  template:
    spec:
      containers:
      - name: files
        image: ${REG_TMP}/nepdemo/flexran_basekit:dpdk-19.11-ocp-4.9.5-ubi-8.4 
        command: [ &quot;/bin/sh&quot;,&quot;-c&quot;,&quot;--&quot; ]
        # command: [&quot;rsync&quot;, &quot;--delete&quot;, &quot;-arz&quot;, &quot;/opt/dpdk-19.11&quot;, &quot;/nepdemo/&quot;]
        args: [&quot; rsync -P --delete -arz /opt/dpdk-19.11 /nepdemo/ &quot;]
        volumeMounts:
          - name: nepdemo
            mountPath: /nepdemo
      restartPolicy: Never
      nodeName: worker-2.ocp4.redhat.ren
      volumes:
        - name: nepdemo
          hostPath:
            path: /var/nepdemo      
EOF

oc create -f /data/install/job.flexran.dpdk.yaml

# copy flexran sdk to local
cat &lt;&lt; EOF &gt; /data/install/job.flexran.sdk.yaml
---
apiVersion: batch/v1
kind: Job
metadata:
  name: flexran.basekit.sdk.copy
  namespace: default
spec:
  template:
    spec:
      containers:
      - name: files
        image: ${REG_TMP}/nepdemo/flexran_basekit:flexran-sdk-20.11-ocp-4.9.5-ubi-8.4
        command: [ &quot;/bin/sh&quot;,&quot;-c&quot;,&quot;--&quot; ]
        # command: [&quot;rsync&quot;, &quot;--delete&quot;, &quot;-arz&quot;, &quot;/data/flexran&quot;, &quot;/nepdemo/&quot;]
        args: [&quot; rsync -P --delete -arz /data/flexran /nepdemo/ &quot;]
        volumeMounts:
          - name: nepdemo
            mountPath: /nepdemo
      restartPolicy: Never
      nodeName: worker-2.ocp4.redhat.ren
      volumes:
        - name: nepdemo
          hostPath:
            path: /var/nepdemo      
EOF

oc create -f /data/install/job.flexran.sdk.yaml

# copy intel icc sdk to local
cat &lt;&lt; EOF &gt; /data/install/job.intel.icc.yaml
---
apiVersion: batch/v1
kind: Job
metadata:
  name: flexran.basekit.intel.icc.copy
  namespace: default
spec:
  template:
    spec:
      containers:
      - name: files
        image: ${REG_TMP}/nepdemo/flexran_basekit:intel.icc-21.11-ocp-4.9.5-ubi-8.4
        command: [ &quot;/bin/sh&quot;,&quot;-c&quot;,&quot;--&quot; ]
        # command: [&quot;rsync&quot;, &quot;--delete&quot;, &quot;-arz&quot;, &quot;/opt/intel/system_studio_2019&quot;, &quot;/nepdemo/&quot;]
        args: [&quot; rsync -P --delete -arz /opt/intel/system_studio_2019 /nepdemo/ &quot;]
        volumeMounts:
          - name: nepdemo
            mountPath: /nepdemo
      restartPolicy: Never
      nodeName: worker-2.ocp4.redhat.ren
      volumes:
        - name: nepdemo
          hostPath:
            path: /var/nepdemo      
EOF

oc create -f /data/install/job.intel.icc.yaml

# copy intel icx sdk to local
cat &lt;&lt; EOF &gt; /data/install/job.intel.icx.yaml
---
apiVersion: batch/v1
kind: Job
metadata:
  name: flexran.basekit.intel.icx.copy
  namespace: default
spec:
  template:
    spec:
      containers:
      - name: files
        image: ${REG_TMP}/nepdemo/flexran_basekit:intel.icx-21.11-ocp-4.9.5-ubi-8.4
        command: [ &quot;/bin/sh&quot;,&quot;-c&quot;,&quot;--&quot; ]
        # command: [&quot;rsync&quot;, &quot;--delete&quot;, &quot;-arz&quot;, &quot;/opt/intel/oneapi&quot;, &quot;/nepdemo/&quot;]
        args: [&quot; rsync -P --delete -arz /opt/intel/oneapi /nepdemo/ &quot;]
        volumeMounts:
          - name: nepdemo
            mountPath: /nepdemo
      restartPolicy: Never
      nodeName: worker-2.ocp4.redhat.ren
      volumes:
        - name: nepdemo
          hostPath:
            path: /var/nepdemo      
EOF

oc create -f /data/install/job.intel.icx.yaml

# copy intel license to local
cat &lt;&lt; EOF &gt; /data/install/job.intel.license.yaml
---
apiVersion: batch/v1
kind: Job
metadata:
  name: flexran.basekit.intel.icx.copy
  namespace: default
spec:
  template:
    spec:
      containers:
      - name: files
        image: ${REG_TMP}/nepdemo/flexran_basekit:intel.icx-21.11-ocp-4.9.5-ubi-8.4
        command: [ &quot;/bin/sh&quot;,&quot;-c&quot;,&quot;--&quot; ]
        args: [&quot;rsync -P --delete -arz /opt/intel/licenses /nepdemo/ ; rsync -P --delete -arz /opt/intel/packagemanager /nepdemo/ &quot;]
        volumeMounts:
          - name: nepdemo
            mountPath: /nepdemo
      restartPolicy: Never
      nodeName: worker-2.ocp4.redhat.ren
      volumes:
        - name: nepdemo
          hostPath:
            path: /var/nepdemo      
EOF

oc create -f /data/install/job.intel.license.yaml

</code></pre>
<h2 id="setup-sriov-operator"><a class="header" href="#setup-sriov-operator">setup sriov operator</a></h2>
<p>openshift有sriov的operator，官方支持intel x710网卡，我们直接用就好了。</p>
<ul>
<li><a href="https://docs.openshift.com/container-platform/4.9/networking/hardware_networks/about-sriov.html">Single Root I/O Virtualization (SR-IOV) hardware networks</a></li>
</ul>
<p>the env has nic Intel X710 : 8086 1572</p>
<pre><code class="language-bash"># install sriov operator
cat &lt;&lt; EOF &gt; /data/install/sriov.yaml
---
apiVersion: v1
kind: Namespace
metadata:
  name: openshift-sriov-network-operator
  annotations:
    workload.openshift.io/allowed: management
---
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: sriov-network-operators
  namespace: openshift-sriov-network-operator
spec:
  targetNamespaces:
  - openshift-sriov-network-operator
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: sriov-network-operator-subscription
  namespace: openshift-sriov-network-operator
spec:
  channel: &quot;4.9&quot;
  installPlanApproval: Manual
  name: sriov-network-operator
  source: redhat-operators
  sourceNamespace: openshift-marketplace
EOF
oc create -f /data/install/sriov.yaml

</code></pre>
<p><img src="imgs/20220506230756.png" alt="" /></p>
<pre><code class="language-bash">oc get SriovNetworkNodeState -n openshift-sriov-network-operator
# NAME                       AGE
# master-0                   42m
# worker-0.ocp4.redhat.ren   42m
# worker-1                   42m
# worker-2.ocp4.redhat.ren   42m

oc get SriovNetworkNodeState/worker-2.ocp4.redhat.ren -n openshift-sriov-network-operator -o yaml
# apiVersion: sriovnetwork.openshift.io/v1
# kind: SriovNetworkNodeState
# metadata:
#   creationTimestamp: &quot;2022-05-06T14:34:54Z&quot;
#   generation: 1
#   name: worker-2.ocp4.redhat.ren
#   namespace: openshift-sriov-network-operator
#   ownerReferences:
#   - apiVersion: sriovnetwork.openshift.io/v1
#     blockOwnerDeletion: true
#     controller: true
#     kind: SriovNetworkNodePolicy
#     name: default
#     uid: 4eca5eea-e1e5-410f-8833-dd2de1434e53
#   resourceVersion: &quot;70932404&quot;
#   uid: 1d122c8e-b788-4f1e-a3d5-865c6230a476
# spec:
#   dpConfigVersion: &quot;70930693&quot;
# status:
#   interfaces:
#   - deviceID: &quot;1572&quot;
#     driver: i40e
#     linkSpeed: -1 Mb/s
#     linkType: ETH
#     mac: 90:e2:ba:a8:29:e6
#     mtu: 1500
#     name: ens2f0
#     pciAddress: 0000:65:00.0
#     totalvfs: 64
#     vendor: &quot;8086&quot;
#   - deviceID: &quot;1572&quot;
#     driver: i40e
#     linkSpeed: -1 Mb/s
#     linkType: ETH
#     mac: 90:e2:ba:a8:29:e7
#     mtu: 1500
#     name: ens2f1
#     pciAddress: 0000:65:00.1
#     totalvfs: 64
#     vendor: &quot;8086&quot;
#   - deviceID: 37d1
#     driver: i40e
#     linkSpeed: 1000 Mb/s
#     linkType: ETH
#     mac: ac:1f:6b:ea:5b:32
#     mtu: 1500
#     name: eno1
#     pciAddress: 0000:b5:00.0
#     totalvfs: 32
#     vendor: &quot;8086&quot;
#   - deviceID: 37d1
#     driver: i40e
#     linkSpeed: 1000 Mb/s
#     linkType: ETH
#     mac: ac:1f:6b:ea:5b:33
#     mtu: 1500
#     name: eno2
#     pciAddress: 0000:b5:00.1
#     totalvfs: 32
#     vendor: &quot;8086&quot;
#   syncStatus: Succeeded

# how to use the sriov to create VF and attach to pod, depends on use case from nep demo request
# remember to active SRIOV in bios
# remember to active VT-d in bios
cat &lt;&lt; EOF &gt; /data/install/sriov.policy.yaml
---
apiVersion: sriovnetwork.openshift.io/v1
kind: SriovNetworkNodePolicy
metadata:
  name: policy-710-nic01-rt2
  namespace: openshift-sriov-network-operator
spec:
  resourceName: intel_710_nic01_rt2
  nodeSelector:
    kubernetes.io/hostname: worker-2.ocp4.redhat.ren
  numVfs: 4
  nicSelector:
    vendor: &quot;8086&quot;
    deviceID: &quot;1572&quot;
    rootDevices:
      - &quot;0000:65:00.0&quot;
    # pfNames:
    #   - &quot;ens2f0&quot;
  # linkType: eth
  # isRdma: false
  deviceType: vfio-pci 
---
apiVersion: sriovnetwork.openshift.io/v1
kind: SriovNetworkNodePolicy
metadata:
  name: policy-710-nic02-rt2
  namespace: openshift-sriov-network-operator
spec:
  resourceName: intel_710_nic02_rt2
  nodeSelector:
    kubernetes.io/hostname: worker-2.ocp4.redhat.ren
  numVfs: 4
  nicSelector:
    vendor: &quot;8086&quot;
    deviceID: &quot;1572&quot;
    rootDevices:
      - &quot;0000:65:00.1&quot;
    # pfNames:
    #   - &quot;ens2f1&quot;
  # linkType: eth
  # isRdma: false
  deviceType: vfio-pci 
EOF
oc create -f /data/install/sriov.policy.yaml

# oc delete -f /data/install/sriov.policy.yaml

oc get sriovnetworknodestates/worker-2.ocp4.redhat.ren -n openshift-sriov-network-operator  -o jsonpath='{.status.syncStatus}' &amp;&amp; echo
# Succeeded


cat &lt;&lt; EOF &gt; /data/install/sriov.attach.yaml
---
apiVersion: sriovnetwork.openshift.io/v1
kind: SriovNetwork
metadata:
  name: intel-710-nic01-rt2
  namespace: openshift-sriov-network-operator
spec:
  resourceName: intel_710_nic01_rt2
  networkNamespace: vbbu-demo
  ipam: |-
    {
      &quot;type&quot;: &quot;static&quot;,
      &quot;addresses&quot;: [
        {
          &quot;address&quot;: &quot;192.168.12.21/24&quot;
        }
      ]
    }
---
apiVersion: sriovnetwork.openshift.io/v1
kind: SriovNetwork
metadata:
  name: intel-710-nic02-rt2
  namespace: openshift-sriov-network-operator
spec:
  resourceName: intel_710_nic02_rt2
  networkNamespace: vbbu-demo
  # ipam: |-
  #   {
  #     &quot;type&quot;: &quot;dhcp&quot;
  #   }
  ipam: |-
    {
      &quot;type&quot;: &quot;static&quot;,
      &quot;addresses&quot;: [
        {
          &quot;address&quot;: &quot;192.168.22.21/24&quot;
        }
      ]
    }  
EOF
oc create -f /data/install/sriov.attach.yaml

# oc delete -f /data/install/sriov.attach.yaml

oc get net-attach-def -n vbbu-demo
# NAME                  AGE
# intel-710-nic01-rt2   34s
# intel-710-nic02-rt2   34s


</code></pre>
<h2 id="setup-fec-sriov-operator"><a class="header" href="#setup-fec-sriov-operator">setup fec sriov operator</a></h2>
<p>intel已经给自己的FEC加速卡做好了operator，还有非常详细的文档，我们很幸福的直接用就好了。</p>
<p><img src="imgs/20220506232629.png" alt="" /></p>
<ul>
<li><a href="https://github.com/smart-edge-open/sriov-fec-operator/blob/main/spec/openshift-sriov-fec-operator.md">SEO Operator for Wireless FEC Accelerators documentation</a></li>
<li><a href="https://github.com/smart-edge-open/sriov-fec-operator/blob/main/spec/vran-accelerators-supported-by-operator.md">Intel's vRAN accelerators supported by SEO Operators on OpenShift</a></li>
</ul>
<pre><code class="language-bash"># install sriov operator
cat &lt;&lt; EOF &gt; /data/install/sriov.fec.yaml
---
apiVersion: v1
kind: Namespace
metadata:
  name: vran-acceleration-operators
  annotations:
    workload.openshift.io/allowed: management
  labels:
     openshift.io/cluster-monitoring: &quot;true&quot;
---
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: vran-operators
  namespace: vran-acceleration-operators
spec:
  targetNamespaces:
    - vran-acceleration-operators
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: sriov-fec-subscription
  namespace: vran-acceleration-operators
spec:
  channel: stable
  installPlanApproval: Manual
  name: sriov-fec
  source: certified-operators
  sourceNamespace: openshift-marketplace
EOF
oc create -f /data/install/sriov.fec.yaml

oc get csv -n vran-acceleration-operators
# NAME                                DISPLAY                                             VERSION   REPLACES   PHASE
# performance-addon-operator.v4.9.0   Performance Addon Operator                          4.9.0                Succeeded
# sriov-fec.v2.2.1                    SEO SR-IOV Operator for Wireless FEC Accelerators   2.2.1                Succeeded

oc get sriovfecnodeconfig -n vran-acceleration-operators 
# No resources found in vran-acceleration-operators namespace.

cat &lt;&lt; EOF &gt; /data/install/sriov.fec.config.yaml
apiVersion: sriovfec.intel.com/v2
kind: SriovFecClusterConfig
metadata:
  name: config
  namespace: vran-acceleration-operators 
spec:
  priority: 1
  nodeSelector:
    kubernetes.io/hostname: worker-2.ocp4.redhat.ren
  acceleratorSelector:
    pciAddress: 0000:17:00.0
  physicalFunction:  
    pfDriver: &quot;pci-pf-stub&quot;
    vfDriver: &quot;vfio-pci&quot;
    vfAmount: 16
    bbDevConfig:
      acc100:
        # Programming mode: 0 = VF Programming, 1 = PF Programming
        # true = PF Programming, false = VF Programming
        pfMode: true
        numVfBundles: 16
        maxQueueSize: 1024
        uplink4G:
          numQueueGroups: 0
          numAqsPerGroups: 16
          aqDepthLog2: 4
        downlink4G:
          numQueueGroups: 0
          numAqsPerGroups: 16
          aqDepthLog2: 4
        uplink5G:
          numQueueGroups: 4
          numAqsPerGroups: 16
          aqDepthLog2: 4
        downlink5G:
          numQueueGroups: 4
          numAqsPerGroups: 16
          aqDepthLog2: 4
EOF
oc create -f /data/install/sriov.fec.config.yaml

# oc delete -f /data/install/sriov.fec.config.yaml

oc get sriovfecnodeconfig -n vran-acceleration-operators
# NAME                       CONFIGURED
# worker-2.ocp4.redhat.ren   Succeeded

oc get sriovfecnodeconfig -n vran-acceleration-operators worker-2.ocp4.redhat.ren -o yaml
# apiVersion: sriovfec.intel.com/v2
# kind: SriovFecNodeConfig
# metadata:
#   creationTimestamp: &quot;2022-05-09T06:51:45Z&quot;
#   generation: 2
#   name: worker-2.ocp4.redhat.ren
#   namespace: vran-acceleration-operators
#   resourceVersion: &quot;72789505&quot;
#   uid: 265c42ae-f898-407c-a4bc-7f17aa8b94bb
# spec:
#   physicalFunctions:
#   - bbDevConfig:
#       acc100:
#         downlink4G:
#           aqDepthLog2: 4
#           numAqsPerGroups: 16
#           numQueueGroups: 0
#         downlink5G:
#           aqDepthLog2: 4
#           numAqsPerGroups: 16
#           numQueueGroups: 4
#         maxQueueSize: 1024
#         numVfBundles: 16
#         pfMode: true
#         uplink4G:
#           aqDepthLog2: 4
#           numAqsPerGroups: 16
#           numQueueGroups: 0
#         uplink5G:
#           aqDepthLog2: 4
#           numAqsPerGroups: 16
#           numQueueGroups: 4
#     pciAddress: &quot;0000:17:00.0&quot;
#     pfDriver: pci-pf-stub
#     vfAmount: 16
#     vfDriver: vfio-pci
# status:
#   conditions:
#   - lastTransitionTime: &quot;2022-05-09T12:48:10Z&quot;
#     message: Configured successfully
#     observedGeneration: 2
#     reason: Succeeded
#     status: &quot;True&quot;
#     type: Configured
#   inventory:
#     sriovAccelerators:
#     - deviceID: 0d5c
#       driver: pci-pf-stub
#       maxVirtualFunctions: 16
#       pciAddress: &quot;0000:17:00.0&quot;
#       vendorID: &quot;8086&quot;
#       virtualFunctions:
#       - deviceID: 0d5d
#         driver: vfio-pci
#         pciAddress: &quot;0000:18:00.0&quot;
#       - deviceID: 0d5d
#         driver: vfio-pci
#         pciAddress: &quot;0000:18:00.1&quot;
#       - deviceID: 0d5d
#         driver: vfio-pci
#         pciAddress: &quot;0000:18:01.2&quot;
#       - deviceID: 0d5d
#         driver: vfio-pci
#         pciAddress: &quot;0000:18:01.3&quot;
#       - deviceID: 0d5d
#         driver: vfio-pci
#         pciAddress: &quot;0000:18:01.4&quot;
#       - deviceID: 0d5d
#         driver: vfio-pci
#         pciAddress: &quot;0000:18:01.5&quot;
#       - deviceID: 0d5d
#         driver: vfio-pci
#         pciAddress: &quot;0000:18:01.6&quot;
#       - deviceID: 0d5d
#         driver: vfio-pci
#         pciAddress: &quot;0000:18:01.7&quot;
#       - deviceID: 0d5d
#         driver: vfio-pci
#         pciAddress: &quot;0000:18:00.2&quot;
#       - deviceID: 0d5d
#         driver: vfio-pci
#         pciAddress: &quot;0000:18:00.3&quot;
#       - deviceID: 0d5d
#         driver: vfio-pci
#         pciAddress: &quot;0000:18:00.4&quot;
#       - deviceID: 0d5d
#         driver: vfio-pci
#         pciAddress: &quot;0000:18:00.5&quot;
#       - deviceID: 0d5d
#         driver: vfio-pci
#         pciAddress: &quot;0000:18:00.6&quot;
#       - deviceID: 0d5d
#         driver: vfio-pci
#         pciAddress: &quot;0000:18:00.7&quot;
#       - deviceID: 0d5d
#         driver: vfio-pci
#         pciAddress: &quot;0000:18:01.0&quot;
#       - deviceID: 0d5d
#         driver: vfio-pci
#         pciAddress: &quot;0000:18:01.1&quot;



</code></pre>
<h2 id="setup-ptp"><a class="header" href="#setup-ptp">setup ptp</a></h2>
<p>intel flexran文档里面说，必须要用ptp，这个正常，在o-ran架构中，ptp是必须的。</p>
<ul>
<li><a href="https://docs.openshift.com/container-platform/4.9/networking/using-ptp.html">Using PTP hardware</a></li>
</ul>
<pre><code class="language-bash"># install ptp operator
cat &lt;&lt; EOF &gt; /data/install/ptp.yaml
---
apiVersion: v1
kind: Namespace
metadata:
  name: openshift-ptp
  annotations:
    workload.openshift.io/allowed: management
  labels:
    name: openshift-ptp
    openshift.io/cluster-monitoring: &quot;true&quot;
---
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: ptp-operators
  namespace: openshift-ptp
spec:
  targetNamespaces:
  - openshift-ptp
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: ptp-operator-subscription
  namespace: openshift-ptp
spec:
  channel: &quot;4.9&quot;
  installPlanApproval: Manual
  name: ptp-operator
  source: redhat-operators
  sourceNamespace: openshift-marketplace
EOF
oc create -f /data/install/ptp.yaml

oc get csv -n openshift-ptp
# NAME                                DISPLAY                      VERSION              REPLACES   PHASE
# performance-addon-operator.v4.9.0   Performance Addon Operator   4.9.0                           Succeeded
# ptp-operator.4.9.0-202204211825     PTP Operator                 4.9.0-202204211825              Succeeded

oc get csv -n openshift-ptp \
  -o custom-columns=Name:.metadata.name,Phase:.status.phase
# Name                                Phase
# performance-addon-operator.v4.9.0   Succeeded
# ptp-operator.4.9.0-202204211825     Succeeded

# as nepdemo request, disable phc2sys service, but we enabled it.
# 坑爹的 ptp4lConf 配置，我查了源代码才知道，他不能有空行
cat &lt;&lt; EOF &gt; /data/install/ptp.config.yaml
apiVersion: ptp.openshift.io/v1
kind: PtpConfig
metadata:
  name: ordinary-clock-ptp-config-worker-2 
  namespace: openshift-ptp
spec:
  profile: 
  - name: &quot;profile1&quot; 
    interface: &quot;ens2f1&quot; 
    ptp4lOpts: &quot;-2 -m&quot; 
    phc2sysOpts: &quot;-a -r&quot; 
    ptp4lConf: |-
      [global]
      #
      # Default Data Set
      #
      twoStepFlag             1
      slaveOnly               0
      priority1               128
      priority2               128
      domainNumber            24
      #utc_offset             37
      clockClass              248
      clockAccuracy           0xFE
      offsetScaledLogVariance 0xFFFF
      free_running            0
      freq_est_interval       1
      dscp_event              0
      dscp_general            0
      dataset_comparison      ieee1588
      G.8275.defaultDS.localPriority  128
      #
      # Port Data Set
      # 16 TS a second use logSyncInterval  -4
      logAnnounceInterval     1
      logSyncInterval         -4
      logMinDelayReqInterval  0
      logMinPdelayReqInterval 0
      announceReceiptTimeout  3
      syncReceiptTimeout      0
      delayAsymmetry          0
      fault_reset_interval    4
      neighborPropDelayThresh 20000000
      masterOnly              0
      G.8275.portDS.localPriority     128
      #
      # Run time options
      #
      assume_two_step         0
      logging_level           6
      path_trace_enabled      0
      follow_up_info          0
      hybrid_e2e              0
      inhibit_multicast_service       0
      net_sync_monitor        0
      tc_spanning_tree        0
      tx_timestamp_timeout    1
      unicast_listen          0
      unicast_master_table    0
      unicast_req_duration    3600
      use_syslog              1
      verbose                 0
      summary_interval        0
      kernel_leap             1
      check_fup_sync          0
      #
      # Servo Options
      #
      pi_proportional_const   0.0
      pi_integral_const       0.0
      pi_proportional_scale   0.0
      pi_proportional_exponent        -0.3
      pi_proportional_norm_max        0.7
      pi_integral_scale       0.0
      pi_integral_exponent    0.4
      pi_integral_norm_max    0.3
      step_threshold          0.0
      first_step_threshold    0.00002
      max_frequency           900000000
      clock_servo             pi
      sanity_freq_limit       200000000
      ntpshm_segment          0
      #
      # Transport options
      #
      transportSpecific       0x0
      ptp_dst_mac             01:1B:19:00:00:00
      p2p_dst_mac             01:80:C2:00:00:0E
      udp_ttl                 1
      udp6_scope              0x0E
      uds_address             /var/run/ptp4l
      #
      # Default interface options
      #
      clock_type              OC
      network_transport       UDPv4
      delay_mechanism         E2E
      time_stamping           hardware
      tsproc_mode             filter
      delay_filter            moving_median
      delay_filter_length     10
      egressLatency           0
      ingressLatency          0
      boundary_clock_jbod     0
      #
      # Clock description
      #
      productDescription      ;;
      revisionData            ;;
      manufacturerIdentity    00:00:00
      userDescription         ;
      timeSource              0xA0
    ptpSchedulingPolicy: SCHED_FIFO  
    ptpSchedulingPriority: 65 
  recommend: 
  - profile: &quot;profile1&quot; 
    priority: 10 
    match: 
    - nodeLabel: &quot;node-role.kubernetes.io/worker&quot; 
      nodeName: &quot;worker-2.ocp4.redhat.ren&quot; 
EOF
oc create -f /data/install/ptp.config.yaml

# oc delete -f /data/install/ptp.config.yaml

</code></pre>
<h2 id="create-deployment--put-all-together-"><a class="header" href="#create-deployment--put-all-together-">create deployment ( put all together )</a></h2>
<p>最终，我们可以拼装出一个完整的部署，我们的部署是一个 pod 里面有 2 个 container。一个 container 是 vbbu 应用的 container ， 按照 intel sdk 中的方法来搞，也就是尽量只把编译后的应用程序本身放进来，而不是把其他的依赖包放进来。这样镜像就会比较小，大概2G左右。 另外一个container是开发用的，因为开发组需要一个开发环境，把东西编译好，然后复制到 vbbu 应用的那个container里面去。</p>
<p>在这里，flexran-release-running 这个container就是最终运行用的。而flexran-dev-env就是开发环境。</p>
<p>目前这个版本是开发版，未来开发测试结束，将把flexran-dev-env取消，另外本地host-path的目录，也会删除，也就是本地的intel sdk都删掉。</p>
<pre><code class="language-bash">
oc new-project vbbu-demo

oc project vbbu-demo

export REG_TMP='tmp-registry.ocp4.redhat.ren:5443'

# kernel driver deployment
oc create serviceaccount svcacct-driver -n vbbu-demo
oc adm policy add-scc-to-user privileged -z svcacct-driver -n vbbu-demo
# oc adm policy add-scc-to-user anyuid -z mysvcacct -n vbbu-demo

cat &lt;&lt; EOF &gt; /data/install/dpdk.kmod.driver.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dpdk-kmod-driver
  # namespace: default
  labels:
    app: dpdk-kmod-driver
spec:
  replicas: 1
  selector:
    matchLabels:
      app: dpdk-kmod-driver
  template:
    metadata:
      labels:
        app: dpdk-kmod-driver
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: &quot;app&quot;
                    operator: In
                    values:
                    - dpdk-kmod-driver
              topologyKey: &quot;kubernetes.io/hostname&quot;
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/hostname
                operator: In
                values:
                - worker-2.ocp4.redhat.ren
      # restartPolicy: Never
      serviceAccountName: svcacct-driver
      initContainers:
      - name: copy
        image: ${REG_TMP}/nepdemo/flexran_vdu:dpdk-kmods-ocp-4.9.5-ubi
        command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;--&quot;]
        args: [&quot;/bin/cp -rf /data/* /nepdemo/&quot;]
        # imagePullPolicy: Always
        volumeMounts:
        - name: driver-files
          mountPath: /nepdemo
      containers:
      - name: driver
        image: ${REG_TMP}/nepdemo/flexran_vdu:flexran-20.11-dpdk-19.11-ocp4.9.5-ubi-8.4
        imagePullPolicy: Always
        command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;--&quot;]
        args: [&quot;insmod /nepdemo/dpdk-kmods/linux/igb_uio/igb_uio.ko ; sleep infinity ;&quot;]
        resources:
          requests:
            cpu: 10m
            memory: 20Mi
        securityContext:
          privileged: true
          runAsUser: 0
        volumeMounts:
        - name: driver-files
          mountPath: /nepdemo
        # - name: host
        #   mountPath: /host
      volumes: 
      - name: driver-files
        emptyDir: {}
      # - name: host
      #   hostPath:
      #     path: /
      #     type: Directory
EOF
oc create -n vbbu-demo -f /data/install/dpdk.kmod.driver.yaml

# to restore
# oc delete -f /data/install/dpdk.kmod.driver.yaml


# the pod with vbbu container and dev container
# later, it will change to deployment
cat &lt;&lt; EOF &gt; /data/install/vran.intel.flexran.yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flexran-binary-release-deployment
  labels:
    app: flexran-binary-release-deployment
spec:
  replicas: 1
  selector:
    matchLabels:
      app: flexran-binary-release
  template:
    metadata:
      labels:
        app: flexran-binary-release
      name: flexran-binary-release
      annotations:
        k8s.v1.cni.cncf.io/networks: |-
          [
            {
              &quot;name&quot;: &quot;intel-710-nic01-rt2&quot;,
              &quot;mac&quot;: &quot;00:11:22:33:44:01&quot;
            },
            {
              &quot;name&quot;: &quot;intel-710-nic02-rt2&quot;,
              &quot;mac&quot;: &quot;00:11:22:33:44:02&quot;
            }
          ]
      cpu-load-balancing.crio.io: &quot;true&quot;
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: &quot;app&quot;
                    operator: In
                    values:
                    - flexran-binary-release
              topologyKey: &quot;kubernetes.io/hostname&quot;
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/hostname
                operator: In
                values:
                - worker-2.ocp4.redhat.ren
      # nodeSelector:
      #   kubernetes.io/hostname: worker-2.ocp4.redhat.ren
      runtimeClassName: performance-wzh-performanceprofile-2
      serviceAccountName: svcacct-driver
      containers:
      - securityContext:
          privileged: false
          capabilities:
            add:
              #- SYS_ADMIN
              - IPC_LOCK
              - SYS_NICE
              - SYS_RESOURCE
              - NET_RAW
        command: [ &quot;/sbin/init&quot; ]
        # command: [ &quot;/bin/sh&quot;,&quot;-c&quot;,&quot;--&quot; ]
        # args: [&quot;  sleep infinity ; &quot;]
        # tty: true
        # stdin: true
        image: ${REG_TMP}/nepdemo/flexran_vdu:flexran-20.11-dpdk-19.11-ocp4.9.5-ubi-8.4
        # image: ${REG_TMP}/nepdemo/flexran_basekit:dpdk-19.11-ocp-4.9.5-ubi-8.4 
        # imagePullPolicy: Always
        name: flexran-release-running
        resources:
          requests:
            memory: &quot;24Gi&quot; 
            intel.com/intel_fec_acc100: '1'
            hugepages-1Gi: 16Gi  
          limits:
            memory: &quot;24Gi&quot;
            intel.com/intel_fec_acc100: '1'
            hugepages-1Gi: 16Gi
        volumeMounts:
        - name: hugepage
          mountPath: /hugepages
        - name: varrun
          mountPath: /var/run/dpdk
          readOnly: false
        # - name: oneapi
        #   mountPath: /opt/intel/oneapi
        #   readOnly: false
        # - name: system-studio-2019
        #   mountPath: /opt/intel/system_studio_2019
        #   readOnly: false   
        # - name: licenses
        #   mountPath: /opt/intel/licenses
        #   readOnly: false
        # - name: packagemanager
        #   mountPath: /opt/intel/packagemanager
        #   readOnly: false 
        - name: dpdk-19-11
          mountPath: /opt/dpdk-19.11
          readOnly: false
        - name: flexran
          mountPath: /data/flexran
          readOnly: false   
        - name: sys
          mountPath: /sys/
          readOnly: false

      - securityContext:
          privileged: false
        command: [ &quot;/bin/sh&quot;,&quot;-c&quot;,&quot;--&quot; ]
        args: [&quot; echo 'source  /opt/intel/system_studio_2019/bin/compilervars.sh intel64' &gt;&gt; /root/.bashrc ; echo 'source /opt/intel/oneapi/setvars.sh' &gt;&gt; /root/.bashrc ; sleep infinity&quot;]
        # tty: true
        # stdin: true
        # env:
        image: ${REG_TMP}/nepdemo/flexran_basekit:dpdk-19.11-ocp-4.9.5-ubi-8.4 
        name: flexran-dev-env
        volumeMounts:
        - name: oneapi
          mountPath: /opt/intel/oneapi
          readOnly: false
        - name: system-studio-2019
          mountPath: /opt/intel/system_studio_2019
          readOnly: false   
        - name: licenses
          mountPath: /opt/intel/licenses
          readOnly: false
        - name: packagemanager
          mountPath: /opt/intel/packagemanager
          readOnly: false   
        - name: dpdk-19-11
          mountPath: /opt/dpdk-19-11
          readOnly: false
        - name: flexran
          mountPath: /data/flexran
          readOnly: false            
      volumes:
      - name: hugepage
        emptyDir:
          medium: HugePages
      - name: varrun
        emptyDir: {}
      - name: dpdk-19-11
        hostPath:
          path: &quot;/var/nepdemo/dpdk-19.11&quot;
      - name: flexran
        hostPath:
          path: &quot;/var/nepdemo/flexran&quot;
      - name: oneapi
        hostPath:
          path: &quot;/var/nepdemo/oneapi&quot;
      - name: system-studio-2019
        hostPath:
          path: &quot;/var/nepdemo/system_studio_2019&quot;
      - name: licenses
        hostPath:
          path: &quot;/var/nepdemo/licenses&quot;
      - name: packagemanager
        hostPath:
          path: &quot;/var/nepdemo/packagemanager&quot;
      - name: sys
        hostPath:
          path: &quot;/sys/&quot;

EOF
oc create -n vbbu-demo -f /data/install/vran.intel.flexran.yaml

# oc delete -n vbbu-demo -f /data/install/vran.intel.flexran.yaml

POD_ID=$(oc get pod -n vbbu-demo -o json | jq -r '.items[].metadata.name | select(. | contains(&quot;flexran-binary-release&quot;))' )
oc rsh -c flexran-dev-env ${POD_ID}
# switch to bash, will run .bashrc, which wil bring you intel icc/icx sdk env.
# bash

# 我们从fec的device plugin里面，能看到设备已经提供出来了
POD_ID=$(oc get pod -n vran-acceleration-operators -o json | jq -r ' .items[].metadata.name | select( contains( &quot;device-plugin&quot; ) ) ')
oc logs -n vran-acceleration-operators $POD_ID
# ......
# I0509 12:53:38.288275       1 server.go:119] Allocate() called with &amp;AllocateRequest{ContainerRequests:[]*ContainerAllocateRequest{&amp;ContainerAllocateRequest{DevicesIDs:[0000:18:01.2],},},}
# I0509 12:53:38.288326       1 accelResourcePool.go:46] GetDeviceSpecs(): for devices: [0000:18:01.2]
# I0509 12:53:38.288435       1 pool_stub.go:97] GetEnvs(): for devices: [0000:18:01.2]
# I0509 12:53:38.288443       1 pool_stub.go:113] GetMounts(): for devices: [0000:18:01.2]
# I0509 12:53:38.288447       1 server.go:128] AllocateResponse send: &amp;AllocateResponse{ContainerResponses:[]*ContainerAllocateResponse{&amp;ContainerAllocateResponse{Envs:map[string]string{PCIDEVICE_INTEL_COM_INTEL_FEC_ACC100: 0000:18:01.2,},Mounts:[]*Mount{},Devices:[]*DeviceSpec{&amp;DeviceSpec{ContainerPath:/dev/vfio/vfio,HostPath:/dev/vfio/vfio,Permissions:mrw,},&amp;DeviceSpec{ContainerPath:/dev/vfio/110,HostPath:/dev/vfio/110,Permissions:mrw,},},Annotations:map[string]string{},},},}

POD_ID=$(oc get pod -n openshift-sriov-network-operator -o json | jq -r ' .items[].metadata.name | select( contains( &quot;device-plugin&quot; ) ) ')
oc logs -n openshift-sriov-network-operator $POD_ID
# ......
# I0511 13:03:13.167902       1 server.go:115] Allocate() called with &amp;AllocateRequest{ContainerRequests:[]*ContainerAllocateRequest{&amp;ContainerAllocateRequest{DevicesIDs:[0000:65:02.0],},},}
# I0511 13:03:13.167961       1 netResourcePool.go:50] GetDeviceSpecs(): for devices: [0000:65:02.0]
# I0511 13:03:13.168068       1 pool_stub.go:97] GetEnvs(): for devices: [0000:65:02.0]
# I0511 13:03:13.168077       1 pool_stub.go:113] GetMounts(): for devices: [0000:65:02.0]
# I0511 13:03:13.168082       1 server.go:124] AllocateResponse send: &amp;AllocateResponse{ContainerResponses:[]*ContainerAllocateResponse{&amp;ContainerAllocateResponse{Envs:map[string]string{PCIDEVICE_OPENSHIFT_IO_INTEL_710_NIC01_RT2: 0000:65:02.0,},Mounts:[]*Mount{},Devices:[]*DeviceSpec{&amp;DeviceSpec{ContainerPath:/dev/vfio/vfio,HostPath:/dev/vfio/vfio,Permissions:mrw,},&amp;DeviceSpec{ContainerPath:/dev/vfio/108,HostPath:/dev/vfio/108,Permissions:mrw,},},Annotations:map[string]string{},},},}
# I0511 13:03:13.168369       1 server.go:115] Allocate() called with &amp;AllocateRequest{ContainerRequests:[]*ContainerAllocateRequest{&amp;ContainerAllocateRequest{DevicesIDs:[0000:65:0a.0],},},}
# I0511 13:03:13.168393       1 netResourcePool.go:50] GetDeviceSpecs(): for devices: [0000:65:0a.0]
# I0511 13:03:13.168470       1 pool_stub.go:97] GetEnvs(): for devices: [0000:65:0a.0]
# I0511 13:03:13.168477       1 pool_stub.go:113] GetMounts(): for devices: [0000:65:0a.0]
# I0511 13:03:13.168481       1 server.go:124] AllocateResponse send: &amp;AllocateResponse{ContainerResponses:[]*ContainerAllocateResponse{&amp;ContainerAllocateResponse{Envs:map[string]string{PCIDEVICE_OPENSHIFT_IO_INTEL_710_NIC02_RT2: 0000:65:0a.0,},Mounts:[]*Mount{},Devices:[]*DeviceSpec{&amp;DeviceSpec{ContainerPath:/dev/vfio/vfio,HostPath:/dev/vfio/vfio,Permissions:mrw,},&amp;DeviceSpec{ContainerPath:/dev/vfio/112,HostPath:/dev/vfio/112,Permissions:mrw,},},Annotations:map[string]string{},},},}

# 到vbbu pod里面验证一下，也能看到设备出现了。
POD_ID=$(oc get pod -n vbbu-demo -o json | jq -r '.items[].metadata.name | select(. | contains(&quot;flexran-binary-release&quot;))' )
oc exec -c flexran-release-running  ${POD_ID} -- ls /dev/vfio
# Defaulted container &quot;flexran-release-running&quot; out of: flexran-release-running, flexran-dev-env
# 110
# 112
# 97
# vfio

POD_ID=$(oc get pod -n vbbu-demo -o json | jq -r '.items[].metadata.name | select(. | contains(&quot;flexran-binary-release&quot;))' )
oc rsh -c flexran-release-running ${POD_ID}

POD_ID=$(oc get pod -n vbbu-demo -o json | jq -r '.items[].metadata.name | select(. | contains(&quot;flexran-binary-release&quot;))' )
oc exec -c flexran-release-running  ${POD_ID} -- ip link
# 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
#     link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
# 3: eth0@if30: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default
#     link/ether 0a:58:0a:fe:0a:0a brd ff:ff:ff:ff:ff:ff link-netnsid 0

POD_ID=$(oc get pod -n vbbu-demo -o json | jq -r '.items[].metadata.name | select(. | contains(&quot;flexran-binary-release&quot;))' )
oc exec -c flexran-release-running  ${POD_ID} -- python3 /root/dpdk-19.11/usertools/dpdk-devbind.py -s
# Network devices using DPDK-compatible driver
# ============================================
# 0000:65:02.0 'Ethernet Virtual Function 700 Series 154c' drv=vfio-pci unused=iavf,igb_uio
# 0000:65:02.1 'Ethernet Virtual Function 700 Series 154c' drv=vfio-pci unused=iavf,igb_uio
# 0000:65:02.2 'Ethernet Virtual Function 700 Series 154c' drv=vfio-pci unused=iavf,igb_uio
# 0000:65:02.3 'Ethernet Virtual Function 700 Series 154c' drv=vfio-pci unused=iavf,igb_uio
# 0000:65:0a.0 'Ethernet Virtual Function 700 Series 154c' drv=vfio-pci unused=iavf,igb_uio
# 0000:65:0a.1 'Ethernet Virtual Function 700 Series 154c' drv=vfio-pci unused=iavf,igb_uio
# 0000:65:0a.2 'Ethernet Virtual Function 700 Series 154c' drv=vfio-pci unused=iavf,igb_uio
# 0000:65:0a.3 'Ethernet Virtual Function 700 Series 154c' drv=vfio-pci unused=iavf,igb_uio

# Network devices using kernel driver
# ===================================
# 0000:65:00.0 'Ethernet Controller X710 for 10GbE SFP+ 1572' if=ens2f0 drv=i40e unused=igb_uio,vfio-pci
# 0000:65:00.1 'Ethernet Controller X710 for 10GbE SFP+ 1572' if=ens2f1 drv=i40e unused=igb_uio,vfio-pci
# 0000:b5:00.0 'Ethernet Connection X722 for 1GbE 37d1' if=eno1 drv=i40e unused=igb_uio,vfio-pci
# 0000:b5:00.1 'Ethernet Connection X722 for 1GbE 37d1' if=eno2 drv=i40e unused=igb_uio,vfio-pci

# Baseband devices using DPDK-compatible driver
# =============================================
# 0000:18:00.0 'Device 0d5d' drv=vfio-pci unused=igb_uio
# 0000:18:00.1 'Device 0d5d' drv=vfio-pci unused=igb_uio
# 0000:18:00.2 'Device 0d5d' drv=vfio-pci unused=igb_uio
# 0000:18:00.3 'Device 0d5d' drv=vfio-pci unused=igb_uio
# 0000:18:00.4 'Device 0d5d' drv=vfio-pci unused=igb_uio
# 0000:18:00.5 'Device 0d5d' drv=vfio-pci unused=igb_uio
# 0000:18:00.6 'Device 0d5d' drv=vfio-pci unused=igb_uio
# 0000:18:00.7 'Device 0d5d' drv=vfio-pci unused=igb_uio
# 0000:18:01.0 'Device 0d5d' drv=vfio-pci unused=igb_uio
# 0000:18:01.1 'Device 0d5d' drv=vfio-pci unused=igb_uio
# 0000:18:01.2 'Device 0d5d' drv=vfio-pci unused=igb_uio
# 0000:18:01.3 'Device 0d5d' drv=vfio-pci unused=igb_uio
# 0000:18:01.4 'Device 0d5d' drv=vfio-pci unused=igb_uio
# 0000:18:01.5 'Device 0d5d' drv=vfio-pci unused=igb_uio
# 0000:18:01.6 'Device 0d5d' drv=vfio-pci unused=igb_uio
# 0000:18:01.7 'Device 0d5d' drv=vfio-pci unused=igb_uio

# Baseband devices using kernel driver
# ====================================
# 0000:17:00.0 'Device 0d5c' drv=pci-pf-stub unused=igb_uio,vfio-pci

# No 'Crypto' devices detected
# ============================

# No 'Eventdev' devices detected
# ==============================

# No 'Mempool' devices detected
# =============================

# No 'Compress' devices detected
# ==============================

# Misc (rawdev) devices using kernel driver
# =========================================
# 0000:00:04.0 'Sky Lake-E CBDMA Registers 2021' drv=ioatdma unused=igb_uio,vfio-pci
# 0000:00:04.1 'Sky Lake-E CBDMA Registers 2021' drv=ioatdma unused=igb_uio,vfio-pci
# 0000:00:04.2 'Sky Lake-E CBDMA Registers 2021' drv=ioatdma unused=igb_uio,vfio-pci
# 0000:00:04.3 'Sky Lake-E CBDMA Registers 2021' drv=ioatdma unused=igb_uio,vfio-pci
# 0000:00:04.4 'Sky Lake-E CBDMA Registers 2021' drv=ioatdma unused=igb_uio,vfio-pci
# 0000:00:04.5 'Sky Lake-E CBDMA Registers 2021' drv=ioatdma unused=igb_uio,vfio-pci
# 0000:00:04.6 'Sky Lake-E CBDMA Registers 2021' drv=ioatdma unused=igb_uio,vfio-pci
# 0000:00:04.7 'Sky Lake-E CBDMA Registers 2021' drv=ioatdma unused=igb_uio,vfio-pci

# No 'Regex' devices detected
# ===========================

oc debug node/worker-2.ocp4.redhat.ren -- ip link
# Starting pod/worker-2ocp4redhatren-debug ...
# To use host binaries, run `chroot /host`
# 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
#     link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
# 2: ens2f0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc mq state DOWN mode DEFAULT group default qlen 1000
#     link/ether 90:e2:ba:a8:29:e6 brd ff:ff:ff:ff:ff:ff
#     vf 0     link/ether 06:b4:8a:df:01:b6 brd ff:ff:ff:ff:ff:ff, spoof checking on, link-state auto, trust off
#     vf 1     link/ether 6a:f3:e9:2e:ce:95 brd ff:ff:ff:ff:ff:ff, spoof checking on, link-state auto, trust off
#     vf 2     link/ether 86:23:2b:24:12:8f brd ff:ff:ff:ff:ff:ff, spoof checking on, link-state auto, trust off
#     vf 3     link/ether 00:11:22:33:44:01 brd ff:ff:ff:ff:ff:ff, spoof checking on, link-state auto, trust off
# 3: ens2f1: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc mq state DOWN mode DEFAULT group default qlen 1000
#     link/ether 90:e2:ba:a8:29:e7 brd ff:ff:ff:ff:ff:ff
#     vf 0     link/ether 00:11:22:33:44:02 brd ff:ff:ff:ff:ff:ff, spoof checking on, link-state auto, trust off
#     vf 1     link/ether f6:9f:b3:a4:f2:da brd ff:ff:ff:ff:ff:ff, spoof checking on, link-state auto, trust off
#     vf 2     link/ether 36:44:0f:fa:b9:84 brd ff:ff:ff:ff:ff:ff, spoof checking on, link-state auto, trust off
#     vf 3     link/ether fa:5b:75:f2:77:8c brd ff:ff:ff:ff:ff:ff, spoof checking on, link-state auto, trust off
# 4: eno1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000
#     link/ether ac:1f:6b:ea:5b:32 brd ff:ff:ff:ff:ff:ff
# 5: eno2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000
#     link/ether ac:1f:6b:ea:5b:33 brd ff:ff:ff:ff:ff:ff
# 10: ovs-system: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
#     link/ether 52:50:27:19:21:e2 brd ff:ff:ff:ff:ff:ff
# 11: br0: &lt;BROADCAST,MULTICAST&gt; mtu 1450 qdisc noop state DOWN mode DEFAULT group default qlen 1000
#     link/ether fe:7b:d1:84:da:4f brd ff:ff:ff:ff:ff:ff
# 12: vxlan_sys_4789: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 65000 qdisc noqueue master ovs-system state UNKNOWN mode DEFAULT group default qlen 1000
#     link/ether b6:c9:1d:9d:77:aa brd ff:ff:ff:ff:ff:ff
# 13: tun0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
#     link/ether 36:7a:65:37:c1:33 brd ff:ff:ff:ff:ff:ff
# 14: vethf21a4c33@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master ovs-system state UP mode DEFAULT group default
#     link/ether ae:f2:57:a5:67:ad brd ff:ff:ff:ff:ff:ff link-netnsid 0
# 15: veth8662e3e2@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master ovs-system state UP mode DEFAULT group default
#     link/ether 9e:49:15:3f:7c:a1 brd ff:ff:ff:ff:ff:ff link-netnsid 1
# 16: veth5d3ab571@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master ovs-system state UP mode DEFAULT group default
#     link/ether aa:ad:f7:cc:b9:57 brd ff:ff:ff:ff:ff:ff link-netnsid 2
# 17: veth20ff5e06@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master ovs-system state UP mode DEFAULT group default
#     link/ether 82:72:8e:6d:1a:4a brd ff:ff:ff:ff:ff:ff link-netnsid 3
# 18: vethd11f4604@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master ovs-system state UP mode DEFAULT group default
#     link/ether 96:df:20:6a:a0:6f brd ff:ff:ff:ff:ff:ff link-netnsid 4
# 20: vethc860c9be@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master ovs-system state UP mode DEFAULT group default
#     link/ether c6:c6:37:fb:1d:48 brd ff:ff:ff:ff:ff:ff link-netnsid 5
# 30: vethfe0374a4@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default
#     link/ether 1e:a1:67:b2:00:f6 brd ff:ff:ff:ff:ff:ff link-netnsid 6
# 32: vethecce46ea@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master ovs-system state UP mode DEFAULT group default
#     link/ether 2e:1d:11:80:37:29 brd ff:ff:ff:ff:ff:ff link-netnsid 8

# Removing debug pod ...


</code></pre>
<p>以上是一个开发环境的部署，要注意，在 /data/flexran 的开发成功，要复制到 /root/flexran 里面，然后用 release 容器来运行测试。</p>
<p>后期，当开发完成以后，会单独的重新制作 release 容器，dev 相关的容器在生成环境上，就都不用了，同理，那些复制文件的 job 也都不会在生产系统上运行。</p>
<h1 id="end"><a class="header" href="#end">end</a></h1>
<h2 id="linuxptp-311"><a class="header" href="#linuxptp-311">linuxptp 3.11</a></h2>
<pre><code class="language-bash"># http://linuxptp.sourceforge.net/
# download linuxptp-3.1.1

# on a rhel8.4
dnf install -y linuxptp

# /etc/ptp4l.conf
# /etc/sysconfig/phc2sys
# /etc/sysconfig/ptp4l
# /etc/timemaster.conf
# /usr/lib/systemd/system/phc2sys.service
# /usr/lib/systemd/system/ptp4l.service
# /usr/lib/systemd/system/timemaster.service

cat /etc/sysconfig/phc2sys
# OPTIONS=&quot;-a -r&quot;

cat /etc/sysconfig/ptp4l
# OPTIONS=&quot;-f /etc/ptp4l.conf -i eth0&quot;

systemctl cat phc2sys
# # /usr/lib/systemd/system/phc2sys.service
# [Unit]
# Description=Synchronize system clock or PTP hardware clock (PHC)
# After=ntpdate.service ptp4l.service

# [Service]
# Type=simple
# EnvironmentFile=-/etc/sysconfig/phc2sys
# ExecStart=/usr/sbin/phc2sys $OPTIONS

# [Install]
# WantedBy=multi-user.target

systemctl cat ptp4l.service
# # /usr/lib/systemd/system/ptp4l.service
# [Unit]
# Description=Precision Time Protocol (PTP) service
# After=network-online.target
# Wants=network-online.target

# [Service]
# Type=simple
# EnvironmentFile=-/etc/sysconfig/ptp4l
# ExecStart=/usr/sbin/ptp4l $OPTIONS

# [Install]
# WantedBy=multi-user.target

mkdir -p /data/ptp
cd /data/ptp
wget https://nchc.dl.sourceforge.net/project/linuxptp/v3.1/linuxptp-3.1.1.tgz
tar zvxf linuxptp-3.1.1.tgz
cd linuxptp-3.1.1
make

cat &lt;&lt; 'EOF' &gt; ptp4l.sh
#!/bin/bash

# echo $DEMO_ENV_NIC &gt; /demo.txt
# echo $DEMO_ENV_PTP4L_ARG &gt;&gt; /demo.txt

# ./ptp4l -f ./configs/default_zill.cfg -2 -i enp101s0f0   -m  &gt; /home/ptp4l.log  2&gt;&amp;1 &amp;
# /usr/local/sbin/ptp4l -f /etc/ptp4l.conf -2 -m -i $DEMO_ENV_NIC
/usr/local/sbin/ptp4l -f /etc/ptp4l.conf -m $DEMO_ENV_PTP4L_ARG

EOF

cat &lt;&lt; 'EOF' &gt; phc2sys.sh
#!/bin/bash

# echo $DEMO_ENV_NIC &gt; /demo.1.txt
# echo $DEMO_ENV_PHC2SYS_ARG &gt;&gt; /demo1.txt

# ./phc2sys -s  enp101s0f0  -O 0 -m -R 8 &gt;/home/phc2sys.log   2&gt;&amp;1 &amp;
# /usr/local/sbin/phc2sys -s $DEMO_ENV_NIC -a -r -m -u 1 -O 0 -R 8 -z /var/run/ptp4l -t [phc2sys]
/usr/local/sbin/phc2sys -m -z /var/run/ptp4l -t [phc2sys] $DEMO_ENV_PHC2SYS_ARG

EOF

cat &lt;&lt; 'EOF' &gt; ts2phc.sh
#!/bin/bash

# echo $DEMO_ENV_NIC &gt; /demo.2.txt
# echo $DEMO_ENV_TS2PHC_ARG &gt;&gt; /demo2.txt

# ./ts2phc -f ./configs/ts2phc-generic_GNSS0.cfg -s generic -m -c enp23s0f0 &gt; /home/ts2phc.log 2&gt;&amp;1 &amp;
# /usr/local/sbin/ts2phc -f /etc/ts2phc.cfg -s generic -m -c $DEMO_ENV_NIC
/usr/local/sbin/ts2phc -f /etc/ts2phc.cfg -m $DEMO_ENV_TS2PHC_ARG

EOF

cat &lt;&lt; EOF &gt; ./ptp.dockerfile
FROM registry.access.redhat.com/ubi8/ubi:8.4

COPY hwstamp_ctl nsm phc2sys phc_ctl pmc ptp4l timemaster ts2phc incdefs.sh version.sh ptp4l.sh phc2sys.sh ts2phc.sh /usr/local/sbin/
RUN cd /usr/local/sbin/ &amp;&amp; chmod +x hwstamp_ctl nsm phc2sys phc_ctl pmc ptp4l timemaster ts2phc incdefs.sh version.sh ptp4l.sh phc2sys.sh ts2phc.sh

EOF

podman build --squash -t quay.io/nepdemo/linuxptp:3.1.1-ubi-8.4-v04 -f ptp.dockerfile ./

podman push quay.io/nepdemo/linuxptp:3.1.1-ubi-8.4-v04

cat &lt;&lt; EOF &gt; /data/install/ptp4l.conf
[global]
#
# Default Data Set
#
twoStepFlag             1
slaveOnly               0
priority1               128
priority2               128
domainNumber            24
#utc_offset             37
clockClass              248
clockAccuracy           0xFE
offsetScaledLogVariance 0xFFFF
free_running            0
freq_est_interval       1
dscp_event              0
dscp_general            0
dataset_comparison      ieee1588
G.8275.defaultDS.localPriority  128
#
# Port Data Set
# 16 TS a second use logSyncInterval  -4
logAnnounceInterval     1
logSyncInterval         -4
logMinDelayReqInterval  0
logMinPdelayReqInterval 0
announceReceiptTimeout  3
syncReceiptTimeout      0
delayAsymmetry          0
fault_reset_interval    4
neighborPropDelayThresh 20000000
masterOnly              0
G.8275.portDS.localPriority     128
#
# Run time options
#
assume_two_step         0
logging_level           6
path_trace_enabled      0
follow_up_info          0
hybrid_e2e              0
inhibit_multicast_service       0
net_sync_monitor        0
tc_spanning_tree        0
tx_timestamp_timeout    1
unicast_listen          0
unicast_master_table    0
unicast_req_duration    3600
use_syslog              1
verbose                 0
summary_interval        0
kernel_leap             1
check_fup_sync          0
#
# Servo Options
#
pi_proportional_const   0.0
pi_integral_const       0.0
pi_proportional_scale   0.0
pi_proportional_exponent        -0.3
pi_proportional_norm_max        0.7
pi_integral_scale       0.0
pi_integral_exponent    0.4
pi_integral_norm_max    0.3
step_threshold          0.0
first_step_threshold    0.00002
max_frequency           900000000
clock_servo             pi
sanity_freq_limit       200000000
ntpshm_segment          0
#
# Transport options
#
transportSpecific       0x0
ptp_dst_mac             01:1B:19:00:00:00
p2p_dst_mac             01:80:C2:00:00:0E
udp_ttl                 1
udp6_scope              0x0E
uds_address             /var/run/ptp4l
#
# Default interface options
#
clock_type              OC
network_transport       UDPv4
delay_mechanism         E2E
time_stamping           hardware
tsproc_mode             filter
delay_filter            moving_median
delay_filter_length     10
egressLatency           0
ingressLatency          0
boundary_clock_jbod     0
#
# Clock description
#
productDescription      ;;
revisionData            ;;
manufacturerIdentity    00:00:00
userDescription         ;
timeSource              0xA0
EOF

cat &lt;&lt; EOF &gt; /data/install/ts2phc.cfg
[global]
use_syslog              0
verbose                 1
logging_level           7
ts2phc.pulsewidth       100000000
# For GNSS module
ts2phc.nmea_serialport /dev/ttyGNSS_6500_0
[ens18f0]
ts2phc.extts_polarity rising
EOF

oc delete configmap ptp-config -n vbbu-demo

oc create configmap ptp-config -n vbbu-demo --from-file=/data/install/ptp4l.conf --from-file=/data/install/ts2phc.cfg --save-config=true

cat &lt;&lt; 'EOF' &gt; /data/install/ptp.demo.yaml
---
apiVersion: v1
kind: Pod
metadata:
  annotations:
  labels:
    app: nepdemo-linuxptp-daemon
  name: nepdemo-linuxptp-daemon
  # namespace: openshift-ptp
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchFields:
          - key: metadata.name
            operator: In
            values:
            - worker-0.ocp4.redhat.ren
  containers:
  - name: ptp4l
    image: quay.io/nepdemo/linuxptp:3.1.1-ubi-8.4-v04
    imagePullPolicy: IfNotPresent
    command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;--&quot;]
    args: [&quot; /usr/local/sbin/ptp4l.sh ;&quot;]
    env:
    - name: DEMO_ENV_PTP4L_ARG
      value: &quot; -i ens18f0 -2 &quot;
    securityContext:
      privileged: true
      runAsUser: 0    
    volumeMounts:
    - mountPath: /etc/ptp4l.conf
      subPath: ptp4l.conf
      name: config-volume
    - mountPath: /var/run/ptp4l
      name: socket-dir
  - name: phc2sys
    image: quay.io/nepdemo/linuxptp:3.1.1-ubi-8.4-v04
    imagePullPolicy: IfNotPresent
    command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;--&quot;]
    args: [&quot; /usr/local/sbin/phc2sys.sh ;&quot;]
    env:
    - name: DEMO_ENV_PHC2SYS_ARG
      value: &quot; -s ens18f0 -r -u 1 -O 0 -R 8 &quot;      
    securityContext:
      privileged: true
      runAsUser: 0    
    volumeMounts:
    - mountPath: /etc/ptp4l.conf
      subPath: ptp4l.conf
      name: config-volume
    - mountPath: /var/run/ptp4l
      name: socket-dir
  - name: ts2phc
    image: quay.io/nepdemo/linuxptp:3.1.1-ubi-8.4-v04
    imagePullPolicy: IfNotPresent
    command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;--&quot;]
    args: [&quot; /usr/local/sbin/ts2phc.sh ;&quot;]
    env:
    - name: DEMO_ENV_TS2PHC_ARG
      value: &quot; -s generic -c ens18f0 &quot;      
    securityContext:
      privileged: true
      runAsUser: 0    
    volumeMounts:
    - mountPath: /etc/ts2phc.cfg
      subPath: ts2phc.cfg
      name: config-volume
    - mountPath: /var/run/ptp4l
      name: socket-dir
    - name: dev
      mountPath: /dev
  hostNetwork: true
  hostPID: true
  serviceAccountName: svcacct-driver
  volumes:
  - configMap:
      defaultMode: 420
      name: ptp-config
    name: config-volume
  - hostPath:
      path: /var/run/ptp
      type: DirectoryOrCreate
    name: socket-dir
  - name: dev
    hostPath:
      path: &quot;/dev&quot;
EOF

oc create -n vbbu-demo -f /data/install/ptp.demo.yaml

# oc delete -n vbbu-demo -f /data/install/ptp.demo.yaml

</code></pre>
<h2 id="baicell-bbu"><a class="header" href="#baicell-bbu">baicell bbu</a></h2>
<pre><code class="language-bash">cd /home/BaiBBU_XSS/tools
./XRAN_BBU stop

./XRAN_BBU start

cat /home/BaiBBU_XSS/BaiBBU_SXSS/DU/bin/logs_gNB_DU

tail -f /home/BaiBBU_XSS/BaiBBU_SXSS/DU/bin/logs_gNB_DU

export tmp_path='/home/BaiBBU_XSS-A/BaiBBU_PXSS/PHY'

cd /data/flexran
cp -r libs $tmp_path/
cp -r sdk $tmp_path/
#cp -r tests flexran_build/flexran/
cp -r wls_mod $tmp_path/
cp -r xran $tmp_path/
#cd flexran_build/flexran/
#add remove flexran source code
rm -rf $tmp_path/sdk/test
rm -rf $tmp_path/sdk/source
rm -rf $tmp_path/libs/ferrybridge

cd /home/BaiBBU_XSS-A/BaiBBU_PXSS/PHY

cat /home/BaiBBU_XSS-A/BaiBBU_PXSS/PHY/bin/l1.sh

cat /home/BaiBBU_XSS-A/BaiBBU_PXSS/PHY/bin/Phy.log

# patch /home/BaiBBU_XSS-A/BaiBBU_PXSS/PHY/bin/l1.sh
# add env variable
# export DIR_WIRELESS_SDK=/data/flexran/sdk/build-avx512-icc
# export -n DIR_WIRELESS_SDK
# export DIR_WIRELESS_SDK=/home/BaiBBU_XSS-A/BaiBBU_PXSS/PHY/sdk/build-avx512-icc

cat /data/flexran/bin/nr5g/gnb/l1/l1.sh

cat /data/flexran/bin/nr5g/gnb/l1/Phy.log



</code></pre>
<p>finnaly, we find out, l1app co-works with gnb_du_mac, but both working as 'EAL: Auto-detected process type: PRIMARY'
<a href="https://doc.dpdk.org/guides/prog_guide/multi_proc_support.html">DPDK docs say, multiple processes can work together.</a></p>
<h2 id="dhcp-for-ru"><a class="header" href="#dhcp-for-ru">dhcp for ru</a></h2>
<pre><code class="language-bash">
nmcli dev con ens1f0

nmcli connection mod ens1f0 ipv4.add 192.168.160.1/24 ipv4.method manual
nmcli con up ens1f0

cat /etc/sysconfig/dhcpd
# .......
# DHCPDARGS=ens1f0

cat /etc/dhcp/dhcpd.conf
# option callhomeip code 43 = string;
# subnet 192.168.160.0 netmask 255.255.255.0 {
#         range 192.168.160.10 192.168.160.100;
#         option domain-name-servers 192.168.160.1;
#         option routers 192.168.160.1;
#         option callhomeip 81:04:C0:A8:A0:A2;
#         default-lease-time 600;
#         max-lease-time 7200;
# }

</code></pre>
<h2 id="some-test-no-use-here"><a class="header" href="#some-test-no-use-here">some test, no use here</a></h2>
<pre><code class="language-bash"># intel icc repo
# https://www.intel.com/content/www/us/en/developer/articles/guide/installing-intel-parallel-studio-xe-runtime-2020-using-yum-repository.html


# offical oneapi docker image build
# https://hub.docker.com/r/intel/oneapi-basekit
# https://github.com/intel/oneapi-containers/blob/12932f721dd0201dfae85cacb62495924ecf42cf/images/docker/basekit/Dockerfile.centos-8

# using files/flexran.dockerfile
# buildah bud --squash -t quay.io/nepdemo/flexran_basekit:oneapi-basekit-official-ocp-4.9.5-ubi-8.4 -f flexran.dockerfile ./

# buildah push quay.io/nepdemo/flexran_basekit:oneapi-basekit-official-ocp-4.9.5-ubi-8.4

podman build --squash -t quay.io/nepdemo/flexran_basekit:oneapi-basekit-official-ocp-4.9.5-ubi-8.4 -f flexran.dockerfile ./

podman push quay.io/nepdemo/flexran_basekit:oneapi-basekit-official-ocp-4.9.5-ubi-8.4

# in container
echo 'distroverpkg=redhat-release' &gt;&gt; /etc/yum.conf

rpm -q --qf %{version} redhat-release;echo
# 8.4

rpm -q --provides $(rpm -q --whatprovides &quot;system-release(releasever)&quot;)
# base-module(platform:el8)
# config(redhat-release) = 8.4-0.6.el8
# redhat-release = 8.4-0.6.el8
# redhat-release(x86-64) = 8.4-0.6.el8
# redhat-release-client
# redhat-release-computenode
# redhat-release-server
# redhat-release-workstation
# system-release = 8.4-0.6.el8
# system-release(releasever) = 8

dnf repolist
sed -i 's|enabled=1|enabled=0|g' /etc/yum/pluginconf.d/subscription-manager.conf
sed -i 's|$releasever|8.4|g' /etc/yum.repos.d/redhat.repo
sed -i '/codeready-builder-for-rhel-8-x86_64-rpms/,/\[/ s/enabled = 0/enabled = 1/' /etc/yum.repos.d/redhat.repo
mv -f /etc/yum.repos.d/ubi.repo /etc/yum.repos.d/ubi.repo.bak
</code></pre>
<h2 id="cache-dnf-repo"><a class="header" href="#cache-dnf-repo">cache dnf repo</a></h2>
<pre><code class="language-bash">mkdir -p /data/dnf
cd /data/dnf

dnf reposync -m --download-metadata --delete -n

dnf copr enable frostyx/modulemd-tools
dnf install -y modulemd-tools 

createrepo ./
repo2module . \
    --module-name foo \
    --module-stream devel \
    --module-version 123 \
    --module-context f32
createrepo_mod .
</code></pre>
<h2 id="sriov-setting-for-non-dpdk"><a class="header" href="#sriov-setting-for-non-dpdk">sriov setting for non-dpdk</a></h2>
<pre><code class="language-bash">
# oc label node worker-2.ocp4.redhat.ren feature.node.kubernetes.io/network-sriov.capable=&quot;true&quot;

# https://docs.openshift.com/container-platform/4.9/networking/hardware_networks/configuring-sriov-ib-attach.html
# Dynamic IP address (DHCP) assignment configuration
# require a dhcp server in cluster
apiVersion: operator.openshift.io/v1
kind: Network
metadata:
  name: cluster
spec:
  additionalNetworks:
  - name: dhcp-shim
    namespace: default
    type: Raw
    rawCNIConfig: |-
      {
        &quot;name&quot;: &quot;dhcp-shim&quot;,
        &quot;cniVersion&quot;: &quot;0.3.1&quot;,
        &quot;type&quot;: &quot;bridge&quot;,
        &quot;ipam&quot;: {
          &quot;type&quot;: &quot;dhcp&quot;
        }
      }
  # ...

oc get Network.operator.openshift.io/cluster -o yaml
# ......
# spec:
#   clusterNetwork:
#   - cidr: 10.254.0.0/16
#     hostPrefix: 24
#   defaultNetwork:
#     type: OpenShiftSDN
#   disableNetworkDiagnostics: false
#   logLevel: Normal
#   managementState: Managed
#   observedConfig: null
#   operatorLogLevel: Normal
#   serviceNetwork:
#   - 172.30.0.0/16
#   unsupportedConfigOverrides: null
# ......

# if you use ipam dhcp, then you do this, otherwise skip
oc edit Network.operator.openshift.io/cluster

oc get pod -n openshift-multus  | grep dhcp
# dhcp-daemon-4s2c4                     1/1     Running   0          3h11m
# dhcp-daemon-9lvch                     1/1     Running   0          3h11m
# dhcp-daemon-lhss5                     1/1     Running   0          3h11m
# dhcp-daemon-q8qmh                     1/1     Running   0          3h11m

</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../../ocp4/4.10/4.10.netflow.table.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                            <a rel="next" href="../../ocp4/4.9/4.9.ci.cd.demo.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../../ocp4/4.10/4.10.netflow.table.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                    <a rel="next" href="../../ocp4/4.9/4.9.ci.cd.demo.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
    </body>
</html>

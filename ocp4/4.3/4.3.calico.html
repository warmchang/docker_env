<!DOCTYPE HTML>
<html lang="zh" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>openshift4 calico 离线部署 - OpenShift4 慢慢走</title>
                

        <!-- Custom HTML head -->
        <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-E3FRMDB7L2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-E3FRMDB7L2');
</script>

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

                <link rel="icon" href="../../favicon.svg">
                        <link rel="shortcut icon" href="../../favicon.png">
                <link rel="stylesheet" href="../../css/variables.css">
        <link rel="stylesheet" href="../../css/general.css">
        <link rel="stylesheet" href="../../css/chrome.css">
                <link rel="stylesheet" href="../../css/print.css" media="print">
        
        <!-- Fonts -->
        <link rel="stylesheet" href="../../FontAwesome/css/font-awesome.css">
                <link rel="stylesheet" href="../../fonts/fonts.css">
        
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../highlight.css">
        <link rel="stylesheet" href="../../tomorrow-night.css">
        <link rel="stylesheet" href="../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        
            </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../../index.html">介绍</a></li><li class="chapter-item expanded "><a href="../../install.html"><strong aria-hidden="true">1.</strong> openshift4 安装系列</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.ocp.pull.secret.html"><strong aria-hidden="true">1.1.</strong> 如何获得 openshift4 免费下载密钥</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.build.dist.html"><strong aria-hidden="true">1.2.</strong> openshift4 离线安装介质的制作</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.sno.static.ip.local.assisted.connected.html"><strong aria-hidden="true">1.3.</strong> assisted install 联线模式下 单节点ocp 无需dhcp 静态ip部署</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.sno.static.ip.local.assisted.disconnected.html"><strong aria-hidden="true">1.4.</strong> assisted install 离线模式下 单节点ocp 无需dhcp 静态ip部署</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.disconnect.bm.upi.static.ip.on.rhel7.html"><strong aria-hidden="true">1.5.</strong> openshift4 rhel7物理机 baremetal UPI模式 离线安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.disconnect.bm.upi.static.ip.on.rhel8.html"><strong aria-hidden="true">1.6.</strong> openshift4 rhel8物理机 baremetal UPI模式 离线安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.disconnect.bm.ipi.on.rhel8.html"><strong aria-hidden="true">1.7.</strong> openshift4 物理机 baremetal IPI模式 离线安装 单网络模式</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.disconnect.bm.ipi.on.rhel8.provisionning.network.html"><strong aria-hidden="true">1.8.</strong> openshift4 物理机 baremetal IPI模式 离线安装 双网络模式</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.cilium.html"><strong aria-hidden="true">1.9.</strong> openshift4 尝鲜 cilium CNI</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.nvidia.gpu.disconnected.html"><strong aria-hidden="true">1.10.</strong> nvidia gpu for openshift 4.6 disconnected 英伟达GPU离线安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.add.image.html"><strong aria-hidden="true">1.11.</strong> openshift4 初始安装后 补充镜像</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.is.sample.html"><strong aria-hidden="true">1.12.</strong> openshift4 补充samples operator 需要的 image stream</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.calico.html" class="active"><strong aria-hidden="true">1.13.</strong> openshift4 calico 离线部署</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.2/4.2.upgrade.html"><strong aria-hidden="true">1.14.</strong> openshift4 集群升级</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.shrink.sysroot.html"><strong aria-hidden="true">1.15.</strong> 缩小根分区 / sysroot 的大小</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.update.service.html"><strong aria-hidden="true">1.16.</strong> 部署升级服务 完善离线升级功能</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.windows.node.html"><strong aria-hidden="true">1.17.</strong> 添加 win10 worker 节点</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.sno.using.bootstrap.disconnected.html"><strong aria-hidden="true">1.18.</strong> 单节点ocp 安装 无需dhcp 静态ip部署</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.disconnect.bm.ipi.sno.static.ip.html"><strong aria-hidden="true">1.19.</strong> IPI模式 单节点 离线 单网络模式 安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.acm.ztp.disconnected.auto.html"><strong aria-hidden="true">1.20.</strong> ACM zero touch provision 远程单节点集群 全自动安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.coreos.boot.html"><strong aria-hidden="true">1.21.</strong> coreos 启动和分区挂载分析</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.installer.html"><strong aria-hidden="true">1.22.</strong> openshift4 单节点 命令行安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.partition.quay.html"><strong aria-hidden="true">1.23.</strong> openshift4 单节点 在第一块硬盘上添加更多分区</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.nfs.lvm.html"><strong aria-hidden="true">1.24.</strong> openshift4 单节点 使用 lvm 和 nfs 在集群内提供存储</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.boot.from.linux.html"><strong aria-hidden="true">1.25.</strong> openshift4 单节点 从centos7/8 开始安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.odf.html"><strong aria-hidden="true">1.26.</strong> openshift4 单节点 安装精简版 ODF/ceph</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.replace.coreos.html"><strong aria-hidden="true">1.27.</strong> 定制 rhcos</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.rpm-ostree.install.html"><strong aria-hidden="true">1.28.</strong> rhcos 里面安装 rpm</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.component.version.html"><strong aria-hidden="true">1.29.</strong> openshift 4 组件版本</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.embeded.dns.haproxy.registry.html"><strong aria-hidden="true">1.30.</strong> 内嵌 dns, haproxy, registrty</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.replace.coreos.rhel.9.0.html"><strong aria-hidden="true">1.31.</strong> 升级 openshift 4.10 内核到 rhel 9.1 支持 海光 x86 cpu</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.11/4.11.acm.hypershift.html"><strong aria-hidden="true">1.32.</strong> 使用 hypershift 安装控制面托管的 openshift 集群</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.12/4.12.3node.upi.agent.html"><strong aria-hidden="true">1.33.</strong> 使用 agent based installer 安装 3 节点集群</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.12/4.12.single.node.upi.agent.html"><strong aria-hidden="true">1.34.</strong> 使用 agent based installer 安装 单节点集群</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.12/4.12.ocp.driver.build.html"><strong aria-hidden="true">1.35.</strong> 在 openshift 内部编译内核驱动 rpm 并使用</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.12/4.12.demo.lab.html"><strong aria-hidden="true">1.36.</strong> how to build an openshift 4.12 demo lab from scratch</a></li></ol></li><li class="chapter-item expanded "><a href="../../usage.html"><strong aria-hidden="true">2.</strong> openshift4 使用系列</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.11/4.11.3node.ipi.for.osp.prod.html"><strong aria-hidden="true">2.1.</strong> 在 openshift 4.11 上安装和运行 openstack</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.flexran.20.11.pf.deploy.html"><strong aria-hidden="true">2.2.</strong> 在openshift4上运行 OpenRAN 无线基站应用</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.netflow.table.html"><strong aria-hidden="true">2.3.</strong> openshift4 可视化 ovs netflow</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.flexran.20.11.html"><strong aria-hidden="true">2.4.</strong> intel o-ran flexran 方案在openshift4上的安装和使用</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.ci.cd.demo.html"><strong aria-hidden="true">2.5.</strong> ci/cd pipeline gitops演示</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.oc.exec.html"><strong aria-hidden="true">2.6.</strong> oc/kubectl exec 原理分析</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.nf.conntrack.html"><strong aria-hidden="true">2.7.</strong> nf_conntrack 在 openshift4.9上的处理</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.load.3rd.part.driver.html"><strong aria-hidden="true">2.8.</strong> 加载第三方设备驱动</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.nep.containerized.helm.html"><strong aria-hidden="true">2.9.</strong> helm chart/helm operator</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.metalb.l2.html"><strong aria-hidden="true">2.10.</strong> 使用 MetalLB 用 Layer2 发布 LoadBalancer</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.metalb.html"><strong aria-hidden="true">2.11.</strong> 使用 MetalLB 用 BGP 发布 LoadBalancer</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.kata.html"><strong aria-hidden="true">2.12.</strong> kata / 沙盒容器</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.sriov.html"><strong aria-hidden="true">2.13.</strong> 在非官方支持的网卡上，测试SRIOV/DPDK</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.keepalived.operator.html"><strong aria-hidden="true">2.14.</strong> 使用 keepalived 激活 LoadBalancer 服务类型</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.real-time.kernel.html"><strong aria-hidden="true">2.15.</strong> 在节点上启用实时操作系统 real-time kernel</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.install.kmod.driver.html"><strong aria-hidden="true">2.16.</strong> 从容器向宿主机注入内核模块 kmod / driver</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.vgpu.sharing.deploy.html"><strong aria-hidden="true">2.17.</strong> GPU/vGPU 共享</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.4/4.4.headless.service.html"><strong aria-hidden="true">2.18.</strong> openshift headless service讲解</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.volumn.html"><strong aria-hidden="true">2.19.</strong> openshift volumn 存储的各种测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.SupportPodPidsLimit.html"><strong aria-hidden="true">2.20.</strong> openshift 设置 SupportPodPidsLimit 解除 pids 限制</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.sso.html"><strong aria-hidden="true">2.21.</strong> openshift4 配置 SSO 点单认证</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.scc.html"><strong aria-hidden="true">2.22.</strong> openshift4 SCC 相关安全能力测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.recover.node.not.ready.html"><strong aria-hidden="true">2.23.</strong> openshift4 从 node not ready 状态恢复</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.QoS.nic.html"><strong aria-hidden="true">2.24.</strong> openshift4 QoS 能力</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.QoS.nic.high.html"><strong aria-hidden="true">2.25.</strong> openshift4 QoS 在流量压力下的表现</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.proxy.html"><strong aria-hidden="true">2.26.</strong> openshift4 使用 image proxy 来下载镜像</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.numa.html"><strong aria-hidden="true">2.27.</strong> openshift4 NUMA 绑核测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.network.policy.html"><strong aria-hidden="true">2.28.</strong> openshift4 Network Policy 测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.multicast.html"><strong aria-hidden="true">2.29.</strong> openshift4 网络多播 测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.firewall.html"><strong aria-hidden="true">2.30.</strong> openshift4 配置节点防火墙</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.ldap.html"><strong aria-hidden="true">2.31.</strong> openshift4 集成 ldap</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.image.pull.html"><strong aria-hidden="true">2.32.</strong> openshift4 维护 image pull secret</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.huge.page.html"><strong aria-hidden="true">2.33.</strong> openshift4 使用大页内存 huge page</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.helm.html"><strong aria-hidden="true">2.34.</strong> openshift4 使用 helm</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.haproxy.html"><strong aria-hidden="true">2.35.</strong> openshift4 定制router 支持 TCP ingress</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.grafana.html"><strong aria-hidden="true">2.36.</strong> openshift4 监控能力展示 grafana</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.cpu.manager.html"><strong aria-hidden="true">2.37.</strong> openshift4 CPU 绑核 测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.build.config.html"><strong aria-hidden="true">2.38.</strong> openshift4 build config &amp; hpa 自动化编译和自动扩缩容</a></li></ol></li><li class="chapter-item expanded "><a href="../../ccn.html"><strong aria-hidden="true">3.</strong> 应用上云系列教程 CCN</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.4/4.4.ccn.devops.deploy.html"><strong aria-hidden="true">3.1.</strong> 应用上云系列教程 containerized cloud native (CCN) for openshift 4.4</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.4/4.4.ccn.devops.build.html"><strong aria-hidden="true">3.2.</strong> CCN 安装介质制作 for openshift 4.4</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.ccn.devops.deploy.html"><strong aria-hidden="true">3.3.</strong> 应用上云系列教程 containerized cloud native (CCN) for openshift 4.6</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.ccn.devops.build.html"><strong aria-hidden="true">3.4.</strong> CCN 安装介质制作 for openshift 4.6</a></li></ol></li><li class="chapter-item expanded "><a href="../../rh.cloud.html"><strong aria-hidden="true">4.</strong> 红帽其他产品系列</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.acm.observ.html"><strong aria-hidden="true">4.1.</strong> ACM observability for openshift 4.10</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.01.ansible.install.html"><strong aria-hidden="true">4.2.</strong> 离线安装 ansible platform</a></li><li class="chapter-item expanded "><a href="../../notes/2021/2021.08.virus.html"><strong aria-hidden="true">4.3.</strong> RHACS 应对log4j 原理和实践</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.ocp.ocs.cnv.ceph.html"><strong aria-hidden="true">4.4.</strong> openshift承载虚拟化业务(CNV)</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.rhacs.html"><strong aria-hidden="true">4.5.</strong> RHACS / stackrox</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.rhacs.deep.html"><strong aria-hidden="true">4.6.</strong> 为 RHACS 找个应用场景: 安全合规测试云 </a></li></ol></li><li class="chapter-item expanded "><a href="../../os.html"><strong aria-hidden="true">5.</strong> 操作系统相关</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../notes/2023/2023.06.rhel.centos.html"><strong aria-hidden="true">5.1.</strong> 红帽断供centos的思考</a></li><li class="chapter-item expanded "><a href="../../notes/2023/satellite.demo.html"><strong aria-hidden="true">5.2.</strong> satellite 红帽注册和内容分发代理</a></li><li class="chapter-item expanded "><a href="../../notes/2023/rhel.subscription.register.html"><strong aria-hidden="true">5.3.</strong> RHEL 订阅在线注册相关问题</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.12.boot.to.install.html"><strong aria-hidden="true">5.4.</strong> 通过新增系统启动项来原地重装操作系统</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.04.os.backup.ReaR.html"><strong aria-hidden="true">5.5.</strong> Relax and Recover(ReaR) 系统备份和灾难恢复</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.04.no-cost.rhel.sub.html"><strong aria-hidden="true">5.6.</strong> 红帽免费的开发者订阅申请和使用</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.01.rpm.belongs.html"><strong aria-hidden="true">5.7.</strong> 在红帽官网查询rpm属于哪个repo</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.01.rhel7.upgrade.to.rhel8.html"><strong aria-hidden="true">5.8.</strong> 离线环境下 原地升级 rhel7-&gt;rhel8</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.01.sysctl.html"><strong aria-hidden="true">5.9.</strong> 系统启动自动加载sysctl配置</a></li><li class="chapter-item expanded "><a href="../../notes/2021/2021.12.ocp.bf2.dpi.url.filter.html"><strong aria-hidden="true">5.10.</strong> Mellanox BF2 刷固件并测试DPI URL-filter场景</a></li><li class="chapter-item expanded "><a href="../../notes/2021/2021.11.bf2.snap.try.html"><strong aria-hidden="true">5.11.</strong> Mellanox BF2 网卡激活snap功能，配置nvme over fabrics 支持</a></li><li class="chapter-item expanded "><a href="../../notes/2021/2021.10.cx6dx.vdpa.offload.html"><strong aria-hidden="true">5.12.</strong> Mellanox CX6 vdpa 硬件卸载 ovs-kernel 方式</a></li><li class="chapter-item expanded "><a href="../../rhel/rhel.build.kernel.html"><strong aria-hidden="true">5.13.</strong> RHEL8编译定制化内核</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.check.whether.vm.html"><strong aria-hidden="true">5.14.</strong> 检查OS是否是运行在虚拟机上</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.4/4.4.ovs.html"><strong aria-hidden="true">5.15.</strong> 两个主机用ovs组网</a></li></ol></li><li class="chapter-item expanded "><a href="../../workshop.html"><strong aria-hidden="true">6.</strong> 优秀的workshop</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.ocp.ocs.workshop.html"><strong aria-hidden="true">6.1.</strong> openshift4 &amp; openshift storage workshop</a></li></ol></li><li class="chapter-item expanded "><a href="../../poc.html"><strong aria-hidden="true">7.</strong> POC</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.3/poc.sc/install.poc.sc.html"><strong aria-hidden="true">7.1.</strong> 2020.04 某次POC openshift LVM调优</a></li></ol></li><li class="chapter-item expanded "><a href="../../osx.html"><strong aria-hidden="true">8.</strong> OSX使用技巧</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../osx/osx.record.system.audio.html"><strong aria-hidden="true">8.1.</strong> 如何录制系统声音</a></li></ol></li></ol>            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                                                <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                                            </div>

                    <h1 class="menu-title">OpenShift4 慢慢走</h1>

                    <div class="right-buttons">
                                                <a href="../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                                                                        <a href="https://github.com/wangzheng422/docker_env" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                                                                        <a href="https://github.com/wangzheng422/docker_env/blob/dev/redhat/ocp4/4.3/4.3.calico.md" title="Suggest an edit" aria-label="Suggest an edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>
                        
                    </div>
                </div>

                                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="openshift-43-calico-离线部署"><a class="header" href="#openshift-43-calico-离线部署">openshift 4.3 calico 离线部署</a></h1>
<p>https://docs.projectcalico.org/getting-started/openshift/requirements</p>
<h2 id="image-prepare"><a class="header" href="#image-prepare">image prepare</a></h2>
<pre><code class="language-bash">
cd /data/ocp4

cat &lt;&lt; EOF &gt; add.image.list
quay.io/tigera/operator-init:v1.3.3
quay.io/tigera/operator:v1.3.3
docker.io/calico/ctl:v3.13.2
docker.io/calico/kube-controllers:v3.13.2
docker.io/calico/node:v3.13.2
docker.io/calico/typha:v3.13.2
docker.io/calico/pod2daemon-flexvol:v3.13.2
docker.io/calico/cni:v3.13.2
EOF

bash add.image.sh add.image.list

bash add.image.load.sh /data/down/mirror_dir

</code></pre>
<h2 id="install"><a class="header" href="#install">install</a></h2>
<pre><code class="language-bash">
# scp install-config.yaml into /root/ocp4
# sed -i 's/OpenShiftSDN/Calico/' install-config.yaml
openshift-install create manifests --dir=/root/ocp4
# scp calico/manifests to manifests
openshift-install create ignition-configs --dir=/root/ocp4

# follow 4.3.disconnect.operator.md to install

oc get tigerastatus

oc get pod -n tigera-operator

oc get pod -n calico-system

# 看看都用了什么image
oc project tigera-operator

oc get pod -o json | jq -r '.items[].spec.containers[].image' | sort | uniq
# quay.io/tigera/operator-init:v1.3.3
# quay.io/tigera/operator:v1.3.3

oc project calico-system

oc get pod -o json | jq -r '.items[].spec.containers[].image' | sort | uniq
# calico/ctl:v3.13.2
# docker.io/calico/kube-controllers:v3.13.2
# docker.io/calico/node:v3.13.2
# docker.io/calico/typha:v3.13.2

# docker.io/calico/pod2daemon-flexvol:v3.13.2
# docker.io/calico/cni:v3.13.2

# 安装控制命令行
oc apply -f calicoctl.yaml

oc exec calicoctl -n calico-system -it -- /calicoctl get node -o wide

oc exec calicoctl -n calico-system -it -- /calicoctl ipam show --show-blocks

oc exec calicoctl -n calico-system -it -- /calicoctl get ipPool -o wide

</code></pre>
<h2 id="calico-下创建-pod指定-ip-pool"><a class="header" href="#calico-下创建-pod指定-ip-pool">calico 下，创建 pod，指定 ip pool</a></h2>
<p>视频讲解</p>
<p><a href="https://www.bilibili.com/video/BV14Z4y1p7wa/"><kbd><img src="imgs/2020-12-17-19-26-18.png" width="600"></kbd></a></p>
<ul>
<li>https://youtu.be/GJSFF7DDCe8</li>
<li>https://www.bilibili.com/video/BV14Z4y1p7wa/</li>
</ul>
<p>https://www.tigera.io/blog/calico-ipam-explained-and-enhanced/</p>
<pre><code class="language-bash"># 创建ip pool
cat &lt;&lt; EOF &gt; calico.ip.pool.yaml
---
apiVersion: projectcalico.org/v3
kind: IPPool
metadata:
  name: ip-pool-1
spec:
  cidr: 172.110.110.0/24
  ipipMode: Always
  natOutgoing: true
---
apiVersion: projectcalico.org/v3
kind: IPPool
metadata:
  name: ip-pool-2
spec:
  cidr: 172.110.220.0/24
  ipipMode: Always
  natOutgoing: true
EOF
cat calico.ip.pool.yaml | oc exec calicoctl -n calico-system -i -- /calicoctl apply -f -

# 检查ip pool的创建情况
oc exec calicoctl -n calico-system -it -- /calicoctl get ipPool -o wide

cat &lt;&lt; EOF &gt; calico.pod.yaml
---
kind: Pod
apiVersion: v1
metadata:
  name: demo-pod1
  namespace: demo
  annotations:
    cni.projectcalico.org/ipv4pools: '[&quot;ip-pool-1&quot;]'
spec:
  nodeSelector:
    kubernetes.io/hostname: 'worker-0.ocp4.redhat.ren'
  restartPolicy: Always
  containers:
    - name: demo
      image: &gt;- 
        registry.redhat.ren:5443/docker.io/wangzheng422/centos:centos7-test
      env:
        - name: key
          value: value
      command: [&quot;iperf3&quot;, &quot;-s&quot;, &quot;-p&quot; ]
      args: [ &quot;6666&quot; ]
      imagePullPolicy: Always
---
kind: Pod
apiVersion: v1
metadata:
  name: demo-pod2
  namespace: demo
  annotations:
    cni.projectcalico.org/ipv4pools: '[&quot;ip-pool-1&quot;]'
spec:
  nodeSelector:
    kubernetes.io/hostname: 'worker-0.ocp4.redhat.ren'
  restartPolicy: Always
  containers:
    - name: demo
      image: &gt;- 
        registry.redhat.ren:5443/docker.io/wangzheng422/centos:centos7-test
      env:
        - name: key
          value: value
      command: [&quot;iperf3&quot;, &quot;-s&quot;, &quot;-p&quot; ]
      args: [ &quot;6666&quot; ]
      imagePullPolicy: Always
---
kind: Pod
apiVersion: v1
metadata:
  name: demo-pod3
  namespace: demo
  annotations:
    cni.projectcalico.org/ipv4pools: '[&quot;ip-pool-2&quot;]'
spec:
  nodeSelector:
    kubernetes.io/hostname: 'worker-0.ocp4.redhat.ren'
  restartPolicy: Always
  containers:
    - name: demo
      image: &gt;- 
        registry.redhat.ren:5443/docker.io/wangzheng422/centos:centos7-test
      env:
        - name: key
          value: value
      command: [&quot;iperf3&quot;, &quot;-s&quot;, &quot;-p&quot; ]
      args: [ &quot;6666&quot; ]
      imagePullPolicy: Always
---
kind: Pod
apiVersion: v1
metadata:
  name: demo-pod4
  namespace: demo
  annotations:
    cni.projectcalico.org/ipv4pools: '[&quot;ip-pool-1&quot;]'
spec:
  nodeSelector:
    kubernetes.io/hostname: 'worker-1.ocp4.redhat.ren'
  restartPolicy: Always
  containers:
    - name: demo
      image: &gt;- 
        registry.redhat.ren:5443/docker.io/wangzheng422/centos:centos7-test
      env:
        - name: key
          value: value
      command: [&quot;iperf3&quot;, &quot;-s&quot;, &quot;-p&quot; ]
      args: [ &quot;6666&quot; ]
      imagePullPolicy: Always
---
kind: Pod
apiVersion: v1
metadata:
  name: demo-pod5
  namespace: demo
  annotations:
    cni.projectcalico.org/ipv4pools: '[&quot;ip-pool-2&quot;]'
spec:
  nodeSelector:
    kubernetes.io/hostname: 'worker-1.ocp4.redhat.ren'
  restartPolicy: Always
  containers:
    - name: demo
      image: &gt;- 
        registry.redhat.ren:5443/docker.io/wangzheng422/centos:centos7-test
      env:
        - name: key
          value: value
      command: [&quot;iperf3&quot;, &quot;-s&quot;, &quot;-p&quot; ]
      args: [ &quot;6666&quot; ]
      imagePullPolicy: Always
EOF
oc apply -f calico.pod.yaml

# 查看pod的IP分配，是按照我们指定的ip地址范围分配的
oc get pod -o wide -n demo
# [root@helper ocp4]# oc get pod -o wide -n demo
# NAME        READY   STATUS    RESTARTS   AGE     IP                NODE                       NOMINATED NODE   READINESS GATES
# demo-pod1   1/1     Running   0          8m52s   172.110.110.67    worker-0.ocp4.redhat.ren   &lt;none&gt;           &lt;none&gt;
# demo-pod2   1/1     Running   0          8m52s   172.110.110.68    worker-0.ocp4.redhat.ren   &lt;none&gt;           &lt;none&gt;
# demo-pod3   1/1     Running   0          8m52s   172.110.220.64    worker-0.ocp4.redhat.ren   &lt;none&gt;           &lt;none&gt;
# demo-pod4   1/1     Running   0          8m52s   172.110.110.128   worker-1.ocp4.redhat.ren   &lt;none&gt;           &lt;none&gt;
# demo-pod5   1/1     Running   0          8m52s   172.110.220.130   worker-1.ocp4.redhat.ren   &lt;none&gt;           &lt;none&gt;

# 获得除了demo-pod1以外的所有pod的ip地址
oc get pod -o json | jq -r '.items[] | select(.metadata.name != &quot;demo-pod1&quot;) | .status.podIP'

# 从demo-pod1上pind这些pod的ip地址，都能ping通。
for var_i in $(oc get pod -o json | jq -r '.items[] | select(.metadata.name != &quot;demo-pod1&quot;) | .status.podIP'); do
    oc exec -n demo demo-pod1 -it -- ping -c 5 ${var_i}
done

# clean up
oc delete -f calico.pod.yaml

cat calico.ip.pool.yaml | oc exec calicoctl -n calico-system -i -- /calicoctl delete -f -

</code></pre>
<h2 id="calico--multus"><a class="header" href="#calico--multus">calico + multus</a></h2>
<p>视频讲解</p>
<p><a href="https://www.bilibili.com/video/BV1zi4y147sk/"><kbd><img src="imgs/2020-12-17-19-27-56.png" width="600"></kbd></a></p>
<ul>
<li>https://youtu.be/MQRv6UASZcA</li>
<li>https://www.bilibili.com/video/BV1zi4y147sk/</li>
<li>https://www.ixigua.com/i6825969911781655048/</li>
</ul>
<pre><code class="language-bash"># 创建multus macvlan需要的ip地址
cat &lt;&lt; EOF &gt; calico.macvlan.yaml
apiVersion: operator.openshift.io/v1
kind: Network
metadata:
  name: cluster
spec:
  additionalNetworks: 
  - name: multus-macvlan-0
    namespace: demo
    type: SimpleMacvlan
    simpleMacvlanConfig:
      ipamConfig:
        type: static
        staticIPAMConfig:
          addresses:
          - address: 10.123.110.11/24
          routes:
  - name: multus-macvlan-1
    namespace: demo
    type: SimpleMacvlan
    simpleMacvlanConfig:
      ipamConfig:
        type: static
        staticIPAMConfig:
          addresses:
          - address: 10.123.110.22/24

EOF
oc apply -f calico.macvlan.yaml

# 检查创建的ip地址
oc get Network.operator.openshift.io -o yaml

# 创建pod，并配置multus，使用macvlan
cat &lt;&lt; EOF &gt; calico.pod.yaml
---
kind: Pod
apiVersion: v1
metadata:
  name: demo-pod1
  namespace: demo
  annotations:
    k8s.v1.cni.cncf.io/networks: '
      [{
        &quot;name&quot;: &quot;multus-macvlan-0&quot;
      }]'
spec:
  nodeSelector:
    kubernetes.io/hostname: 'worker-0.ocp4.redhat.ren'
  restartPolicy: Always
  containers:
    - name: demo
      image: &gt;- 
        registry.redhat.ren:5443/docker.io/wangzheng422/centos:centos7-test
      env:
        - name: key
          value: value
      command: [&quot;iperf3&quot;, &quot;-s&quot;, &quot;-p&quot; ]
      args: [ &quot;6666&quot; ]
      imagePullPolicy: Always
---
kind: Pod
apiVersion: v1
metadata:
  name: demo-pod2
  namespace: demo
  annotations:
    k8s.v1.cni.cncf.io/networks: '
      [{
        &quot;name&quot;: &quot;multus-macvlan-1&quot;
      }]'
spec:
  nodeSelector:
    kubernetes.io/hostname: 'worker-1.ocp4.redhat.ren'
  restartPolicy: Always
  containers:
    - name: demo
      image: &gt;- 
        registry.redhat.ren:5443/docker.io/wangzheng422/centos:centos7-test
      env:
        - name: key
          value: value
      command: [&quot;iperf3&quot;, &quot;-s&quot;, &quot;-p&quot; ]
      args: [ &quot;6666&quot; ]
      imagePullPolicy: Always

EOF
oc apply -f calico.pod.yaml

# 查看demo-pod2上的ip地址
var_ips=$(oc get pod -o json | jq -r '.items[] | select(.metadata.name != &quot;demo-pod1&quot;) | .metadata.annotations[&quot;k8s.v1.cni.cncf.io/networks-status&quot;] | fromjson | .[].ips[0] ' )
echo -e &quot;$var_ips&quot;

# oc get pod -o json | jq -r ' .items[] | select(.metadata.name != &quot;demo-pod1&quot;) | { podname: .metadata.name, ip: ( .metadata.annotations[&quot;k8s.v1.cni.cncf.io/networks-status&quot;] | fromjson | .[].ips[0] ) } | [.podname, .ip] | @tsv'

# 从demo pod1上ping demo pod2上的2个ip地址
for var_i in $var_ips; do
  oc exec -n demo demo-pod1 -it -- ping -c 5 ${var_i}
done

# restore
oc delete -f calico.pod.yaml

cat &lt;&lt; EOF &gt; calico.macvlan.yaml
apiVersion: operator.openshift.io/v1
kind: Network
metadata:
  name: cluster
EOF
oc apply -f calico.macvlan.yaml
</code></pre>
<h2 id="calico--static-ip"><a class="header" href="#calico--static-ip">calico + static ip</a></h2>
<p>https://docs.projectcalico.org/networking/use-specific-ip</p>
<p>视频讲解</p>
<p><a href="https://www.bilibili.com/video/BV1zz411q78i/"><kbd><img src="imgs/2020-12-17-19-30-26.png" width="600"></kbd></a></p>
<ul>
<li>https://youtu.be/q8FtuOzBixA</li>
<li>https://www.bilibili.com/video/BV1zz411q78i/</li>
</ul>
<pre><code class="language-bash"># 创建测试用的静态ip deployment，和pod
cat &lt;&lt; EOF &gt; demo.yaml
---
kind: Deployment
apiVersion: apps/v1
metadata:
  annotations:
  name: demo
spec:
  replicas: 1
  selector:
    matchLabels:
      app: demo
  template:
    metadata:
      labels:
        app: demo  
      annotations:
        &quot;cni.projectcalico.org/ipAddrs&quot;: '[&quot;10.254.22.33&quot;]'
    spec:
      nodeSelector:
        # kubernetes.io/hostname: 'worker-1.ocp4.redhat.ren'
      restartPolicy: Always
      containers:
        - name: demo1
          image: &gt;- 
            registry.redhat.ren:5443/docker.io/wangzheng422/centos:centos7-test
          env:
            - name: key
              value: value
          command: [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;--&quot; ]
          args: [ &quot;trap : TERM INT; sleep infinity &amp; wait&quot; ]
          imagePullPolicy: Always
---
kind: Pod
apiVersion: v1
metadata:
  name: demo-pod1
  namespace: demo
spec:
  nodeSelector:
    kubernetes.io/hostname: 'worker-0.ocp4.redhat.ren'
  restartPolicy: Always
  containers:
    - name: demo
      image: &gt;- 
        registry.redhat.ren:5443/docker.io/wangzheng422/centos:centos7-test
      env:
        - name: key
          value: value
      command: [&quot;iperf3&quot;, &quot;-s&quot;, &quot;-p&quot; ]
      args: [ &quot;6666&quot; ]
      imagePullPolicy: Always
EOF
oc apply -n demo -f demo.yaml

# 检查pod的ip地址
oc get pod -o wide
# NAME                    READY   STATUS    RESTARTS   AGE   IP              NODE                       NOMINATED NODE   READINESS GATES
# demo-8688cf4477-s26rs   1/1     Running   0          5s    10.254.22.33    worker-1.ocp4.redhat.ren   &lt;none&gt;           &lt;none&gt;
# demo-pod1               1/1     Running   0          6s    10.254.115.48   worker-0.ocp4.redhat.ren   &lt;none&gt;           &lt;none&gt;

# ping测试
oc exec -n demo demo-pod1 -it -- ping -c 5 10.254.22.33

# 移动pod到其他node
oc get pod -o wide

# ping测试
oc exec -n demo demo-pod1 -it -- ping -c 5 10.254.22.33

# clean up
oc delete -n demo -f demo.yaml

</code></pre>
<h2 id="calico--mtu"><a class="header" href="#calico--mtu">calico + mtu</a></h2>
<p>https://docs.projectcalico.org/networking/mtu</p>
<p>视频讲解</p>
<p><a href="https://www.bilibili.com/video/BV1Tk4y167Zs/"><kbd><img src="imgs/2020-12-17-19-32-19.png" width="600"></kbd></a></p>
<ul>
<li>https://youtu.be/hTafoKlQiY0</li>
<li>https://www.bilibili.com/video/BV1Tk4y167Zs/</li>
</ul>
<pre><code class="language-bash"># 先检查一下已有的mtu
cat &lt;&lt; EOF &gt; demo.yaml
---
kind: Pod
apiVersion: v1
metadata:
  name: demo-pod1
  namespace: demo
spec:
  nodeSelector:
    kubernetes.io/hostname: 'worker-0.ocp4.redhat.ren'
  restartPolicy: Always
  containers:
    - name: demo
      image: &gt;- 
        registry.redhat.ren:5443/docker.io/wangzheng422/centos:centos7-test
      env:
        - name: key
          value: value
      command: [&quot;iperf3&quot;, &quot;-s&quot;, &quot;-p&quot; ]
      args: [ &quot;6666&quot; ]
      imagePullPolicy: Always
---
kind: Pod
apiVersion: v1
metadata:
  name: demo-pod2
  namespace: demo
spec:
  nodeSelector:
    kubernetes.io/hostname: 'worker-1.ocp4.redhat.ren'
  restartPolicy: Always
  containers:
    - name: demo
      image: &gt;- 
        registry.redhat.ren:5443/docker.io/wangzheng422/centos:centos7-test
      env:
        - name: key
          value: value
      command: [&quot;iperf3&quot;, &quot;-s&quot;, &quot;-p&quot; ]
      args: [ &quot;6666&quot; ]
      imagePullPolicy: Always
EOF
oc apply -n demo -f demo.yaml

# 检查 mtu，现在tunl上是1480，eth0上是1410
oc exec -it demo-pod1 -- ip a
# 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
#     link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
#     inet 127.0.0.1/8 scope host lo
#        valid_lft forever preferred_lft forever
#     inet6 ::1/128 scope host
#        valid_lft forever preferred_lft forever
# 2: tunl0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop state DOWN group default qlen 1000
#     link/ipip 0.0.0.0 brd 0.0.0.0
# 4: eth0@if54: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1410 qdisc noqueue state UP group default
#     link/ether c2:e9:6a:c8:62:77 brd ff:ff:ff:ff:ff:ff link-netnsid 0
#     inet 10.254.115.50/32 scope global eth0
#        valid_lft forever preferred_lft forever
#     inet6 fe80::c0e9:6aff:fec8:6277/64 scope link
#        valid_lft forever preferred_lft forever

# 把mtu 从1410改成700
oc get installations.operator.tigera.io -o yaml

oc edit installations.operator.tigera.io
# spec:
#   calicoNetwork:
#     mtu: 700

# 重启calico node pod
# oc delete deploy calico-kube-controllers -n calico-system
# oc delete deploy calico-typha -n calico-system
# oc delete ds calico-node -n calico-system
oc delete -n demo -f demo.yaml

# 重启worker node

# 重新创建pod
# oc apply -n demo -f demo.yaml

# 查看mtu
oc exec -i demo-pod1 -- ip a
oc exec -i demo-pod2 -- ip a

# 各种ping测试
var_ip=$(oc get pod -o json | jq -r '.items[] | select(.metadata.name == &quot;demo-pod1&quot;) | .status.podIP')
echo $var_ip
# ICMP+IP 的包头有 28 bytes
#  the IP stack of your system adds ICMP and IP headers which equals to 28 bytes
oc exec -i demo-pod2 -- ping -M do -s $((600-28)) -c 5 $var_ip
oc exec -i demo-pod2 -- ping -M do -s $((700-28)) -c 5 $var_ip
oc exec -i demo-pod2 -- ping -M do -s $((800-28)) -c 5 $var_ip

# 把mtu从700恢复成1410
oc edit installations.operator.tigera.io
# spec:
#   calicoNetwork:

oc get installations.operator.tigera.io -o yaml

# 重启calico node pod
# oc delete deploy calico-kube-controllers -n calico-system
# oc delete deploy calico-typha -n calico-system
# oc delete ds calico-node -n calico-system
oc delete -n demo -f demo.yaml

# 重启worker node

# 重新创建pod
# oc apply -n demo -f demo.yaml

# 查看mtu
oc exec -i demo-pod1 -- ip a
oc exec -i demo-pod2 -- ip a

# 各种ping测试
var_ip=$(oc get pod -o json | jq -r '.items[] | select(.metadata.name == &quot;demo-pod1&quot;) | .status.podIP')
echo $var_ip
# ICMP+IP 的包头有 28 bytes
#  the IP stack of your system adds ICMP and IP headers which equals to 28 bytes
oc exec -i demo-pod2 -- ping -M do -s $((600-28)) -c 5 $var_ip
oc exec -i demo-pod2 -- ping -M do -s $((700-28)) -c 5 $var_ip
oc exec -i demo-pod2 -- ping -M do -s $((800-28)) -c 5 $var_ip

# restore
oc delete -n demo -f demo.yaml

</code></pre>
<h2 id="calico--ipv4v6-dual-stack"><a class="header" href="#calico--ipv4v6-dual-stack">calico + ipv4/v6 dual stack</a></h2>
<p>视频讲解</p>
<p><a href="https://www.bilibili.com/video/BV1va4y1e7c1/"><kbd><img src="imgs/2020-12-17-19-33-34.png" width="600"></kbd></a></p>
<ul>
<li>https://youtu.be/ju4d7jWs7DQ</li>
<li>https://www.bilibili.com/video/BV1va4y1e7c1/</li>
<li>https://www.ixigua.com/i6827830624431112715/</li>
</ul>
<pre><code class="language-bash"># 在集群安装之前，配置文件写入ipv6地址信息
# install openshift with calico and ipv6 config
# networking:
#   clusterNetworks:
#   - cidr: 10.254.0.0/16
#     hostPrefix: 24
#   - cidr: fd00:192:168:7::/64
#     hostPrefix: 80

# 在安装集群的过程中，给主机添加ipv6地址，安装就可以顺利继续了
## add ipv6 address to hosts
# helper
nmcli con modify eth0 ipv6.address &quot;fd00:192:168:7::11/64&quot; ipv6.gateway fd00:192:168:7::1
nmcli con modify eth0 ipv6.method manual
nmcli con reload
nmcli con up eth0

# master0
nmcli con modify ens3 ipv6.address fd00:192:168:7::13/64 ipv6.gateway fd00:192:168:7::1 ipv6.method manual
nmcli con reload
nmcli con up ens3

# master1
nmcli con modify ens3 ipv6.address fd00:192:168:7::14/64 ipv6.gateway fd00:192:168:7::1 ipv6.method manual
nmcli con reload
nmcli con up ens3

# master2
nmcli con modify ens3 ipv6.address fd00:192:168:7::15/64 ipv6.gateway fd00:192:168:7::1 ipv6.method manual
nmcli con reload
nmcli con up ens3

# worker0
nmcli con modify ens3 ipv6.address fd00:192:168:7::16/64 ipv6.gateway fd00:192:168:7::1 ipv6.method manual
nmcli con reload
nmcli con up ens3

# worker1
nmcli con modify ens3 ipv6.address fd00:192:168:7::17/64 ipv6.gateway fd00:192:168:7::1 ipv6.method manual
nmcli con reload
nmcli con up ens3

oc apply -f calicoctl.yaml

oc exec calicoctl -n calico-system -it -- /calicoctl get node -o wide

oc exec calicoctl -n calico-system -it -- /calicoctl ipam show --show-blocks

oc exec calicoctl -n calico-system -it -- /calicoctl get ipPool -o wide

# 在openshift的开发者视图上部署一个tomcat

# 从浏览器上，直接访问route入口，测试ipv4的效果。

# 在master0上直接访问worker1上的pod ipv6地址
curl -g -6 'http://[fd00:192:168:7:697b:8c59:3298:b950]:8080/'

# 在集群外，直接访问worker0上的pod ipv6地址
ip -6 route add fd00:192:168:7:697b:8c59:3298::/112 via fd00:192:168:7::17 dev eth0
curl -g -6 'http://[fd00:192:168:7:697b:8c59:3298:b950]:8080/'

</code></pre>
<h2 id="calico--bgp"><a class="header" href="#calico--bgp">calico + bgp</a></h2>
<pre><code class="language-bash">
cat &lt;&lt; EOF &gt; calico.serviceip.yaml
apiVersion: projectcalico.org/v3
kind: BGPConfiguration
metadata:
  name: default
spec:
  serviceClusterIPs:
  - cidr: 10.96.0.0/16
EOF
cat calico.serviceip.yaml | oc exec calicoctl -n calico-system -i -- /calicoctl apply -f -

oc exec calicoctl -n calico-system -i -- /calicoctl patch bgpconfiguration default -p '{&quot;spec&quot;: {&quot;nodeToNodeMeshEnabled&quot;: true}}'

oc exec calicoctl -n calico-system -it -- /calicoctl get bgpconfig default -o yaml

oc exec calicoctl -n calico-system -it -- /calicoctl get node -o wide

oc exec calicoctl -n calico-system -it -- /calicoctl ipam show --show-blocks

oc exec calicoctl -n calico-system -it -- /calicoctl get ipPool -o wide


oc exec calicoctl -n calico-system -it -- /calicoctl get workloadEndpoint

oc exec calicoctl -n calico-system -it -- /calicoctl get BGPPeer

cat &lt;&lt; EOF &gt; calico.bgp.yaml
---
apiVersion: projectcalico.org/v3
kind: BGPPeer
metadata:
  name: my-global-peer
spec:
  peerIP: 192.168.7.11
  asNumber: 64513
EOF
cat calico.bgp.yaml | oc exec calicoctl -n calico-system -i -- /calicoctl apply -f -

# on helper
# https://www.vultr.com/docs/configuring-bgp-using-quagga-on-vultr-centos-7
yum install quagga
systemctl start zebra
systemctl start bgpd
cp /usr/share/doc/quagga-*/bgpd.conf.sample /etc/quagga/bgpd.conf
vtysh
show running-config
configure terminal
no router bgp 7675
router bgp 64513
no auto-summary
no synchronization
neighbor 192.168.7.13 remote-as 64512
neighbor 192.168.7.13 description &quot;calico&quot;
neighbor 192.168.7.13 attribute-unchanged next-hop
neighbor 192.168.7.13 ebgp-multihop 255
neighbor 192.168.7.13 next-hop-self
# no neighbor 192.168.7.13 next-hop-self
neighbor 192.168.7.13 activate
interface eth0
exit
exit
write
show running-config
show ip bgp summary

# 测试一下
cat &lt;&lt; EOF &gt; calico.ip.pool.yaml
---
apiVersion: projectcalico.org/v3
kind: IPPool
metadata:
  name: ip-pool-1
spec:
  cidr: 172.110.110.0/24
  ipipMode: Always
  natOutgoing: false
---
apiVersion: projectcalico.org/v3
kind: IPPool
metadata:
  name: ip-pool-2
spec:
  cidr: 172.110.220.0/24
  ipipMode: Always
  natOutgoing: false
EOF
cat calico.ip.pool.yaml | oc exec calicoctl -n calico-system -i -- /calicoctl apply -f -

oc exec calicoctl -n calico-system -it -- /calicoctl get ipPool -o wide

cat &lt;&lt; EOF &gt; calico.pod.yaml
---
kind: Pod
apiVersion: v1
metadata:
  name: demo-pod1
  namespace: demo
  annotations:
    cni.projectcalico.org/ipv4pools: '[&quot;ip-pool-1&quot;]'
spec:
  nodeSelector:
    kubernetes.io/hostname: 'worker-0.ocp4.redhat.ren'
  restartPolicy: Always
  containers:
    - name: demo
      image: &gt;- 
        registry.redhat.ren:5443/docker.io/wangzheng422/centos:centos7-test
      env:
        - name: key
          value: value
      command: [&quot;iperf3&quot;, &quot;-s&quot;, &quot;-p&quot; ]
      args: [ &quot;6666&quot; ]
      imagePullPolicy: Always
---
kind: Pod
apiVersion: v1
metadata:
  name: demo-pod2
  namespace: demo
  annotations:
    cni.projectcalico.org/ipv4pools: '[&quot;ip-pool-1&quot;]'
spec:
  nodeSelector:
    kubernetes.io/hostname: 'worker-0.ocp4.redhat.ren'
  restartPolicy: Always
  containers:
    - name: demo
      image: &gt;- 
        registry.redhat.ren:5443/docker.io/wangzheng422/centos:centos7-test
      env:
        - name: key
          value: value
      command: [&quot;iperf3&quot;, &quot;-s&quot;, &quot;-p&quot; ]
      args: [ &quot;6666&quot; ]
      imagePullPolicy: Always
---
kind: Pod
apiVersion: v1
metadata:
  name: demo-pod3
  namespace: demo
  annotations:
    cni.projectcalico.org/ipv4pools: '[&quot;ip-pool-2&quot;]'
spec:
  nodeSelector:
    kubernetes.io/hostname: 'worker-0.ocp4.redhat.ren'
  restartPolicy: Always
  containers:
    - name: demo
      image: &gt;- 
        registry.redhat.ren:5443/docker.io/wangzheng422/centos:centos7-test
      env:
        - name: key
          value: value
      command: [&quot;iperf3&quot;, &quot;-s&quot;, &quot;-p&quot; ]
      args: [ &quot;6666&quot; ]
      imagePullPolicy: Always
---
kind: Pod
apiVersion: v1
metadata:
  name: demo-pod4
  namespace: demo
  annotations:
    cni.projectcalico.org/ipv4pools: '[&quot;ip-pool-1&quot;]'
spec:
  nodeSelector:
    kubernetes.io/hostname: 'worker-1.ocp4.redhat.ren'
  restartPolicy: Always
  containers:
    - name: demo
      image: &gt;- 
        registry.redhat.ren:5443/docker.io/wangzheng422/centos:centos7-test
      env:
        - name: key
          value: value
      command: [&quot;iperf3&quot;, &quot;-s&quot;, &quot;-p&quot; ]
      args: [ &quot;6666&quot; ]
      imagePullPolicy: Always
---
kind: Pod
apiVersion: v1
metadata:
  name: demo-pod5
  namespace: demo
  annotations:
    cni.projectcalico.org/ipv4pools: '[&quot;ip-pool-2&quot;]'
spec:
  nodeSelector:
    kubernetes.io/hostname: 'worker-1.ocp4.redhat.ren'
  restartPolicy: Always
  containers:
    - name: demo
      image: &gt;- 
        registry.redhat.ren:5443/docker.io/wangzheng422/centos:centos7-test
      env:
        - name: key
          value: value
      command: [&quot;iperf3&quot;, &quot;-s&quot;, &quot;-p&quot; ]
      args: [ &quot;6666&quot; ]
      imagePullPolicy: Always
EOF
oc apply -f calico.pod.yaml

</code></pre>
<h2 id="run-caliconode-with-backendnone"><a class="header" href="#run-caliconode-with-backendnone">run calico/node with —backend=none</a></h2>
<p>CALICO_NETWORKING_BACKEND none</p>
<p>https://docs.projectcalico.org/reference/node/configuration</p>
<p><img src="imgs/2020-11-16-22-50-39.png" alt="" /></p>
<h2 id="backups"><a class="header" href="#backups">backups</a></h2>
<pre><code class="language-bash">
skopeo copy docker://quay.io/tigera/operator-init:v1.3.3 docker://registry.redhat.ren:5443/tigera/operator-init:v1.3.3
skopeo copy docker://quay.io/tigera/operator:v1.3.3 docker://registry.redhat.ren:5443/tigera/operator:v1.3.3

skopeo copy docker://docker.io/calico/ctl:v3.13.2 docker://registry.redhat.ren:5443/calico/ctl:v3.13.2
skopeo copy docker://docker.io/calico/kube-controllers:v3.13.2 docker://registry.redhat.ren:5443/calico/kube-controllers:v3.13.2
skopeo copy docker://docker.io/calico/node:v3.13.2 docker://registry.redhat.ren:5443/calico/node:v3.13.2
skopeo copy docker://docker.io/calico/typha:v3.13.2 docker://registry.redhat.ren:5443/calico/typha:v3.13.2
skopeo copy docker://docker.io/calico/pod2daemon-flexvol:v3.13.2 docker://registry.redhat.ren:5443/calico/pod2daemon-flexvol:v3.13.2
skopeo copy docker://docker.io/calico/cni:v3.13.2 docker://registry.redhat.ren:5443/calico/cni:v3.13.2

curl https://docs.projectcalico.org/manifests/ocp/crds/01-crd-installation.yaml -o manifests/01-crd-installation.yaml
curl https://docs.projectcalico.org/manifests/ocp/crds/01-crd-tigerastatus.yaml -o manifests/01-crd-tigerastatus.yaml
curl https://docs.projectcalico.org/manifests/ocp/crds/calico/kdd/02-crd-bgpconfiguration.yaml -o manifests/02-crd-bgpconfiguration.yaml
curl https://docs.projectcalico.org/manifests/ocp/crds/calico/kdd/02-crd-bgppeer.yaml -o manifests/02-crd-bgppeer.yaml
curl https://docs.projectcalico.org/manifests/ocp/crds/calico/kdd/02-crd-blockaffinity.yaml -o manifests/02-crd-blockaffinity.yaml
curl https://docs.projectcalico.org/manifests/ocp/crds/calico/kdd/02-crd-clusterinformation.yaml -o manifests/02-crd-clusterinformation.yaml
curl https://docs.projectcalico.org/manifests/ocp/crds/calico/kdd/02-crd-felixconfiguration.yaml -o manifests/02-crd-felixconfiguration.yaml
curl https://docs.projectcalico.org/manifests/ocp/crds/calico/kdd/02-crd-globalnetworkpolicy.yaml -o manifests/02-crd-globalnetworkpolicy.yaml
curl https://docs.projectcalico.org/manifests/ocp/crds/calico/kdd/02-crd-globalnetworkset.yaml -o manifests/02-crd-globalnetworkset.yaml
curl https://docs.projectcalico.org/manifests/ocp/crds/calico/kdd/02-crd-hostendpoint.yaml -o manifests/02-crd-hostendpoint.yaml
curl https://docs.projectcalico.org/manifests/ocp/crds/calico/kdd/02-crd-ipamblock.yaml -o manifests/02-crd-ipamblock.yaml
curl https://docs.projectcalico.org/manifests/ocp/crds/calico/kdd/02-crd-ipamconfig.yaml -o manifests/02-crd-ipamconfig.yaml
curl https://docs.projectcalico.org/manifests/ocp/crds/calico/kdd/02-crd-ipamhandle.yaml -o manifests/02-crd-ipamhandle.yaml
curl https://docs.projectcalico.org/manifests/ocp/crds/calico/kdd/02-crd-ippool.yaml -o manifests/02-crd-ippool.yaml
curl https://docs.projectcalico.org/manifests/ocp/crds/calico/kdd/02-crd-networkpolicy.yaml -o manifests/02-crd-networkpolicy.yaml
curl https://docs.projectcalico.org/manifests/ocp/crds/calico/kdd/02-crd-networkset.yaml -o manifests/02-crd-networkset.yaml
curl https://docs.projectcalico.org/manifests/ocp/tigera-operator/00-namespace-tigera-operator.yaml -o manifests/00-namespace-tigera-operator.yaml
curl https://docs.projectcalico.org/manifests/ocp/tigera-operator/02-rolebinding-tigera-operator.yaml -o manifests/02-rolebinding-tigera-operator.yaml
curl https://docs.projectcalico.org/manifests/ocp/tigera-operator/02-role-tigera-operator.yaml -o manifests/02-role-tigera-operator.yaml
curl https://docs.projectcalico.org/manifests/ocp/tigera-operator/02-serviceaccount-tigera-operator.yaml -o manifests/02-serviceaccount-tigera-operator.yaml
curl https://docs.projectcalico.org/manifests/ocp/tigera-operator/02-configmap-calico-resources.yaml -o manifests/02-configmap-calico-resources.yaml
curl https://docs.projectcalico.org/manifests/ocp/tigera-operator/02-configmap-tigera-install-script.yaml -o manifests/02-configmap-tigera-install-script.yaml
curl https://docs.projectcalico.org/manifests/ocp/tigera-operator/02-tigera-operator.yaml -o manifests/02-tigera-operator.yaml
curl https://docs.projectcalico.org/manifests/ocp/01-cr-installation.yaml -o manifests/01-cr-installation.yaml

curl https://docs.projectcalico.org/manifests/calicoctl.yaml -o manifests/calicoctl.yaml

oc get Network.operator.openshift.io -o yaml
  # defaultNetwork:
  #   calicoSDNConfig:
  #     mtu: 700
  #   openshiftSDNConfig:
  #     mtu: 700
oc api-resources | grep -i calico
oc api-resources | grep -i tigera

oc get FelixConfiguration -o yaml

oc exec calicoctl -n calico-system -it -- /calicoctl get bgpconfig default

cat &lt;&lt; EOF &gt; calico.serviceip.yaml
apiVersion: projectcalico.org/v3
kind: BGPConfiguration
metadata:
  name: default
spec:
  serviceClusterIPs:
  - cidr: 10.96.0.0/16
  - cidr: fd00:192:168:7:1:1::/112
EOF
cat calico.serviceip.yaml | oc exec calicoctl -n calico-system -i -- /calicoctl apply -f -

oc exec calicoctl -n calico-system -it -- /calicoctl get workloadEndpoint
oc exec calicoctl -n calico-system -it -- /calicoctl get BGPPeer

cat &lt;&lt; EOF &gt; calico.bgp.yaml
---
apiVersion: projectcalico.org/v3
kind: BGPPeer
metadata:
  name: my-global-peer
spec:
  peerIP: 192.168.7.11
  asNumber: 64513
---
apiVersion: projectcalico.org/v3
kind: BGPPeer
metadata:
  name: my-global-peer-v6
spec:
  peerIP: fd00:192:168:7::11
  asNumber: 64513
EOF
cat calico.bgp.yaml | oc exec calicoctl -n calico-system -i -- /calicoctl apply -f -

# on helper
# https://www.vultr.com/docs/configuring-bgp-using-quagga-on-vultr-centos-7
yum install quagga
systemctl start zebra
systemctl start bgpd
cp /usr/share/doc/quagga-*/bgpd.conf.sample /etc/quagga/bgpd.conf
vtysh
show running-config
configure terminal
no router bgp 7675
router bgp 64513
no auto-summary
no synchronization
neighbor 192.168.7.13 remote-as 64512
neighbor 192.168.7.13 description &quot;calico&quot;
neighbor fd00:192:168:7::13 remote-as 64512
neighbor fd00:192:168:7::13 description &quot;calico&quot;
interface eth0
?? no ipv6 nd suppress-ra
exit
exit
write
show running-config
show ip bgp summary

# https://access.redhat.com/documentation/en-us/openshift_container_platform/4.3/html/networking/cluster-network-operator

oc get Network.operator.openshift.io -o yaml
oc edit Network.operator.openshift.io cluster
  # - cidr: fd01:192:168:7:11:/64
  #   hostPrefix: 80

oc get network.config/cluster
oc edit network.config/cluster

oc get installations.operator.tigera.io -o yaml
oc edit installations.operator.tigera.io
    # nodeAddressAutodetectionV6:
    #   firstFound: true
    - blockSize: 122
      cidr: fd01:192:168:7:11:/80
      encapsulation: None
      natOutgoing: Disabled
      nodeSelector: all()

</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                                                    <a rel="prev" href="../../ocp4/4.5/4.5.is.sample.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                        
                                                    <a rel="next" href="../../ocp4/4.2/4.2.upgrade.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                                    <a rel="prev" href="../../ocp4/4.5/4.5.is.sample.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                
                                    <a rel="next" href="../../ocp4/4.2/4.2.upgrade.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
                            </nav>

        </div>

        
        
        
                <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        
        
                <script src="../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../searcher.js" type="text/javascript" charset="utf-8"></script>
        
        <script src="../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        
        
    </body>
</html>

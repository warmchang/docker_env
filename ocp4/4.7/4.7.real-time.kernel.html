<!DOCTYPE HTML>
<html lang="zh" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>在节点上启用实时操作系统 real-time kernel - OpenShift4 慢慢走</title>
                

        <!-- Custom HTML head -->
        <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-E3FRMDB7L2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-E3FRMDB7L2');
</script>

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

                <link rel="icon" href="../../favicon.svg">
                        <link rel="shortcut icon" href="../../favicon.png">
                <link rel="stylesheet" href="../../css/variables.css">
        <link rel="stylesheet" href="../../css/general.css">
        <link rel="stylesheet" href="../../css/chrome.css">
                <link rel="stylesheet" href="../../css/print.css" media="print">
        
        <!-- Fonts -->
        <link rel="stylesheet" href="../../FontAwesome/css/font-awesome.css">
                <link rel="stylesheet" href="../../fonts/fonts.css">
        
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../highlight.css">
        <link rel="stylesheet" href="../../tomorrow-night.css">
        <link rel="stylesheet" href="../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        
            </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../../index.html">介绍</a></li><li class="chapter-item expanded "><a href="../../install.html"><strong aria-hidden="true">1.</strong> openshift4 安装系列</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.ocp.pull.secret.html"><strong aria-hidden="true">1.1.</strong> 如何获得 openshift4 免费下载密钥</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.build.dist.html"><strong aria-hidden="true">1.2.</strong> openshift4 离线安装介质的制作</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.sno.static.ip.local.assisted.connected.html"><strong aria-hidden="true">1.3.</strong> assisted install 联线模式下 单节点ocp 无需dhcp 静态ip部署</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.sno.static.ip.local.assisted.disconnected.html"><strong aria-hidden="true">1.4.</strong> assisted install 离线模式下 单节点ocp 无需dhcp 静态ip部署</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.disconnect.bm.upi.static.ip.on.rhel7.html"><strong aria-hidden="true">1.5.</strong> openshift4 rhel7物理机 baremetal UPI模式 离线安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.disconnect.bm.upi.static.ip.on.rhel8.html"><strong aria-hidden="true">1.6.</strong> openshift4 rhel8物理机 baremetal UPI模式 离线安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.disconnect.bm.ipi.on.rhel8.html"><strong aria-hidden="true">1.7.</strong> openshift4 物理机 baremetal IPI模式 离线安装 单网络模式</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.disconnect.bm.ipi.on.rhel8.provisionning.network.html"><strong aria-hidden="true">1.8.</strong> openshift4 物理机 baremetal IPI模式 离线安装 双网络模式</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.cilium.html"><strong aria-hidden="true">1.9.</strong> openshift4 尝鲜 cilium CNI</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.nvidia.gpu.disconnected.html"><strong aria-hidden="true">1.10.</strong> nvidia gpu for openshift 4.6 disconnected 英伟达GPU离线安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.add.image.html"><strong aria-hidden="true">1.11.</strong> openshift4 初始安装后 补充镜像</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.is.sample.html"><strong aria-hidden="true">1.12.</strong> openshift4 补充samples operator 需要的 image stream</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.calico.html"><strong aria-hidden="true">1.13.</strong> openshift4 calico 离线部署</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.2/4.2.upgrade.html"><strong aria-hidden="true">1.14.</strong> openshift4 集群升级</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.shrink.sysroot.html"><strong aria-hidden="true">1.15.</strong> 缩小根分区 / sysroot 的大小</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.update.service.html"><strong aria-hidden="true">1.16.</strong> 部署升级服务 完善离线升级功能</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.windows.node.html"><strong aria-hidden="true">1.17.</strong> 添加 win10 worker 节点</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.sno.using.bootstrap.disconnected.html"><strong aria-hidden="true">1.18.</strong> 单节点ocp 安装 无需dhcp 静态ip部署</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.disconnect.bm.ipi.sno.static.ip.html"><strong aria-hidden="true">1.19.</strong> IPI模式 单节点 离线 单网络模式 安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.acm.ztp.disconnected.auto.html"><strong aria-hidden="true">1.20.</strong> ACM zero touch provision 远程单节点集群 全自动安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.coreos.boot.html"><strong aria-hidden="true">1.21.</strong> coreos 启动和分区挂载分析</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.installer.html"><strong aria-hidden="true">1.22.</strong> openshift4 单节点 命令行安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.partition.quay.html"><strong aria-hidden="true">1.23.</strong> openshift4 单节点 在第一块硬盘上添加更多分区</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.nfs.lvm.html"><strong aria-hidden="true">1.24.</strong> openshift4 单节点 使用 lvm 和 nfs 在集群内提供存储</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.boot.from.linux.html"><strong aria-hidden="true">1.25.</strong> openshift4 单节点 从centos7/8 开始安装</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.sno.odf.html"><strong aria-hidden="true">1.26.</strong> openshift4 单节点 安装精简版 ODF/ceph</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.replace.coreos.html"><strong aria-hidden="true">1.27.</strong> 定制 rhcos</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.rpm-ostree.install.html"><strong aria-hidden="true">1.28.</strong> rhcos 里面安装 rpm</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.component.version.html"><strong aria-hidden="true">1.29.</strong> openshift 4 组件版本</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.embeded.dns.haproxy.registry.html"><strong aria-hidden="true">1.30.</strong> 内嵌 dns, haproxy, registrty</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.replace.coreos.rhel.9.0.html"><strong aria-hidden="true">1.31.</strong> 升级 openshift 4.10 内核到 rhel 9.1 支持 海光 x86 cpu</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.11/4.11.acm.hypershift.html"><strong aria-hidden="true">1.32.</strong> 使用 hypershift 安装控制面托管的 openshift 集群</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.12/4.12.3node.upi.agent.html"><strong aria-hidden="true">1.33.</strong> 使用 agent based installer 安装 3 节点集群</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.12/4.12.single.node.upi.agent.html"><strong aria-hidden="true">1.34.</strong> 使用 agent based installer 安装 单节点集群</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.12/4.12.ocp.driver.build.html"><strong aria-hidden="true">1.35.</strong> 在 openshift 内部编译内核驱动 rpm 并使用</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.12/4.12.demo.lab.html"><strong aria-hidden="true">1.36.</strong> how to build an openshift 4.12 demo lab from scratch</a></li></ol></li><li class="chapter-item expanded "><a href="../../usage.html"><strong aria-hidden="true">2.</strong> openshift4 使用系列</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.11/4.11.3node.ipi.for.osp.prod.html"><strong aria-hidden="true">2.1.</strong> 在 openshift 4.11 上安装和运行 openstack</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.flexran.20.11.pf.deploy.html"><strong aria-hidden="true">2.2.</strong> 在openshift4上运行 OpenRAN 无线基站应用</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.netflow.table.html"><strong aria-hidden="true">2.3.</strong> openshift4 可视化 ovs netflow</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.flexran.20.11.html"><strong aria-hidden="true">2.4.</strong> intel o-ran flexran 方案在openshift4上的安装和使用</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.ci.cd.demo.html"><strong aria-hidden="true">2.5.</strong> ci/cd pipeline gitops演示</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.oc.exec.html"><strong aria-hidden="true">2.6.</strong> oc/kubectl exec 原理分析</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.nf.conntrack.html"><strong aria-hidden="true">2.7.</strong> nf_conntrack 在 openshift4.9上的处理</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.load.3rd.part.driver.html"><strong aria-hidden="true">2.8.</strong> 加载第三方设备驱动</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.9/4.9.nep.containerized.helm.html"><strong aria-hidden="true">2.9.</strong> helm chart/helm operator</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.metalb.l2.html"><strong aria-hidden="true">2.10.</strong> 使用 MetalLB 用 Layer2 发布 LoadBalancer</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.metalb.html"><strong aria-hidden="true">2.11.</strong> 使用 MetalLB 用 BGP 发布 LoadBalancer</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.8/4.8.kata.html"><strong aria-hidden="true">2.12.</strong> kata / 沙盒容器</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.sriov.html"><strong aria-hidden="true">2.13.</strong> 在非官方支持的网卡上，测试SRIOV/DPDK</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.keepalived.operator.html"><strong aria-hidden="true">2.14.</strong> 使用 keepalived 激活 LoadBalancer 服务类型</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.real-time.kernel.html" class="active"><strong aria-hidden="true">2.15.</strong> 在节点上启用实时操作系统 real-time kernel</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.install.kmod.driver.html"><strong aria-hidden="true">2.16.</strong> 从容器向宿主机注入内核模块 kmod / driver</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.vgpu.sharing.deploy.html"><strong aria-hidden="true">2.17.</strong> GPU/vGPU 共享</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.4/4.4.headless.service.html"><strong aria-hidden="true">2.18.</strong> openshift headless service讲解</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.volumn.html"><strong aria-hidden="true">2.19.</strong> openshift volumn 存储的各种测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.SupportPodPidsLimit.html"><strong aria-hidden="true">2.20.</strong> openshift 设置 SupportPodPidsLimit 解除 pids 限制</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.sso.html"><strong aria-hidden="true">2.21.</strong> openshift4 配置 SSO 点单认证</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.scc.html"><strong aria-hidden="true">2.22.</strong> openshift4 SCC 相关安全能力测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.recover.node.not.ready.html"><strong aria-hidden="true">2.23.</strong> openshift4 从 node not ready 状态恢复</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.QoS.nic.html"><strong aria-hidden="true">2.24.</strong> openshift4 QoS 能力</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.QoS.nic.high.html"><strong aria-hidden="true">2.25.</strong> openshift4 QoS 在流量压力下的表现</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.proxy.html"><strong aria-hidden="true">2.26.</strong> openshift4 使用 image proxy 来下载镜像</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.numa.html"><strong aria-hidden="true">2.27.</strong> openshift4 NUMA 绑核测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.network.policy.html"><strong aria-hidden="true">2.28.</strong> openshift4 Network Policy 测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.multicast.html"><strong aria-hidden="true">2.29.</strong> openshift4 网络多播 测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.firewall.html"><strong aria-hidden="true">2.30.</strong> openshift4 配置节点防火墙</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.ldap.html"><strong aria-hidden="true">2.31.</strong> openshift4 集成 ldap</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.image.pull.html"><strong aria-hidden="true">2.32.</strong> openshift4 维护 image pull secret</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.huge.page.html"><strong aria-hidden="true">2.33.</strong> openshift4 使用大页内存 huge page</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.helm.html"><strong aria-hidden="true">2.34.</strong> openshift4 使用 helm</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.haproxy.html"><strong aria-hidden="true">2.35.</strong> openshift4 定制router 支持 TCP ingress</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.grafana.html"><strong aria-hidden="true">2.36.</strong> openshift4 监控能力展示 grafana</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.cpu.manager.html"><strong aria-hidden="true">2.37.</strong> openshift4 CPU 绑核 测试</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.3/4.3.build.config.html"><strong aria-hidden="true">2.38.</strong> openshift4 build config &amp; hpa 自动化编译和自动扩缩容</a></li></ol></li><li class="chapter-item expanded "><a href="../../ccn.html"><strong aria-hidden="true">3.</strong> 应用上云系列教程 CCN</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.4/4.4.ccn.devops.deploy.html"><strong aria-hidden="true">3.1.</strong> 应用上云系列教程 containerized cloud native (CCN) for openshift 4.4</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.4/4.4.ccn.devops.build.html"><strong aria-hidden="true">3.2.</strong> CCN 安装介质制作 for openshift 4.4</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.ccn.devops.deploy.html"><strong aria-hidden="true">3.3.</strong> 应用上云系列教程 containerized cloud native (CCN) for openshift 4.6</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.6/4.6.ccn.devops.build.html"><strong aria-hidden="true">3.4.</strong> CCN 安装介质制作 for openshift 4.6</a></li></ol></li><li class="chapter-item expanded "><a href="../../rh.cloud.html"><strong aria-hidden="true">4.</strong> 红帽其他产品系列</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.10/4.10.acm.observ.html"><strong aria-hidden="true">4.1.</strong> ACM observability for openshift 4.10</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.01.ansible.install.html"><strong aria-hidden="true">4.2.</strong> 离线安装 ansible platform</a></li><li class="chapter-item expanded "><a href="../../notes/2021/2021.08.virus.html"><strong aria-hidden="true">4.3.</strong> RHACS 应对log4j 原理和实践</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.ocp.ocs.cnv.ceph.html"><strong aria-hidden="true">4.4.</strong> openshift承载虚拟化业务(CNV)</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.rhacs.html"><strong aria-hidden="true">4.5.</strong> RHACS / stackrox</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.7/4.7.rhacs.deep.html"><strong aria-hidden="true">4.6.</strong> 为 RHACS 找个应用场景: 安全合规测试云 </a></li></ol></li><li class="chapter-item expanded "><a href="../../os.html"><strong aria-hidden="true">5.</strong> 操作系统相关</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../notes/2023/satellite.demo.html"><strong aria-hidden="true">5.1.</strong> satellite 红帽注册和内容分发代理</a></li><li class="chapter-item expanded "><a href="../../notes/2023/rhel.subscription.register.html"><strong aria-hidden="true">5.2.</strong> RHEL 订阅在线注册相关问题</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.12.boot.to.install.html"><strong aria-hidden="true">5.3.</strong> 通过新增系统启动项来原地重装操作系统</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.04.os.backup.ReaR.html"><strong aria-hidden="true">5.4.</strong> Relax and Recover(ReaR) 系统备份和灾难恢复</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.04.no-cost.rhel.sub.html"><strong aria-hidden="true">5.5.</strong> 红帽免费的开发者订阅申请和使用</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.01.rpm.belongs.html"><strong aria-hidden="true">5.6.</strong> 在红帽官网查询rpm属于哪个repo</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.01.rhel7.upgrade.to.rhel8.html"><strong aria-hidden="true">5.7.</strong> 离线环境下 原地升级 rhel7-&gt;rhel8</a></li><li class="chapter-item expanded "><a href="../../notes/2022/2022.01.sysctl.html"><strong aria-hidden="true">5.8.</strong> 系统启动自动加载sysctl配置</a></li><li class="chapter-item expanded "><a href="../../notes/2021/2021.12.ocp.bf2.dpi.url.filter.html"><strong aria-hidden="true">5.9.</strong> Mellanox BF2 刷固件并测试DPI URL-filter场景</a></li><li class="chapter-item expanded "><a href="../../notes/2021/2021.11.bf2.snap.try.html"><strong aria-hidden="true">5.10.</strong> Mellanox BF2 网卡激活snap功能，配置nvme over fabrics 支持</a></li><li class="chapter-item expanded "><a href="../../notes/2021/2021.10.cx6dx.vdpa.offload.html"><strong aria-hidden="true">5.11.</strong> Mellanox CX6 vdpa 硬件卸载 ovs-kernel 方式</a></li><li class="chapter-item expanded "><a href="../../rhel/rhel.build.kernel.html"><strong aria-hidden="true">5.12.</strong> RHEL8编译定制化内核</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.check.whether.vm.html"><strong aria-hidden="true">5.13.</strong> 检查OS是否是运行在虚拟机上</a></li><li class="chapter-item expanded "><a href="../../ocp4/4.4/4.4.ovs.html"><strong aria-hidden="true">5.14.</strong> 两个主机用ovs组网</a></li></ol></li><li class="chapter-item expanded "><a href="../../workshop.html"><strong aria-hidden="true">6.</strong> 优秀的workshop</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.5/4.5.ocp.ocs.workshop.html"><strong aria-hidden="true">6.1.</strong> openshift4 &amp; openshift storage workshop</a></li></ol></li><li class="chapter-item expanded "><a href="../../poc.html"><strong aria-hidden="true">7.</strong> POC</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../ocp4/4.3/poc.sc/install.poc.sc.html"><strong aria-hidden="true">7.1.</strong> 2020.04 某次POC openshift LVM调优</a></li></ol></li><li class="chapter-item expanded "><a href="../../osx.html"><strong aria-hidden="true">8.</strong> OSX使用技巧</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../osx/osx.record.system.audio.html"><strong aria-hidden="true">8.1.</strong> 如何录制系统声音</a></li></ol></li></ol>            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                                                <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                                            </div>

                    <h1 class="menu-title">OpenShift4 慢慢走</h1>

                    <div class="right-buttons">
                                                <a href="../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                                                                        <a href="https://github.com/wangzheng422/docker_env" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                                                                        <a href="https://github.com/wangzheng422/docker_env/blob/dev/redhat/ocp4/4.7/4.7.real-time.kernel.md" title="Suggest an edit" aria-label="Suggest an edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>
                        
                    </div>
                </div>

                                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="real-time-kernel-for-openshift4"><a class="header" href="#real-time-kernel-for-openshift4">Real-Time Kernel for Openshift4</a></h1>
<p>5G RAN vDU 对操作系统的实时性要求很高， 基本都要求基于实时操作系统搞， openshift4 是一个和操作系统紧密捆绑的paas平台， 内置了实时操作系统， 这个操作系统是使用了 rhel8 的内核， 并使用 ostree 打包的操作系统。</p>
<p>openshift4 可以在node 上启动实时操作系统，有2个办法，一个是通过performance-addon operator</p>
<ul>
<li>https://docs.openshift.com/container-platform/4.7/scalability_and_performance/cnf-performance-addon-operator-for-low-latency-nodes.html</li>
</ul>
<p>另外一个，是直接用machine config的办法搞</p>
<ul>
<li>https://docs.openshift.com/container-platform/4.7/post_installation_configuration/machine-configuration-tasks.html#nodes-nodes-rtkernel-arguments_post-install-machine-configuration-tasks</li>
</ul>
<p>本次试验部署架构图</p>
<p><img src="dia/4.7.real-time.kernel.drawio.svg" alt="" /></p>
<p>视频讲解:</p>
<p><a href="https://www.bilibili.com/video/BV1av411V7dQ/"><kbd><img src="imgs/2021-06-07-16-31-23.png" width="600"></kbd></a></p>
<ul>
<li><a href="https://www.bilibili.com/video/BV1av411V7dQ/">bilibili</a></li>
<li><a href="https://youtu.be/Updyv2X1INY">youtube</a></li>
</ul>
<h1 id="操作系统上怎么做"><a class="header" href="#操作系统上怎么做">操作系统上怎么做</a></h1>
<p>用实时操作系统，就是为了性能，那么如果我们是一台物理机，不考虑容器平台，我们应该怎么配置，让这个实时操作系统性能最大化呢？</p>
<p>一般来说，有2个通用的配置</p>
<ul>
<li>对实时操作系统，并进行系统调优配置。</li>
<li>物理机bios进行配置，关闭超线程，关闭irq balance，关闭cpu c-state 等节电功能。</li>
</ul>
<p>对于第一个，实时操作系统的配置，参考这里</p>
<ul>
<li>install kernel-rt</li>
<li>install rt-test</li>
</ul>
<pre><code class="language-bash">cat /etc/tuned/realtime-variables.conf
# isolated_cores=1-30
# isolate_managed_irq=Y
tuned-adm profile realtime
reboot

swapoff -a
systemctl stop irqbalance
</code></pre>
<p>对于第二个，物理机上bios配置，要找服务器的厂商文档，查看官方的low latency配置文档。 <a href="https://www.dell.com/downloads/global/products/pedge/en/configuring_low_Latency_environments_on_dell_poweredge_servers.pdf">比如这里</a></p>
<table><thead><tr><th>System Setup Screen</th><th>Setting</th><th>Default</th><th>Recommended Alternative for Low- Latency Environments</th></tr></thead><tbody>
<tr><td>Processor Settings</td><td>Logical Processor</td><td>Enabled</td><td>Disabled</td></tr>
<tr><td>Processor Settings</td><td>Turbo Mode</td><td>Enabled</td><td>Disabled2</td></tr>
<tr><td>Processor Settings</td><td>C-States</td><td>Enabled</td><td>Disabled</td></tr>
<tr><td>Processor Settings</td><td>C1E</td><td>Enabled</td><td>Disabled</td></tr>
<tr><td>Power Management</td><td>Power Management</td><td>Active Power Controller</td><td>Maximum Performance</td></tr>
</tbody></table>
<h1 id="先使用performance-addon-operator这个是官方推荐的方法"><a class="header" href="#先使用performance-addon-operator这个是官方推荐的方法">先使用performance addon operator，这个是官方推荐的方法。</a></h1>
<p>performance addon operator 是openshift4里面的一个operator，他的作用是，让用户进行简单的yaml配置，然后operator帮助客户进行复杂的kernel parameter, kubelet, tuned配置。</p>
<pre><code class="language-bash"># on 104, create a new worker node
export KVM_DIRECTORY=/data/kvm

mkdir -p  ${KVM_DIRECTORY}
cd ${KVM_DIRECTORY}
scp root@172.21.6.11:/data/install/{*worker-0}.iso ${KVM_DIRECTORY}/

virt-install --name=ocp4-worker0 --vcpus=4 --ram=8192 \
--disk path=/data/kvm/ocp4-worker0.qcow2,bus=virtio,size=120 \
--os-variant rhel8.0 --network bridge=br0,model=virtio \
--graphics vnc,listen=127.0.0.1,port=59005 \
--boot menu=on --cdrom ${KVM_DIRECTORY}/rhcos_install-worker-0.iso 

# go back to helper
oc get csr
oc get csr -ojson | jq -r '.items[] | select(.status == {} ) | .metadata.name' | xargs oc adm certificate approve

# install performance addon operator following offical document
# https://docs.openshift.com/container-platform/4.7/scalability_and_performance/cnf-performance-addon-operator-for-low-latency-nodes.html

cat &lt;&lt; EOF &gt; /data/install/worker-rt.yaml
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfigPool
metadata:
  name: worker-rt
  labels:
    machineconfiguration.openshift.io/role: worker-rt
spec:
  machineConfigSelector:
    matchExpressions:
      - {key: machineconfiguration.openshift.io/role, operator: In, values: [worker,worker-rt]}
  nodeSelector:
    matchLabels:
      node-role.kubernetes.io/worker-rt: &quot;&quot;

EOF
oc create -f /data/install/worker-rt.yaml

oc label MachineConfigPool/worker-rt machineconfiguration.openshift.io/role=worker-rt

# to restore
oc delete -f /data/install/worker-rt.yaml

oc label node worker-0 node-role.kubernetes.io/worker-rt=&quot;&quot;

# 以下的配置，是保留了0-1核给系统，剩下的2-3核给应用，实际物理机上，一般是2-19给应用。
cat &lt;&lt; EOF &gt; /data/install/performance.yaml
apiVersion: performance.openshift.io/v2
kind: PerformanceProfile
metadata:
   name: example-performanceprofile
spec:
  additionalKernelArgs:
    - selinux=0
    - intel_iommu=on
  globallyDisableIrqLoadBalancing: true
  cpu:
      isolated: &quot;2-3&quot;
      reserved: &quot;0-1&quot;
  hugepages:
      defaultHugepagesSize: &quot;1G&quot;
      pages:
         - size: &quot;1G&quot;
           count: 2
           node: 0
  realTimeKernel:
      enabled: true
  numa:  
      topologyPolicy: &quot;single-numa-node&quot;
  nodeSelector:
      node-role.kubernetes.io/worker-rt: &quot;&quot;

EOF
oc create -f /data/install/performance.yaml

# restore
oc delete -f /data/install/performance.yaml

# check the result
ssh core@worker-0
uname -a
# Linux worker-0 4.18.0-240.22.1.rt7.77.el8_3.x86_64 #1 SMP PREEMPT_RT Fri Mar 26 18:44:48 EDT 2021 x86_64 x86_64 x86_64 GNU/Linux

</code></pre>
<h2 id="remove-worker-0"><a class="header" href="#remove-worker-0">remove worker-0</a></h2>
<pre><code class="language-bash">oc delete node worker-0

virsh destroy ocp4-worker0 

virsh undefine ocp4-worker0 

</code></pre>
<h1 id="try-with-machine-config-with-tunned-this-is-diy-if-you-like-"><a class="header" href="#try-with-machine-config-with-tunned-this-is-diy-if-you-like-">try with machine config with tunned, this is DIY if you like :)</a></h1>
<p>machine config的办法，特点是定制化程度很高，如果客户之前用rt-kernel的操作系统，调优过应用，那么用machine config的方法，能够直接把客户之前的调优参数于应用过来，就不用纠结各种调优的参数，在openshift4上面，应该怎么配置进去了。</p>
<p>you can use machine config dirctly, this can give you full customization capabilities. If you customer already fine-tune kernel parameter on rt-kernel, you can use their kernel parameter directly on openshift4 without try the parameters by yourself.</p>
<pre><code class="language-bash"># 打开节点的real time kernel
# cat &lt;&lt; EOF &gt; /data/install/99-worker-realtime.yaml
# apiVersion: machineconfiguration.openshift.io/v1
# kind: MachineConfig
# metadata:
#   labels:
#     machineconfiguration.openshift.io/role: &quot;worker-rt&quot;
#   name: 99-worker-realtime
# spec:
#   kernelType: realtime
# EOF
# oc create -f  /data/install/99-worker-realtime.yaml

# 配置kernel启动参数，每个参数一行
# http://abcdxyzk.github.io/blog/2015/02/11/kernel-base-param/
# no_timer_check clocksource=tsc tsc=perfect intel_pstate=disable selinux=0 enforcing=0 nmi_watchdog=0 softlockup_panic=0 isolcpus=2-19 nohz_full=2-19 idle=poll default_hugepagesz=1G hugepagesz=1G hugepages=32  skew_tick=1 rcu_nocbs=2-19 kthread_cpus=0-1 irqaffinity=0-1 rcu_nocb_poll iommu=pt intel_iommu=on
cat &lt;&lt; EOF &gt; /data/install/05-worker-kernelarg-realtime.yaml
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfig
metadata:
  labels:
    machineconfiguration.openshift.io/role: worker-rt
  name: 05-worker-kernelarg-realtime
spec:
  config:
    ignition:
      version: 3.1.0
  kernelArguments:
    - no_timer_check  # 禁止运行内核中时钟IRQ源缺陷检测代码。主要用于解决某些AMD平台的CPU占用过高以及时钟过快的故障。
    - clocksource=tsc # clocksource={jiffies|acpi_pm|hpet|tsc} tsc TSC(Time Stamp Counter)的主体是位于CPU里面的一个64位TSC寄存器，与传统的以中断形式存在的周期性时钟不同，TSC是以计数器形式存在的单步递增性时钟，两者的区别在于，周期性时钟是通过周期性触发中断达到计时目的，如心跳一般。而单步递增时钟则不发送中断，取而代之的是由软件自己在需要的时候去主动读取TSC寄存器的值来获得时间。TSC的精度更高并且速度更快，但仅能在较新的CPU(Sandy Bridge之后)上使用。
    - tsc=perfect
    - intel_pstate=disable  # intel_pstate驱动支持现代Intel处理器的温控。 intel_pstate=disable选项可以强制使用传统遗留的CPU驱动acpi_cpufreq
    - selinux=0
    - enforcing=0
    - nmi_watchdog=0  # 配置nmi_watchdog(不可屏蔽中断看门狗) 0 表示关闭看门狗；
    - softlockup_panic=0  # 是否在检测到软死锁(soft-lockup)的时候让内核panic
    - isolcpus=2-19 # 将列表中的CPU从内核SMP平衡和调度算法中剔除。 提出后并不是绝对不能再使用该CPU的，操作系统仍然可以强制指定特定的进程使用哪个CPU(可以通过taskset来做到)。该参数的目的主要是用于实现特定cpu只运行特定进程的目的。
    - nohz_full=2-19  #在 16 核的系统中，设定 nohz_full=1-15 可以在 1 到 15 内核中启用动态无时钟内核性能，并将所有的计时移动至唯一未设定的内核中（0 内核）, [注意](1)&quot;boot CPU&quot;(通常都是&quot;0&quot;号CPU)会无条件的从列表中剔除。(2)这里列出的CPU编号必须也要同时列进&quot;rcu_nocbs=...&quot;参数中。
    - idle=poll # 对CPU进入休眠状态的额外设置。poll 从根本上禁用休眠功能(也就是禁止进入C-states状态)，可以略微提升一些CPU性能，但是却需要多消耗许多电力，得不偿失。不推荐使用。
    - default_hugepagesz=1G
    - hugepagesz=1G
    - hugepages=32
    - skew_tick=1 # Offset the periodic timer tick per cpu to mitigate xtime_lock contention on larger systems, and/or RCU lock contention on all systems with CONFIG_MAXSMP set. Note: increases power consumption, thus should only be enabled if running jitter sensitive (HPC/RT) workloads.
    - rcu_nocbs=2-19  # 指定哪些CPU是No-CB CPU
    - kthread_cpus=0-1
    - irqaffinity=0-1 # 通过内核参数irqaffinity==[cpu列表],设置linux中断的亲和性，设置后，默认由这些cpu核来处理非CPU绑定中断。避免linux中断影响cpu2、cpu3上的实时应用，将linux中断指定到cpu0、cpu1处理。
    - rcu_nocb_poll # 减少了需要从卸载cpu执行唤醒操作。避免了rcuo kthreads线程显式的唤醒。另一方面这会增加耗电量
    - iommu=pt
    - intel_iommu=on
  kernelType: realtime
EOF
oc create -f /data/install/05-worker-kernelarg-realtime.yaml

# 一般都需要 cpu/numa 绑核，这个在 kubelet 的配置里面做
cat &lt;&lt; EOF &gt; /data/install/cpumanager-kubeletconfig.yaml
apiVersion: machineconfiguration.openshift.io/v1
kind: KubeletConfig
metadata:
  name: cpumanager-enabled
spec:
  machineConfigPoolSelector:
    matchLabels:
      custom-kubelet: cpumanager-enabled
  kubeletConfig:
     cpuManagerPolicy: static 
     cpuManagerReconcilePeriod: 5s 
     topologyManagerPolicy: single-numa-node 
     reservedSystemCPUs: &quot;0,1&quot; 
EOF
oc create -f  /data/install/cpumanager-kubeletconfig.yaml

# 以下如果在 bios 里面关掉了，就不用做了。
# if irqbalance disabled in bios, you can skip below step.
# cat &lt;&lt; EOF &gt; /data/install/99-custom-disable-irqbalance-worker.yaml
# apiVersion: machineconfiguration.openshift.io/v1
# kind: MachineConfig
# metadata:
#     labels:
#         machineconfiguration.openshift.io/role: worker-rt
#     name: 99-custom-disable-irqbalance-worker
# spec:
#     config:
#         ignition:
#             version: 2.2.0
#         systemd:
#             units:
#             - enabled: false
#               mask: true
#               name: irqbalance.service
# EOF
# oc create -f /data/install/99-custom-disable-irqbalance-worker.yaml


# 我们基于performace addon ， 改一下他的例子， 这次我们基于 realtime
cat &lt;&lt; EOF &gt; /data/install/tuned.yaml
apiVersion: tuned.openshift.io/v1
kind: Tuned
metadata:
  name: wzh-realtime
  namespace: openshift-cluster-node-tuning-operator
spec:
  profile:
  - data: |
      [main]
      summary=wzh version for realtime, 5G RAN
      include=openshift-node,realtime

      # Different values will override the original values in parent profiles.

      [variables]
      # isolated_cores take a list of ranges; e.g. isolated_cores=2,4-7

      isolated_cores=2-19
      isolate_managed_irq=Y

      [service]
      service.stalld=start,enable

    name: wzh-realtime
  recommend:
  - machineConfigLabels:
      machineconfiguration.openshift.io/role: worker-rt
    priority: 20
    profile: wzh-realtime
EOF
oc create -f /data/install/tuned.yaml

# to restore
oc delete -f  /data/install/tuned.yaml

# https://zhuanlan.zhihu.com/p/336381111
# yum install rt-test
# 在测试现场，经过整个晚上的测试，可以看到系统的实时性非常好
# 目标结果，最大不应超过 6μs
cyclictest -m -p95 -d0 -a 2-17 -t 16
</code></pre>
<p><img src="imgs/2021-05-25-10-18-23.png" alt="" /></p>
<h1 id="try-to-deploy-a-vdu-pod-using-yaml"><a class="header" href="#try-to-deploy-a-vdu-pod-using-yaml">try to deploy a vDU pod, using yaml</a></h1>
<pre><code class="language-yaml">---

apiVersion: &quot;k8s.cni.cncf.io/v1&quot;
kind: NetworkAttachmentDefinition
metadata:
  name: host-device-du
spec:
  config: '{
    &quot;cniVersion&quot;: &quot;0.3.0&quot;,
    &quot;type&quot;: &quot;host-device&quot;,
    &quot;device&quot;: &quot;ens81f1np1&quot;,
    &quot;ipam&quot;: {
      &quot;type&quot;: &quot;host-local&quot;,
      &quot;subnet&quot;: &quot;192.168.12.0/24&quot;,
      &quot;rangeStart&quot;: &quot;192.168.12.105&quot;,
      &quot;rangeEnd&quot;: &quot;192.168.12.105&quot;,
      &quot;routes&quot;: [{
        &quot;dst&quot;: &quot;0.0.0.0/0&quot;
      }],
      &quot;gateway&quot;: &quot;192.168.12.1&quot;
    }
  }'

---

apiVersion: apps/v1
kind: Deployment
metadata:
  name: du-deployment1
  labels:
    app: du-deployment1
spec:
  replicas: 1
  selector:
    matchLabels:
      app: du-pod1
  template:
    metadata:
      labels: 
        app: du-pod1
      annotations:
        k8s.v1.cni.cncf.io/networks: '[
          { &quot;name&quot;: &quot;host-device-du&quot;,
            &quot;interface&quot;: &quot;net1&quot; }
          ]'
    spec:
      containers:
      - name: du-container1
        image: &quot;registry.ocp4.redhat.ren:5443/ocp4/centos:7.6.1810&quot;
        imagePullPolicy: IfNotPresent
        tty: true
        stdin: true
        env:
          - name: duNetProviderDriver
            value: &quot;host-netdevice&quot;
        command:
          - sleep
          - infinity
        securityContext:
            privileged: true
            capabilities:
                add:
                - CAP_SYS_ADMIN
        volumeMounts:
          - mountPath: /hugepages
            name: hugepage
          - name: lib-modules
            mountPath: /lib/modules
          - name: src
            mountPath: /usr/src
          - name: dev
            mountPath: /dev
          - name: cache-volume
            mountPath: /dev/shm
        resources:
          requests:
            cpu: 16
            memory: 48Gi
            hugepages-1Gi: 8Gi
          limits:
            cpu: 16
            memory: 48Gi
            hugepages-1Gi: 8Gi
      volumes:
        - name: hugepage
          emptyDir:
            medium: HugePages
        - name: lib-modules
          hostPath:
            path: /lib/modules
        - name: src
          hostPath:
            path: /usr/src
        - name: dev
          hostPath:
            path: &quot;/dev&quot;
        - name: cache-volume
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi
      nodeSelector:
        node-role.kubernetes.io/worker-rt: &quot;&quot;
</code></pre>
<h2 id="research"><a class="header" href="#research">research</a></h2>
<pre><code class="language-bash">
oc get Tuned -n openshift-cluster-node-tuning-operator
# NAME                                                    AGE
# default                                                 18d
# openshift-node-performance-example-performanceprofile   12d
# rendered                                                18d

oc get Tuned/default -o yaml -n openshift-cluster-node-tuning-operator
</code></pre>
<pre><code class="language-yaml">apiVersion: tuned.openshift.io/v1
kind: Tuned
metadata:
  creationTimestamp: &quot;2021-05-05T16:09:36Z&quot;
  generation: 1
  name: default
  namespace: openshift-cluster-node-tuning-operator
  resourceVersion: &quot;6067&quot;
  selfLink: /apis/tuned.openshift.io/v1/namespaces/openshift-cluster-node-tuning-operator/tuneds/default
  uid: 205c01c5-2609-4f2f-b676-ad746ea3c9f3
spec:
  profile:
  - data: |
      [main]
      summary=Optimize systems running OpenShift (parent profile)
      include=${f:virt_check:virtual-guest:throughput-performance}

      [selinux]
      avc_cache_threshold=8192

      [net]
      nf_conntrack_hashsize=131072

      [sysctl]
      net.ipv4.ip_forward=1
      kernel.pid_max=&gt;4194304
      net.netfilter.nf_conntrack_max=1048576
      net.ipv4.conf.all.arp_announce=2
      net.ipv4.neigh.default.gc_thresh1=8192
      net.ipv4.neigh.default.gc_thresh2=32768
      net.ipv4.neigh.default.gc_thresh3=65536
      net.ipv6.neigh.default.gc_thresh1=8192
      net.ipv6.neigh.default.gc_thresh2=32768
      net.ipv6.neigh.default.gc_thresh3=65536
      vm.max_map_count=262144

      [sysfs]
      /sys/module/nvme_core/parameters/io_timeout=4294967295
      /sys/module/nvme_core/parameters/max_retries=10
    name: openshift
  - data: |
      [main]
      summary=Optimize systems running OpenShift control plane
      include=openshift

      [sysctl]
      # ktune sysctl settings, maximizing i/o throughput
      #
      # Minimal preemption granularity for CPU-bound tasks:
      # (default: 1 msec#  (1 + ilog(ncpus)), units: nanoseconds)
      kernel.sched_min_granularity_ns=10000000
      # The total time the scheduler will consider a migrated process
      # &quot;cache hot&quot; and thus less likely to be re-migrated
      # (system default is 500000, i.e. 0.5 ms)
      kernel.sched_migration_cost_ns=5000000
      # SCHED_OTHER wake-up granularity.
      #
      # Preemption granularity when tasks wake up.  Lower the value to
      # improve wake-up latency and throughput for latency critical tasks.
      kernel.sched_wakeup_granularity_ns=4000000
    name: openshift-control-plane
  - data: |
      [main]
      summary=Optimize systems running OpenShift nodes
      include=openshift

      [sysctl]
      net.ipv4.tcp_fastopen=3
      fs.inotify.max_user_watches=65536
      fs.inotify.max_user_instances=8192
    name: openshift-node
  recommend:
  - match:
    - label: node-role.kubernetes.io/master
    - label: node-role.kubernetes.io/infra
    operand:
      debug: false
    priority: 30
    profile: openshift-control-plane
  - operand:
      debug: false
    priority: 40
    profile: openshift-node
status: {}
</code></pre>
<pre><code class="language-bas">oc get Tuned/openshift-node-performance-example-performanceprofile -o yaml -n openshift-cluster-node-tuning-operator
</code></pre>
<pre><code class="language-yaml">apiVersion: tuned.openshift.io/v1
kind: Tuned
metadata:
  name: openshift-node-performance-example-performanceprofile
  namespace: openshift-cluster-node-tuning-operator
spec:
  profile:
  - data: &quot;[main]\nsummary=Openshift node optimized for deterministic performance at the cost of increased power consumption, focused on low latency network performance. Based on Tuned 2.11 and Cluster node tuning (oc 4.5)\ninclude=openshift-node,cpu-partitioning\n\n# Inheritance of base profiles legend:\n# cpu-partitioning -&gt; network-latency -&gt; latency-performance\n# https://github.com/redhat-performance/tuned/blob/master/profiles/latency-performance/tuned.conf\n# https://github.com/redhat-performance/tuned/blob/master/profiles/network-latency/tuned.conf\n# https://github.com/redhat-performance/tuned/blob/master/profiles/cpu-partitioning/tuned.conf\n\n# All values are mapped with a comment where a parent profile contains them.\n# Different values will override the original values in parent profiles.\n\n[variables]\n# isolated_cores take a list of ranges; e.g. isolated_cores=2,4-7\n\nisolated_cores=2-3 \n\n\nnot_isolated_cores_expanded=${f:cpulist_invert:${isolated_cores_expanded}}\n\n[cpu]\nforce_latency=cstate.id:1|3                   #  latency-performance  (override)\ngovernor=performance                          #  latency-performance \nenergy_perf_bias=performance                  #  latency-performance \nmin_perf_pct=100                              #  latency-performance \n\n[service]\nservice.stalld=start,enable\n\n[vm]\ntransparent_hugepages=never                   #  network-latency\n\n\n[irqbalance]\n# Override the value set by cpu-partitioning with an empty one\nbanned_cpus=\&quot;\&quot;\n\n\n[scheduler]\ngroup.ksoftirqd=0:f:11:*:ksoftirqd.*\ngroup.rcuc=0:f:11:*:rcuc.*\n\ndefault_irq_smp_affinity = ignore\n\n\n[sysctl]\nkernel.hung_task_timeout_secs = 600           # cpu-partitioning #realtime\nkernel.nmi_watchdog = 0                       # cpu-partitioning #realtime\nkernel.sched_rt_runtime_us = -1               # realtime \nkernel.timer_migration = 0                    # cpu-partitioning (= 1) #realtime (= 0)\nkernel.numa_balancing=0                       # network-latency\nnet.core.busy_read=50                         # network-latency\nnet.core.busy_poll=50                         # network-latency\nnet.ipv4.tcp_fastopen=3                       # network-latency\nvm.stat_interval = 10                         # cpu-partitioning  #realtime\n\n# ktune sysctl settings for rhel6 servers, maximizing i/o throughput\n#\n# Minimal preemption granularity for CPU-bound tasks:\n# (default: 1 msec#  (1 + ilog(ncpus)), units: nanoseconds)\nkernel.sched_min_granularity_ns=10000000      # latency-performance\n\n# If a workload mostly uses anonymous memory and it hits this limit, the entire\n# working set is buffered for I/O, and any more write buffering would require\n# swapping, so it's time to throttle writes until I/O can catch up.  Workloads\n# that mostly use file mappings may be able to use even higher values.\n#\n# The generator of dirty data starts writeback at this percentage (system default\n# is 20%)\nvm.dirty_ratio=10                             # latency-performance\n\n# Start background writeback (via writeback threads) at this percentage (system\n# default is 10%)\nvm.dirty_background_ratio=3                   # latency-performance\n\n# The swappiness parameter controls the tendency of the kernel to move\n# processes out of physical memory and onto the swap disk.\n# 0 tells the kernel to avoid swapping processes out of physical memory\n# for as long as possible\n# 100 tells the kernel to aggressively swap processes out of physical memory\n# and move them to swap cache\nvm.swappiness=10                              # latency-performance\n\n# The total time the scheduler will consider a migrated process\n# \&quot;cache hot\&quot; and thus less likely to be re-migrated\n# (system default is 500000, i.e. 0.5 ms)\nkernel.sched_migration_cost_ns=5000000        # latency-performance\n\n[selinux]\navc_cache_threshold=8192                      # Custom (atomic host)\n\n[net]\nnf_conntrack_hashsize=131072                  # Custom (atomic host)\n\n[bootloader]\n# set empty values to disable RHEL initrd setting in cpu-partitioning \ninitrd_remove_dir=     \ninitrd_dst_img=\ninitrd_add_dir=\n# overrides cpu-partitioning cmdline\ncmdline_cpu_part=+nohz=on rcu_nocbs=${isolated_cores} tuned.non_isolcpus=${not_isolated_cpumask} intel_pstate=disable nosoftlockup\n\ncmdline_realtime=+tsc=nowatchdog intel_iommu=on iommu=pt isolcpus=managed_irq,${isolated_cores} systemd.cpu_affinity=${not_isolated_cores_expanded}\n\ncmdline_hugepages=+ default_hugepagesz=1G  \ncmdline_additionalArg=+\n&quot;
    name: openshift-node-performance-example-performanceprofile
  recommend:
  - machineConfigLabels:
      machineconfiguration.openshift.io/role: worker-rt
    priority: 20
    profile: openshift-node-performance-example-performanceprofile
status: {}
</code></pre>
<pre><code class="language-yaml">apiVersion: tuned.openshift.io/v1
kind: Tuned
metadata:
  name: openshift-node-performance-example-performanceprofile
  namespace: openshift-cluster-node-tuning-operator
spec:
  profile:
  - data: |
      [main]
      summary=Openshift node optimized for deterministic performance at the cost of increased power consumption, focused on low latency network performance. Based on Tuned 2.11 and Cluster node tuning (oc 4.5)
      include=openshift-node,cpu-partitioning

      # Inheritance of base profiles legend:
      # cpu-partitioning -&gt; network-latency -&gt; latency-performance
      # https://github.com/redhat-performance/tuned/blob/master/profiles/latency-performance/tuned.conf
      # https://github.com/redhat-performance/tuned/blob/master/profiles/network-latency/tuned.conf
      # https://github.com/redhat-performance/tuned/blob/master/profiles/cpu-partitioning/tuned.conf

      # All values are mapped with a comment where a parent profile contains them.
      # Different values will override the original values in parent profiles.

      [variables]
      # isolated_cores take a list of ranges; e.g. isolated_cores=2,4-7

      isolated_cores=2-3


      not_isolated_cores_expanded=

      [cpu]
      force_latency=cstate.id:1|3                   #  latency-performance  (override)
      governor=performance                          #  latency-performance
      energy_perf_bias=performance                  #  latency-performance
      min_perf_pct=100                              #  latency-performance

      [service]
      service.stalld=start,enable

      [vm]
      transparent_hugepages=never                   #  network-latency


      [irqbalance]
      # Override the value set by cpu-partitioning with an empty one
      banned_cpus=&quot;&quot;


      [scheduler]
      group.ksoftirqd=0:f:11:*:ksoftirqd.*
      group.rcuc=0:f:11:*:rcuc.*

      default_irq_smp_affinity = ignore


      [sysctl]
      kernel.hung_task_timeout_secs = 600           # cpu-partitioning #realtime
      kernel.nmi_watchdog = 0                       # cpu-partitioning #realtime
      kernel.sched_rt_runtime_us = -1               # realtime
      kernel.timer_migration = 0                    # cpu-partitioning (= 1) #realtime (= 0)
      kernel.numa_balancing=0                       # network-latency
      net.core.busy_read=50                         # network-latency
      net.core.busy_poll=50                         # network-latency
      net.ipv4.tcp_fastopen=3                       # network-latency
      vm.stat_interval = 10                         # cpu-partitioning  #realtime

      # ktune sysctl settings for rhel6 servers, maximizing i/o throughput
      #
      # Minimal preemption granularity for CPU-bound tasks:
      # (default: 1 msec#  (1 + ilog(ncpus)), units: nanoseconds)
      kernel.sched_min_granularity_ns=10000000      # latency-performance

      # If a workload mostly uses anonymous memory and it hits this limit, the entire
      # working set is buffered for I/O, and any more write buffering would require
      # swapping, so it's time to throttle writes until I/O can catch up.  Workloads
      # that mostly use file mappings may be able to use even higher values.
      #
      # The generator of dirty data starts writeback at this percentage (system default
      # is 20%)
      vm.dirty_ratio=10                             # latency-performance

      # Start background writeback (via writeback threads) at this percentage (system
      # default is 10%)
      vm.dirty_background_ratio=3                   # latency-performance

      # The swappiness parameter controls the tendency of the kernel to move
      # processes out of physical memory and onto the swap disk.
      # 0 tells the kernel to avoid swapping processes out of physical memory
      # for as long as possible
      # 100 tells the kernel to aggressively swap processes out of physical memory
      # and move them to swap cache
      vm.swappiness=10                              # latency-performance

      # The total time the scheduler will consider a migrated process
      # &quot;cache hot&quot; and thus less likely to be re-migrated
      # (system default is 500000, i.e. 0.5 ms)
      kernel.sched_migration_cost_ns=5000000        # latency-performance

      [selinux]
      avc_cache_threshold=8192                      # Custom (atomic host)

      [net]
      nf_conntrack_hashsize=131072                  # Custom (atomic host)

      [bootloader]
      # set empty values to disable RHEL initrd setting in cpu-partitioning
      initrd_remove_dir=
      initrd_dst_img=
      initrd_add_dir=
      # overrides cpu-partitioning cmdline
      cmdline_cpu_part=+nohz=on rcu_nocbs= tuned.non_isolcpus= intel_pstate=disable nosoftlockup

      cmdline_realtime=+tsc=nowatchdog intel_iommu=on iommu=pt isolcpus=managed_irq, systemd.cpu_affinity=

      cmdline_hugepages=+ default_hugepagesz=1G
      cmdline_additionalArg=+
    name: openshift-node-performance-example-performanceprofile
  recommend:
  - machineConfigLabels:
      machineconfiguration.openshift.io/role: worker-rt
    priority: 20
    profile: openshift-node-performance-example-performanceprofile
</code></pre>
<pre><code class="language-bash"># tuned 的配置，如果有些在bios里面做了，那么也可以忽略。我们基于performace addon ， 改一下他的例子.
cat &lt;&lt; EOF &gt; /data/install/tuned.yaml
apiVersion: tuned.openshift.io/v1
kind: Tuned
metadata:
  name: openshift-node-wzh-performance-profile
  namespace: openshift-cluster-node-tuning-operator
spec:
  profile:
  - data: |
      [main]
      summary=Openshift node optimized for deterministic performance at the cost of increased power consumption, focused on low latency network performance. Based on Tuned 2.11 and Cluster node tuning (oc 4.5)
      include=openshift-node,cpu-partitioning

      # Inheritance of base profiles legend:
      # cpu-partitioning -&gt; network-latency -&gt; latency-performance
      # https://github.com/redhat-performance/tuned/blob/master/profiles/latency-performance/tuned.conf
      # https://github.com/redhat-performance/tuned/blob/master/profiles/network-latency/tuned.conf
      # https://github.com/redhat-performance/tuned/blob/master/profiles/cpu-partitioning/tuned.conf

      # All values are mapped with a comment where a parent profile contains them.
      # Different values will override the original values in parent profiles.

      [variables]
      # isolated_cores take a list of ranges; e.g. isolated_cores=2,4-7

      isolated_cores=2-19
      isolate_managed_irq=Y

      not_isolated_cores_expanded=

      [cpu]
      # force_latency=cstate.id:1|3                   #  latency-performance  (override)
      governor=performance                          #  latency-performance
      energy_perf_bias=performance                  #  latency-performance
      min_perf_pct=100                              #  latency-performance

      [service]
      service.stalld=start,enable

      [vm]
      transparent_hugepages=never                   #  network-latency


      [irqbalance]
      # Override the value set by cpu-partitioning with an empty one
      banned_cpus=&quot;&quot;


      [scheduler]
      group.ksoftirqd=0:f:11:*:ksoftirqd.*
      group.rcuc=0:f:11:*:rcuc.*

      default_irq_smp_affinity = ignore


      [sysctl]
      kernel.hung_task_timeout_secs = 600           # cpu-partitioning #realtime
      kernel.nmi_watchdog = 0                       # cpu-partitioning #realtime
      kernel.sched_rt_runtime_us = -1               # realtime
      kernel.timer_migration = 0                    # cpu-partitioning (= 1) #realtime (= 0)
      kernel.numa_balancing=0                       # network-latency
      net.core.busy_read=50                         # network-latency
      net.core.busy_poll=50                         # network-latency
      net.ipv4.tcp_fastopen=3                       # network-latency
      vm.stat_interval = 10                         # cpu-partitioning  #realtime

      # ktune sysctl settings for rhel6 servers, maximizing i/o throughput
      #
      # Minimal preemption granularity for CPU-bound tasks:
      # (default: 1 msec#  (1 + ilog(ncpus)), units: nanoseconds)
      kernel.sched_min_granularity_ns=10000000      # latency-performance

      # If a workload mostly uses anonymous memory and it hits this limit, the entire
      # working set is buffered for I/O, and any more write buffering would require
      # swapping, so it's time to throttle writes until I/O can catch up.  Workloads
      # that mostly use file mappings may be able to use even higher values.
      #
      # The generator of dirty data starts writeback at this percentage (system default
      # is 20%)
      vm.dirty_ratio=10                             # latency-performance

      # Start background writeback (via writeback threads) at this percentage (system
      # default is 10%)
      vm.dirty_background_ratio=3                   # latency-performance

      # The swappiness parameter controls the tendency of the kernel to move
      # processes out of physical memory and onto the swap disk.
      # 0 tells the kernel to avoid swapping processes out of physical memory
      # for as long as possible
      # 100 tells the kernel to aggressively swap processes out of physical memory
      # and move them to swap cache
      vm.swappiness=10                              # latency-performance

      # The total time the scheduler will consider a migrated process
      # &quot;cache hot&quot; and thus less likely to be re-migrated
      # (system default is 500000, i.e. 0.5 ms)
      kernel.sched_migration_cost_ns=5000000        # latency-performance

      [selinux]
      avc_cache_threshold=8192                      # Custom (atomic host)

      [net]
      nf_conntrack_hashsize=131072                  # Custom (atomic host)

      [bootloader]
      # set empty values to disable RHEL initrd setting in cpu-partitioning
      initrd_remove_dir=
      initrd_dst_img=
      initrd_add_dir=
      # overrides cpu-partitioning cmdline
      cmdline_cpu_part=+nohz=on rcu_nocbs= tuned.non_isolcpus= intel_pstate=disable nosoftlockup

      cmdline_realtime=+tsc=nowatchdog intel_iommu=on iommu=pt isolcpus=managed_irq, systemd.cpu_affinity=

      cmdline_hugepages=+ default_hugepagesz=1G
      cmdline_additionalArg=+
    name: openshift-node-wzh-performance-profile
  recommend:
  - machineConfigLabels:
      machineconfiguration.openshift.io/role: worker-rt
    priority: 20
    profile: openshift-node-wzh-performance-profile
EOF
oc create -f /data/install/tuned.yaml

# 用了performance example的profile 效果很好
cyclictest -m -p95 -d0 -a 2-17 -t 16
</code></pre>
<p><img src="imgs/2021-05-26-21-01-57.png" alt="" /></p>
<h1 id="example-config"><a class="header" href="#example-config">example config</a></h1>
<pre><code class="language-bash">oc get mc
</code></pre>
<pre><code>NAME                                                  GENERATEDBYCONTROLLER                      IGNITIONVERSION   AGE
00-master                                             791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             62d
00-worker                                             791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             62d
01-master-container-runtime                           791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             62d
01-master-kubelet                                     791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             62d
01-worker-container-runtime                           791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             62d
01-worker-kubelet                                     791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             62d
05-worker-kernelarg-rtran                                                                        3.1.0             62d
50-nto-worker-rt                                                                                 3.1.0             58d
99-master-generated-registries                        791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             62d
99-master-ssh                                                                                    3.1.0             62d
99-worker-generated-registries                        791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             62d
99-worker-realtime                                                                                                 62d
99-worker-rt-generated-kubelet                        791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             58d
99-worker-ssh                                                                                    3.1.0             62d
load-sctp-module                                                                                 3.1.0             6d9h
rendered-master-0629f16bcba29a60e894f3d9e14e47b9      791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             62d
rendered-worker-7497d1b2e86631a4f390a6eba0aef74f      791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             62d
rendered-worker-rt-1e40da418635be6c6b81ebc33a1f0640   791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             62d
rendered-worker-rt-35d27df9ed0ff75a6a192700313a88f8   791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             58d
rendered-worker-rt-3e87a41fe1e455977a4a972f8d4258aa   791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             58d
rendered-worker-rt-4ba64193fdbace8fc101541335067ad4   791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             62d
rendered-worker-rt-7497d1b2e86631a4f390a6eba0aef74f   791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             62d
rendered-worker-rt-9cf8ebbc1c0cf88bb3a9716b6d66e60e   791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             58d
rendered-worker-rt-bb3c16a689e7797fb4c828cec877c9ed   791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             58d
rendered-worker-rt-ea53e6c4fc58b5f9f505ebed3cb32345   791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             58d
rendered-worker-rt-fd13902df04099f149d7653da3552f5d   791d1cc2626d1e4e5da59f15c1a6166fd398aef8   3.1.0             6d9h
</code></pre>
<pre><code class="language-bash">oc get mc/05-worker-kernelarg-rtran -o json | jq &quot;del(.metadata.managedFields, .metadata.uid, .metadata.selfLink, .metadata.resourceVersion, .metadata.generation, .metadata.creationTimestamp)&quot;
</code></pre>
<pre><code class="language-json">{
  &quot;apiVersion&quot;: &quot;machineconfiguration.openshift.io/v1&quot;,
  &quot;kind&quot;: &quot;MachineConfig&quot;,
  &quot;metadata&quot;: {
    &quot;labels&quot;: {
      &quot;machineconfiguration.openshift.io/role&quot;: &quot;worker-rt&quot;
    },
    &quot;name&quot;: &quot;05-worker-kernelarg-rtran&quot;
  },
  &quot;spec&quot;: {
    &quot;config&quot;: {
      &quot;ignition&quot;: {
        &quot;version&quot;: &quot;3.1.0&quot;
      }
    },
    &quot;kernelArguments&quot;: [
      &quot;no_timer_check&quot;,
      &quot;clocksource=tsc&quot;,
      &quot;tsc=perfect&quot;,
      &quot;selinux=0&quot;,
      &quot;enforcing=0&quot;,
      &quot;nmi_watchdog=0&quot;,
      &quot;softlockup_panic=0&quot;,
      &quot;isolcpus=2-19&quot;,
      &quot;nohz_full=2-19&quot;,
      &quot;idle=poll&quot;,
      &quot;default_hugepagesz=1G&quot;,
      &quot;hugepagesz=1G&quot;,
      &quot;hugepages=16&quot;,
      &quot;skew_tick=1&quot;,
      &quot;rcu_nocbs=2-19&quot;,
      &quot;kthread_cpus=0-1&quot;,
      &quot;irqaffinity=0-1&quot;,
      &quot;rcu_nocb_poll&quot;,
      &quot;iommu=pt&quot;,
      &quot;intel_iommu=on&quot;
    ]
  }
}
</code></pre>
<pre><code class="language-bash">oc get mc/50-nto-worker-rt -o json | jq &quot;del(.metadata.managedFields, .metadata.uid, .metadata.selfLink, .metadata.resourceVersion, .metadata.generation, .metadata.creationTimestamp)&quot;
</code></pre>
<pre><code class="language-json">{
  &quot;apiVersion&quot;: &quot;machineconfiguration.openshift.io/v1&quot;,
  &quot;kind&quot;: &quot;MachineConfig&quot;,
  &quot;metadata&quot;: {
    &quot;annotations&quot;: {
      &quot;tuned.openshift.io/generated-by-controller-version&quot;: &quot;v4.6.0-202104221811.p0-0-gfdb7aec-dirty&quot;
    },
    &quot;labels&quot;: {
      &quot;machineconfiguration.openshift.io/role&quot;: &quot;worker-rt&quot;
    },
    &quot;name&quot;: &quot;50-nto-worker-rt&quot;
  },
  &quot;spec&quot;: {
    &quot;config&quot;: {
      &quot;ignition&quot;: {
        &quot;config&quot;: {
          &quot;replace&quot;: {
            &quot;verification&quot;: {}
          }
        },
        &quot;proxy&quot;: {},
        &quot;security&quot;: {
          &quot;tls&quot;: {}
        },
        &quot;timeouts&quot;: {},
        &quot;version&quot;: &quot;3.1.0&quot;
      },
      &quot;passwd&quot;: {},
      &quot;storage&quot;: {},
      &quot;systemd&quot;: {}
    },
    &quot;extensions&quot;: null,
    &quot;fips&quot;: false,
    &quot;kernelArguments&quot;: [
      &quot;skew_tick=1&quot;,
      &quot;isolcpus=managed_irq,domain,2-19&quot;,
      &quot;intel_pstate=disable&quot;,
      &quot;nosoftlockup&quot;,
      &quot;tsc=nowatchdog&quot;
    ],
    &quot;kernelType&quot;: &quot;&quot;,
    &quot;osImageURL&quot;: &quot;&quot;
  }
}
</code></pre>
<pre><code class="language-bash">oc get mc/99-worker-realtime -o json | jq &quot;del(.metadata.managedFields, .metadata.uid, .metadata.selfLink, .metadata.resourceVersion, .metadata.generation, .metadata.creationTimestamp)&quot;
</code></pre>
<pre><code class="language-json">{
  &quot;apiVersion&quot;: &quot;machineconfiguration.openshift.io/v1&quot;,
  &quot;kind&quot;: &quot;MachineConfig&quot;,
  &quot;metadata&quot;: {
    &quot;labels&quot;: {
      &quot;machineconfiguration.openshift.io/role&quot;: &quot;worker-rt&quot;
    },
    &quot;name&quot;: &quot;99-worker-realtime&quot;
  },
  &quot;spec&quot;: {
    &quot;kernelType&quot;: &quot;realtime&quot;
  }
}
</code></pre>
<pre><code class="language-bash">oc get mc/load-sctp-module -o json | jq &quot;del(.metadata.managedFields, .metadata.uid, .metadata.selfLink, .metadata.resourceVersion, .metadata.generation, .metadata.creationTimestamp)&quot;
</code></pre>
<pre><code class="language-json">{
  &quot;apiVersion&quot;: &quot;machineconfiguration.openshift.io/v1&quot;,
  &quot;kind&quot;: &quot;MachineConfig&quot;,
  &quot;metadata&quot;: {
    &quot;labels&quot;: {
      &quot;machineconfiguration.openshift.io/role&quot;: &quot;worker-rt&quot;
    },
    &quot;name&quot;: &quot;load-sctp-module&quot;
  },
  &quot;spec&quot;: {
    &quot;config&quot;: {
      &quot;ignition&quot;: {
        &quot;version&quot;: &quot;3.1.0&quot;
      },
      &quot;storage&quot;: {
        &quot;files&quot;: [
          {
            &quot;contents&quot;: {
              &quot;source&quot;: &quot;data:,&quot;
            },
            &quot;mode&quot;: 420,
            &quot;overwrite&quot;: true,
            &quot;path&quot;: &quot;/etc/modprobe.d/sctp-blacklist.conf&quot;
          },
          {
            &quot;contents&quot;: {
              &quot;source&quot;: &quot;data:,sctp&quot;
            },
            &quot;mode&quot;: 420,
            &quot;overwrite&quot;: true,
            &quot;path&quot;: &quot;/etc/modules-load.d/sctp-load.conf&quot;
          }
        ]
      }
    }
  }
}

</code></pre>
<pre><code class="language-bash">oc get Tuned -n openshift-cluster-node-tuning-operator
NAME           AGE
default        62d
rendered       62d
wzh-realtime   58d

oc get Tuned/wzh-realtime -n openshift-cluster-node-tuning-operator -o json | jq &quot;del(.metadata.managedFields, .metadata.uid, .metadata.selfLink, .metadata.resourceVersion, .metadata.generation, .metadata.creationTimestamp)&quot; 
</code></pre>
<pre><code class="language-json">{
  &quot;apiVersion&quot;: &quot;tuned.openshift.io/v1&quot;,
  &quot;kind&quot;: &quot;Tuned&quot;,
  &quot;metadata&quot;: {
    &quot;name&quot;: &quot;wzh-realtime&quot;,
    &quot;namespace&quot;: &quot;openshift-cluster-node-tuning-operator&quot;
  },
  &quot;spec&quot;: {
    &quot;profile&quot;: [
      {
        &quot;data&quot;: &quot;[main]\nsummary=wzh version for realtime, 5G RAN\ninclude=openshift-node,realtime\n\n# Inheritance of base profiles legend:\n# cpu-partitioning -&gt; network-latency -&gt; latency-performance\n# https://github.com/redhat-performance/tuned/blob/master/profiles/latency-performance/tuned.conf\n# https://github.com/redhat-performance/tuned/blob/master/profiles/network-latency/tuned.conf\n# https://github.com/redhat-performance/tuned/blob/master/profiles/cpu-partitioning/tuned.conf\n\n# All values are mapped with a comment where a parent profile contains them.\n# Different values will override the original values in parent profiles.\n\n[variables]\n# isolated_cores take a list of ranges; e.g. isolated_cores=2,4-7\n\nisolated_cores=2-19\nisolate_managed_irq=Y\n&quot;,
        &quot;name&quot;: &quot;wzh-realtime&quot;
      }
    ],
    &quot;recommend&quot;: [
      {
        &quot;machineConfigLabels&quot;: {
          &quot;machineconfiguration.openshift.io/role&quot;: &quot;worker-rt&quot;
        },
        &quot;priority&quot;: 20,
        &quot;profile&quot;: &quot;wzh-realtime&quot;
      }
    ]
  }
}
</code></pre>
<pre><code class="language-bash">oc get Tuned/wzh-realtime -n openshift-cluster-node-tuning-operator -o json | jq &quot;.spec.profile[0].data&quot; | jq -r
</code></pre>
<pre><code>[main]
summary=wzh version for realtime, 5G RAN
include=openshift-node,realtime

# Inheritance of base profiles legend:
# cpu-partitioning -&gt; network-latency -&gt; latency-performance
# https://github.com/redhat-performance/tuned/blob/master/profiles/latency-performance/tuned.conf
# https://github.com/redhat-performance/tuned/blob/master/profiles/network-latency/tuned.conf
# https://github.com/redhat-performance/tuned/blob/master/profiles/cpu-partitioning/tuned.conf

# All values are mapped with a comment where a parent profile contains them.
# Different values will override the original values in parent profiles.

[variables]
# isolated_cores take a list of ranges; e.g. isolated_cores=2,4-7

isolated_cores=2-19
isolate_managed_irq=Y
</code></pre>
<pre><code class="language-bash">oc get deployment.apps/du-deployment1 -o json | jq &quot;del(.metadata.managedFields, .metadata.uid, .metadata.selfLink, .metadata.resourceVersion, .metadata.generation, .metadata.creationTimestamp)&quot;
</code></pre>
<pre><code class="language-json">{
  &quot;apiVersion&quot;: &quot;apps/v1&quot;,
  &quot;kind&quot;: &quot;Deployment&quot;,
  &quot;metadata&quot;: {
    &quot;annotations&quot;: {
      &quot;deployment.kubernetes.io/revision&quot;: &quot;1&quot;,
      &quot;kubectl.kubernetes.io/last-applied-configuration&quot;: &quot;{\&quot;apiVersion\&quot;:\&quot;apps/v1\&quot;,\&quot;kind\&quot;:\&quot;Deployment\&quot;,\&quot;metadata\&quot;:{\&quot;annotations\&quot;:{},\&quot;labels\&quot;:{\&quot;app\&quot;:\&quot;du-deployment1\&quot;},\&quot;name\&quot;:\&quot;du-deployment1\&quot;,\&quot;namespace\&quot;:\&quot;default\&quot;},\&quot;spec\&quot;:{\&quot;replicas\&quot;:1,\&quot;selector\&quot;:{\&quot;matchLabels\&quot;:{\&quot;app\&quot;:\&quot;du-pod1\&quot;}},\&quot;template\&quot;:{\&quot;metadata\&quot;:{\&quot;annotations\&quot;:{\&quot;k8s.v1.cni.cncf.io/networks\&quot;:\&quot;[ { \\\&quot;name\\\&quot;: \\\&quot;host-device-du\\\&quot;, \\\&quot;interface\\\&quot;: \\\&quot;veth11\\\&quot; } ]\&quot;},\&quot;labels\&quot;:{\&quot;app\&quot;:\&quot;du-pod1\&quot;}},\&quot;spec\&quot;:{\&quot;containers\&quot;:[{\&quot;command\&quot;:[\&quot;sleep\&quot;,\&quot;infinity\&quot;],\&quot;env\&quot;:[{\&quot;name\&quot;:\&quot;duNetProviderDriver\&quot;,\&quot;value\&quot;:\&quot;host-netdevice\&quot;}],\&quot;image\&quot;:\&quot;registry.ocp4.redhat.ren:5443/ocp4/du:v1-wzh\&quot;,\&quot;imagePullPolicy\&quot;:\&quot;IfNotPresent\&quot;,\&quot;name\&quot;:\&quot;du-container1\&quot;,\&quot;resources\&quot;:{\&quot;limits\&quot;:{\&quot;cpu\&quot;:16,\&quot;hugepages-1Gi\&quot;:\&quot;8Gi\&quot;,\&quot;memory\&quot;:\&quot;48Gi\&quot;},\&quot;requests\&quot;:{\&quot;cpu\&quot;:16,\&quot;hugepages-1Gi\&quot;:\&quot;8Gi\&quot;,\&quot;memory\&quot;:\&quot;48Gi\&quot;}},\&quot;securityContext\&quot;:{\&quot;capabilities\&quot;:{\&quot;add\&quot;:[\&quot;CAP_SYS_ADMIN\&quot;]},\&quot;privileged\&quot;:true},\&quot;stdin\&quot;:true,\&quot;tty\&quot;:true,\&quot;volumeMounts\&quot;:[{\&quot;mountPath\&quot;:\&quot;/hugepages\&quot;,\&quot;name\&quot;:\&quot;hugepage\&quot;},{\&quot;mountPath\&quot;:\&quot;/lib/modules\&quot;,\&quot;name\&quot;:\&quot;lib-modules\&quot;},{\&quot;mountPath\&quot;:\&quot;/usr/src\&quot;,\&quot;name\&quot;:\&quot;src\&quot;},{\&quot;mountPath\&quot;:\&quot;/dev\&quot;,\&quot;name\&quot;:\&quot;dev\&quot;},{\&quot;mountPath\&quot;:\&quot;/dev/shm\&quot;,\&quot;name\&quot;:\&quot;cache-volume\&quot;}]}],\&quot;nodeSelector\&quot;:{\&quot;node-role.kubernetes.io/worker-rt\&quot;:\&quot;\&quot;},\&quot;volumes\&quot;:[{\&quot;emptyDir\&quot;:{\&quot;medium\&quot;:\&quot;HugePages\&quot;},\&quot;name\&quot;:\&quot;hugepage\&quot;},{\&quot;hostPath\&quot;:{\&quot;path\&quot;:\&quot;/lib/modules\&quot;},\&quot;name\&quot;:\&quot;lib-modules\&quot;},{\&quot;hostPath\&quot;:{\&quot;path\&quot;:\&quot;/usr/src\&quot;},\&quot;name\&quot;:\&quot;src\&quot;},{\&quot;hostPath\&quot;:{\&quot;path\&quot;:\&quot;/dev\&quot;},\&quot;name\&quot;:\&quot;dev\&quot;},{\&quot;emptyDir\&quot;:{\&quot;medium\&quot;:\&quot;Memory\&quot;,\&quot;sizeLimit\&quot;:\&quot;16Gi\&quot;},\&quot;name\&quot;:\&quot;cache-volume\&quot;}]}}}}\n&quot;
    },
    &quot;labels&quot;: {
      &quot;app&quot;: &quot;du-deployment1&quot;
    },
    &quot;name&quot;: &quot;du-deployment1&quot;,
    &quot;namespace&quot;: &quot;default&quot;
  },
  &quot;spec&quot;: {
    &quot;progressDeadlineSeconds&quot;: 600,
    &quot;replicas&quot;: 1,
    &quot;revisionHistoryLimit&quot;: 10,
    &quot;selector&quot;: {
      &quot;matchLabels&quot;: {
        &quot;app&quot;: &quot;du-pod1&quot;
      }
    },
    &quot;strategy&quot;: {
      &quot;rollingUpdate&quot;: {
        &quot;maxSurge&quot;: &quot;25%&quot;,
        &quot;maxUnavailable&quot;: &quot;25%&quot;
      },
      &quot;type&quot;: &quot;RollingUpdate&quot;
    },
    &quot;template&quot;: {
      &quot;metadata&quot;: {
        &quot;annotations&quot;: {
          &quot;k8s.v1.cni.cncf.io/networks&quot;: &quot;[ { \&quot;name\&quot;: \&quot;host-device-du\&quot;, \&quot;interface\&quot;: \&quot;veth11\&quot; } ]&quot;
        },
        &quot;creationTimestamp&quot;: null,
        &quot;labels&quot;: {
          &quot;app&quot;: &quot;du-pod1&quot;
        }
      },
      &quot;spec&quot;: {
        &quot;containers&quot;: [
          {
            &quot;command&quot;: [
              &quot;sleep&quot;,
              &quot;infinity&quot;
            ],
            &quot;env&quot;: [
              {
                &quot;name&quot;: &quot;duNetProviderDriver&quot;,
                &quot;value&quot;: &quot;host-netdevice&quot;
              }
            ],
            &quot;image&quot;: &quot;registry.ocp4.redhat.ren:5443/ocp4/du:v1-wzh&quot;,
            &quot;imagePullPolicy&quot;: &quot;IfNotPresent&quot;,
            &quot;name&quot;: &quot;du-container1&quot;,
            &quot;resources&quot;: {
              &quot;limits&quot;: {
                &quot;cpu&quot;: &quot;16&quot;,
                &quot;hugepages-1Gi&quot;: &quot;8Gi&quot;,
                &quot;memory&quot;: &quot;48Gi&quot;
              },
              &quot;requests&quot;: {
                &quot;cpu&quot;: &quot;16&quot;,
                &quot;hugepages-1Gi&quot;: &quot;8Gi&quot;,
                &quot;memory&quot;: &quot;48Gi&quot;
              }
            },
            &quot;securityContext&quot;: {
              &quot;capabilities&quot;: {
                &quot;add&quot;: [
                  &quot;CAP_SYS_ADMIN&quot;
                ]
              },
              &quot;privileged&quot;: true
            },
            &quot;stdin&quot;: true,
            &quot;terminationMessagePath&quot;: &quot;/dev/termination-log&quot;,
            &quot;terminationMessagePolicy&quot;: &quot;File&quot;,
            &quot;tty&quot;: true,
            &quot;volumeMounts&quot;: [
              {
                &quot;mountPath&quot;: &quot;/hugepages&quot;,
                &quot;name&quot;: &quot;hugepage&quot;
              },
              {
                &quot;mountPath&quot;: &quot;/lib/modules&quot;,
                &quot;name&quot;: &quot;lib-modules&quot;
              },
              {
                &quot;mountPath&quot;: &quot;/usr/src&quot;,
                &quot;name&quot;: &quot;src&quot;
              },
              {
                &quot;mountPath&quot;: &quot;/dev&quot;,
                &quot;name&quot;: &quot;dev&quot;
              },
              {
                &quot;mountPath&quot;: &quot;/dev/shm&quot;,
                &quot;name&quot;: &quot;cache-volume&quot;
              }
            ]
          }
        ],
        &quot;dnsPolicy&quot;: &quot;ClusterFirst&quot;,
        &quot;nodeSelector&quot;: {
          &quot;node-role.kubernetes.io/worker-rt&quot;: &quot;&quot;
        },
        &quot;restartPolicy&quot;: &quot;Always&quot;,
        &quot;schedulerName&quot;: &quot;default-scheduler&quot;,
        &quot;securityContext&quot;: {},
        &quot;terminationGracePeriodSeconds&quot;: 30,
        &quot;volumes&quot;: [
          {
            &quot;emptyDir&quot;: {
              &quot;medium&quot;: &quot;HugePages&quot;
            },
            &quot;name&quot;: &quot;hugepage&quot;
          },
          {
            &quot;hostPath&quot;: {
              &quot;path&quot;: &quot;/lib/modules&quot;,
              &quot;type&quot;: &quot;&quot;
            },
            &quot;name&quot;: &quot;lib-modules&quot;
          },
          {
            &quot;hostPath&quot;: {
              &quot;path&quot;: &quot;/usr/src&quot;,
              &quot;type&quot;: &quot;&quot;
            },
            &quot;name&quot;: &quot;src&quot;
          },
          {
            &quot;hostPath&quot;: {
              &quot;path&quot;: &quot;/dev&quot;,
              &quot;type&quot;: &quot;&quot;
            },
            &quot;name&quot;: &quot;dev&quot;
          },
          {
            &quot;emptyDir&quot;: {
              &quot;medium&quot;: &quot;Memory&quot;,
              &quot;sizeLimit&quot;: &quot;16Gi&quot;
            },
            &quot;name&quot;: &quot;cache-volume&quot;
          }
        ]
      }
    }
  },
  &quot;status&quot;: {
    &quot;availableReplicas&quot;: 1,
    &quot;conditions&quot;: [
      {
        &quot;lastTransitionTime&quot;: &quot;2021-07-21T06:21:57Z&quot;,
        &quot;lastUpdateTime&quot;: &quot;2021-07-21T06:23:05Z&quot;,
        &quot;message&quot;: &quot;ReplicaSet \&quot;du-deployment1-d5dc9854d\&quot; has successfully progressed.&quot;,
        &quot;reason&quot;: &quot;NewReplicaSetAvailable&quot;,
        &quot;status&quot;: &quot;True&quot;,
        &quot;type&quot;: &quot;Progressing&quot;
      },
      {
        &quot;lastTransitionTime&quot;: &quot;2021-07-21T11:07:55Z&quot;,
        &quot;lastUpdateTime&quot;: &quot;2021-07-21T11:07:55Z&quot;,
        &quot;message&quot;: &quot;Deployment has minimum availability.&quot;,
        &quot;reason&quot;: &quot;MinimumReplicasAvailable&quot;,
        &quot;status&quot;: &quot;True&quot;,
        &quot;type&quot;: &quot;Available&quot;
      }
    ],
    &quot;observedGeneration&quot;: 7,
    &quot;readyReplicas&quot;: 1,
    &quot;replicas&quot;: 1,
    &quot;updatedReplicas&quot;: 1
  }
}

</code></pre>
<pre><code class="language-bash">oc get net-attach-def
# NAME             AGE
# host-device-du   6h32m
# macvlan-conf     23d

oc get net-attach-def/host-device-du -o json | jq &quot;del(.metadata.managedFields, .metadata.uid, .metadata.selfLink, .metadata.resourceVersion, .metadata.generation, .metadata.creationTimestamp)&quot;
</code></pre>
<pre><code class="language-json">{
  &quot;apiVersion&quot;: &quot;k8s.cni.cncf.io/v1&quot;,
  &quot;kind&quot;: &quot;NetworkAttachmentDefinition&quot;,
  &quot;metadata&quot;: {
    &quot;annotations&quot;: {
      &quot;kubectl.kubernetes.io/last-applied-configuration&quot;: &quot;{\&quot;apiVersion\&quot;:\&quot;k8s.cni.cncf.io/v1\&quot;,\&quot;kind\&quot;:\&quot;NetworkAttachmentDefinition\&quot;,\&quot;metadata\&quot;:{\&quot;annotations\&quot;:{},\&quot;name\&quot;:\&quot;host-device-du\&quot;,\&quot;namespace\&quot;:\&quot;default\&quot;},\&quot;spec\&quot;:{\&quot;config\&quot;:\&quot;{ \\\&quot;cniVersion\\\&quot;: \\\&quot;0.3.0\\\&quot;, \\\&quot;type\\\&quot;: \\\&quot;host-device\\\&quot;, \\\&quot;device\\\&quot;: \\\&quot;ens81f1np1\\\&quot;, \\\&quot;ipam\\\&quot;: { \\\&quot;type\\\&quot;: \\\&quot;host-local\\\&quot;, \\\&quot;subnet\\\&quot;: \\\&quot;192.168.12.0/24\\\&quot;, \\\&quot;rangeStart\\\&quot;: \\\&quot;192.168.12.105\\\&quot;, \\\&quot;rangeEnd\\\&quot;: \\\&quot;192.168.12.105\\\&quot;, \\\&quot;routes\\\&quot;: [{ \\\&quot;dst\\\&quot;: \\\&quot;0.0.0.0/0\\\&quot; }], \\\&quot;gateway\\\&quot;: \\\&quot;192.168.12.1\\\&quot; } }\&quot;}}\n&quot;
    },
    &quot;name&quot;: &quot;host-device-du&quot;,
    &quot;namespace&quot;: &quot;default&quot;
  },
  &quot;spec&quot;: {
    &quot;config&quot;: &quot;{ \&quot;cniVersion\&quot;: \&quot;0.3.0\&quot;, \&quot;type\&quot;: \&quot;host-device\&quot;, \&quot;device\&quot;: \&quot;ens18f1\&quot;, \&quot;ipam\&quot;: { \&quot;type\&quot;: \&quot;host-local\&quot;, \&quot;subnet\&quot;: \&quot;192.168.12.0/24\&quot;, \&quot;rangeStart\&quot;: \&quot;192.168.12.105\&quot;, \&quot;rangeEnd\&quot;: \&quot;192.168.12.105\&quot;, \&quot;routes\&quot;: [{ \&quot;dst\&quot;: \&quot;0.0.0.0/0\&quot; }], \&quot;gateway\&quot;: \&quot;192.168.12.1\&quot; } }&quot;
  }
}
</code></pre>
<pre><code class="language-bash">oc get net-attach-def/host-device-du -o json | jq &quot;del(.metadata.managedFields, .metadata.uid, .metadata.selfLink, .metadata.resourceVersion, .metadata.generation, .metadata.creationTimestamp)&quot; | jq .spec.config | jq &quot;fromjson&quot;
</code></pre>
<pre><code class="language-json">{
  &quot;cniVersion&quot;: &quot;0.3.0&quot;,
  &quot;type&quot;: &quot;host-device&quot;,
  &quot;device&quot;: &quot;ens18f1&quot;,
  &quot;ipam&quot;: {
    &quot;type&quot;: &quot;host-local&quot;,
    &quot;subnet&quot;: &quot;192.168.12.0/24&quot;,
    &quot;rangeStart&quot;: &quot;192.168.12.105&quot;,
    &quot;rangeEnd&quot;: &quot;192.168.12.105&quot;,
    &quot;routes&quot;: [
      {
        &quot;dst&quot;: &quot;0.0.0.0/0&quot;
      }
    ],
    &quot;gateway&quot;: &quot;192.168.12.1&quot;
  }
}
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                                                    <a rel="prev" href="../../ocp4/4.7/4.7.keepalived.operator.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                        
                                                    <a rel="next" href="../../ocp4/4.7/4.7.install.kmod.driver.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                                    <a rel="prev" href="../../ocp4/4.7/4.7.keepalived.operator.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                
                                    <a rel="next" href="../../ocp4/4.7/4.7.install.kmod.driver.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
                            </nav>

        </div>

        
        
        
                <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        
        
                <script src="../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../searcher.js" type="text/javascript" charset="utf-8"></script>
        
        <script src="../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        
        
    </body>
</html>
